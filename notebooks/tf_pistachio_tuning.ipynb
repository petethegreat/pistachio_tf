{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67e146c-7741-4e5d-b3e5-152d1fcce01c",
   "metadata": {},
   "source": [
    "# tensorflow pistachio\n",
    "Tuning with hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d7921-a931-4947-85fa-036f43cf4653",
   "metadata": {},
   "source": [
    "## Links\n",
    "  - [notes on training/validation loss](https://siddiqueabusaleh.medium.com/why-my-training-loss-is-higher-than-validation-loss-is-the-reported-loss-even-accurate-8843e14a0756)\n",
    "  - [initialisation values](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines)\n",
    "  - [shap feature importance](https://shap.readthedocs.io/en/latest/tabular_examples.html#neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9645c12f-836e-43ef-a516-dd6134687a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 14:41:12.268416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c077c-56e8-4081-b5dc-34945bd1fa61",
   "metadata": {},
   "source": [
    "## arff to csv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98bbd97-83f9-40e2-a125-e20d695ac0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19e49d4-8185-4a92-b60f-7e94609fccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/pistachio_16.csv exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from scipy.io import arff\n",
    "import os \n",
    "\n",
    "from pistachio.data import load_arff_file\n",
    "\n",
    "label_mapping = {'Kirmizi_Pistachio': 0, 'Siit_Pistachio': 1}\n",
    "\n",
    "\n",
    "arff_filename = './data/Pistachio_16_Features_Dataset.arff'\n",
    "csv_filename = './data/pistachio_16.csv'\n",
    "\n",
    "if not os.path.exists(csv_filename):\n",
    "    df = load_arff_file(arff_filename, label_mapping)\n",
    "    df.head()\n",
    "    df.to_csv(csv_filename, index=False, header=True)\n",
    "    print(f'wrote file to {csv_filename}')\n",
    "else:\n",
    "    print(f'{csv_filename} exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1321b8-3de5-4129-862a-7b503427c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7728108f-df68-4e88-bfd0-a9298262c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset\n",
    "# BATCH_SIZE = 16 \n",
    "# PREFETCH = tf.data.AUTOTUNE\n",
    "SEED=37\n",
    "\n",
    "# model parameters\n",
    "# UNITS = 12\n",
    "# LAYER_1_L1 = 2e-4\n",
    "# LAYER_1_L2 = 5e-3\n",
    "# LAYER_2_L1 = 2e-4\n",
    "# LAYER_2_L2 = 5e-3\n",
    "\n",
    "\n",
    "\n",
    "#model fitting\n",
    "# EPOCHS = 500\n",
    "# LEARNING_RATE = 0.001 # initial learning rate\n",
    "# LR_PLATEAU_FACTOR = 0.5\n",
    "# LR_PLATEAU_PATIENCE = 5\n",
    "# LR_DECAY_RATE = 0.8\n",
    "# MIN_LEARNING_RATE = 1e-6\n",
    "# EARLY_STOPPING_PATIENCE = 40\n",
    "\n",
    "\n",
    "# mlflow\n",
    "MLFLOW_URI = uri=\"http://pistachio_mlflow:5000\"\n",
    "MLFLOW_EXPERIMENT = \"pistachio_tf_tuning\"\n",
    "MLFLOW_RUN_DESCRIPTION = 'initial tuning of two layer model'\n",
    "MLFLOW_TAGS = {'architecture': f'two layers'}\n",
    "\n",
    "# hyperopt\n",
    "TRIALS_FILE_LOCATION = f'./trials/trials_{MLFLOW_EXPERIMENT}.pkl'\n",
    "# will save trials object at this location\n",
    "TRIALS_PER_RUN = 5\n",
    "# run this many trials per notebook execution.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e66103-32dc-4820-8089-71b0f3b4b789",
   "metadata": {},
   "source": [
    "## dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7845cd-40fe-4406-9874-ca68bc501561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "df shape = (1288, 17)\n",
      "   Class  AREA\n",
      "0      0   738\n",
      "1      1   550\n",
      "validation\n",
      "df shape = (430, 17)\n",
      "   Class  AREA\n",
      "0      0   247\n",
      "1      1   183\n",
      "test\n",
      "df shape = (430, 17)\n",
      "   Class  AREA\n",
      "0      0   247\n",
      "1      1   183\n"
     ]
    }
   ],
   "source": [
    "from pistachio.data import read_or_generate_splits\n",
    "\n",
    "# define where train/test csvs will live\n",
    "split_data_path = f\"./data/seed_{SEED}/\"\n",
    "if not os.path.exists(split_data_path):\n",
    "    os.makedirs(split_data_path)\n",
    "\n",
    "train_df, valid_df, test_df = read_or_generate_splits(split_data_path, csv_filename, seed=SEED)\n",
    "\n",
    "for setname, df in zip(['train','validation','test'],[train_df, valid_df, test_df]):\n",
    "    print(setname)\n",
    "    print(f'df shape = {df.shape}')\n",
    "    agged = df.groupby('Class').agg({'AREA':'count'}).reset_index()\n",
    "    print(agged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f2aaff-b76c-4041-b30b-09399a3ec519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AREA',\n",
       " 'PERIMETER',\n",
       " 'MAJOR_AXIS',\n",
       " 'MINOR_AXIS',\n",
       " 'ECCENTRICITY',\n",
       " 'EQDIASQ',\n",
       " 'SOLIDITY',\n",
       " 'CONVEX_AREA',\n",
       " 'EXTENT',\n",
       " 'ASPECT_RATIO',\n",
       " 'ROUNDNESS',\n",
       " 'COMPACTNESS',\n",
       " 'SHAPEFACTOR_1',\n",
       " 'SHAPEFACTOR_2',\n",
       " 'SHAPEFACTOR_3',\n",
       " 'SHAPEFACTOR_4']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = list(train_df.columns)\n",
    "feature_columns.remove('Class')\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778ff87f-3a47-493f-8bdc-54309fc32215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pistachio.data import df_to_dataset\n",
    "# # create datasets\n",
    "# train_ds = df_to_dataset(train_df,'Class', shuffle=True, drop=True)\n",
    "# valid_ds = df_to_dataset(valid_df,'Class', shuffle=False, drop=False)\n",
    "# test_ds = df_to_dataset(test_df,'Class', shuffle=False, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0033c4dd-2a95-4b3c-b256-cdbb478cf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "# hyperopt search space/parameters\n",
    "hp_space = {\n",
    "    # model\n",
    "    'units': hp.randint('units', 5,12),\n",
    "    'layer_l1_reg': hp.loguniform('layer_l1_reg', 2e-6,2e-3),\n",
    "    'layer_l2_reg':hp.loguniform('layer_l2_reg', 2e-6,2e-3),\n",
    "    'feature_columns':feature_columns,\n",
    "    # fitting\n",
    "    'learning_rate': hp.loguniform('learnig_rate', 1e-7,5e-3),\n",
    "    'lr_plateau_factor': hp.uniform('lr_plateau_factor', 0.5, 0.95),\n",
    "    'lr_plateau_patience': 20,\n",
    "    'lr_decay_rate': 0.9,\n",
    "    'min_learning_rate': 5e-8,\n",
    "    'early_stopping_patience': 40,\n",
    "\n",
    "    # data/batch/epochs\n",
    "    'batch_size': 16,\n",
    "    'prefetch':  tf.data.AUTOTUNE,\n",
    "    'epochs': 500,\n",
    "    'seed':SEED\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0274feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pistachio.data import df_to_dataset\n",
    "from pistachio.model import get_pistachio_model\n",
    "from typing import Dict \n",
    "import mlflow\n",
    "# create datasets\n",
    "import mlflow\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, roc_curve\n",
    "\n",
    "from pistachio.evaluation import plot_metric, get_roc_results, plot_roc_curve, get_confusion_matrix\n",
    "from pistachio.evaluation import make_precision_recall_plot, make_prob_calibration_plot, make_confusion_matrix_plot\n",
    "sns.set()\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI)\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "\n",
    "# define our hyperopt objective\n",
    "def pistachio_objective(kwargs) ->Dict:\n",
    "    '''take model parameters, build, train and evaluate model, return loss value and other stats'''\n",
    "    \n",
    "    # reset tf state\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # start mlflow run\n",
    "    with  mlflow.start_run(tags=MLFLOW_TAGS, description=MLFLOW_RUN_DESCRIPTION) as mlflow_run:\n",
    "\n",
    "        run_name = mlflow_run.info.run_name\n",
    "        run_id = mlflow_run.info.run_id\n",
    "        # mlflow.log_params(kwargs)\n",
    "\n",
    "\n",
    "        # define datasets \n",
    "        # think these need to go in here, given that we're clearing the tf state\n",
    "        train_ds = df_to_dataset(\n",
    "            train_df,\n",
    "            'Class',\n",
    "            shuffle=True,\n",
    "            drop=True,\n",
    "            batch_size=kwargs.get('batch_size',32),\n",
    "            prefetch=kwargs.get('prefetch', 32))\n",
    "\n",
    "        valid_ds = df_to_dataset(\n",
    "            valid_df,\n",
    "            'Class', \n",
    "            shuffle=False,\n",
    "            drop=False,\n",
    "            batch_size=kwargs.get('batch_size',32),\n",
    "            prefetch=kwargs.get('prefetch', 32))\n",
    "        \n",
    "        # get the model we'll train, adapting it on train data\n",
    "        model = get_pistachio_model(\n",
    "            feature_columns=feature_columns,\n",
    "            units=kwargs.get('units',10),\n",
    "            layer_l1_reg=kwargs.get('layer_l1_reg',0.0),\n",
    "            layer_l2_reg=kwargs.get('layer_l2_reg',0.0))\n",
    "    \n",
    "        checkpoint_dir = './pistachio_model_checkpoints/'\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, run_name)\n",
    "        os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "        metrics = {\n",
    "        'predicted_probability': [\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.BinaryAccuracy()]}\n",
    "\n",
    "        callbacks = [\n",
    "            # tf.keras.callbacks.TensorBoard(logdir, update_freq='batch'),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', \n",
    "                factor=kwargs.get('lr_plateau_factor'), \n",
    "                patience=kwargs.get('lr_plateau_patience'), \n",
    "                min_lr=kwargs.get('min_learning_rate')),\n",
    "            tf.keras.callbacks.EarlyStopping(patience=kwargs.get()),\n",
    "            # checkpoint\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                initial_value_threshold=0.7,\n",
    "                save_best_only=True),\n",
    "            # mlflow\n",
    "            mlflow.keras.MlflowCallback(mlflow_run)]\n",
    "    \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=kwargs.get('learning_rate'))\n",
    "\n",
    "        # compile model\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss={'predicted_probability': tf.keras.losses.BinaryCrossentropy(from_logits=False)},\n",
    "            metrics=metrics)\n",
    "        \n",
    "        # train model\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=kwargs.get('epochs'),\n",
    "            callbacks=callbacks,\n",
    "            validation_data=valid_ds)\n",
    "        \n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df['epoch'] = history_df.index\n",
    "        # history_df.columns\n",
    "\n",
    "        # plot training stuff\n",
    "        plot_dir = f'./plots/{run_name}/'\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        metrics_to_plot = [\n",
    "            'learning_rate',\n",
    "            'auc',\n",
    "            'loss',\n",
    "            'binary_accuracy',\n",
    "            'recall',\n",
    "            'precision']\n",
    "\n",
    "        metric_plots = {}\n",
    "        for mm in metrics_to_plot:\n",
    "            metric_plots[mm] = plot_metric(history_df, mm);\n",
    "            fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "            print(fig_path)\n",
    "            metric_plots[mm][0].savefig(fig_path);\n",
    "        \n",
    "        # look at the best training epoch, get some metrics\n",
    "\n",
    "        val_metrics = [k for k in history_df.columns if k.startswith('val')]\n",
    "        best_epoch = history_df.loc[history_df.val_loss == np.min(history_df.val_loss)][['epoch'] + val_metrics].copy()\n",
    "\n",
    "        # best_epoch\n",
    "        rename = {k:f'best_epoch_{k}' for k in val_metrics}\n",
    "        rename['epoch'] = 'best_epoch'\n",
    "\n",
    "        best_stats = best_epoch\\\n",
    "            .rename(columns=rename)\\\n",
    "            .to_dict(orient='records')[0]\n",
    "        \n",
    "        # log these things\n",
    "        mlflow.log_artifacts(plot_dir, artifact_path='training_plots')\n",
    "        mlflow.log_metrics(best_stats)\n",
    "\n",
    "        # load the best version of the model\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "        # get predictions on validation set\n",
    "        valid_features = {k: valid_df[k].values for k in feature_columns}\n",
    "        valid_predictions = model.predict(valid_features)\n",
    "        valid_df['predicted_prob'] = valid_predictions\n",
    "        threshold = 0.5\n",
    "        valid_df['predicted_class'] = valid_df.predicted_prob.map(lambda x: 0 if x < threshold else 1)\n",
    "\n",
    "        # roc curve\n",
    "        roc_results = get_roc_results(valid_df.predicted_prob, valid_df.Class)\n",
    "        valid_auc_score = roc_auc_score(valid_df.Class, valid_df.predicted_prob)\n",
    "        fig, ax = plot_roc_curve(*roc_results, title=f'validation data, auc_score = {valid_auc_score}');\n",
    "        roc_plot_path = os.path.join(plot_dir, 'roc_curve.png')\n",
    "        fig.savefig(roc_plot_path)\n",
    "\n",
    "        # precision recall\n",
    "        fig, ax = make_precision_recall_plot(valid_df.predicted_prob, valid_df.Class, title='precision-recall')\n",
    "        prec_rec_path = os.path.join(plot_dir,'precision_recall_curve.png')\n",
    "        fig.savefig(prec_rec_path)\n",
    "\n",
    "        # confusion matrix\n",
    "        fig, ax = make_confusion_matrix_plot(valid_df.predicted_class, valid_df.Class)\n",
    "        confusion_plot_path = os.path.join(plot_dir, 'confusion_matrix.png')\n",
    "        fig.savefig(confusion_plot_path)\n",
    "\n",
    "        # prob calibration\n",
    "        fig, ax = make_prob_calibration_plot(valid_df.predicted_prob, valid_df.Class, title='pistachio classifier probability calibration')\n",
    "        prob_cal_path = os.path.join(plot_dir,'probability_calibration.png')\n",
    "        fig.savefig(prob_cal_path)\n",
    "\n",
    "        validation_metrics_path = './saved_model_validation_metrics.txt'\n",
    "        with open(validation_metrics_path,'w') as outfile:\n",
    "            outfile.write(f'accuracy: {accuracy_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "            outfile.write(f'precision: {precision_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "            outfile.write(f'recall: {recall_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "            outfile.write(f'f1_score: {f1_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "            outfile.write(f'roc_auc_score: {valid_auc_score}\\n')\n",
    "        \n",
    "            mlflow.log_artifact(roc_plot_path, artifact_path='evaluation_plots')\n",
    "            mlflow.log_artifact(confusion_plot_path, artifact_path='evaluation_plots')\n",
    "            mlflow.log_artifact(prob_cal_path, artifact_path='evaluation_plots')\n",
    "            mlflow.log_artifact(prec_rec_path, artifact_path='evaluation_plots')\n",
    "\n",
    "            mlflow.log_artifact(validation_metrics_path)\n",
    "            # mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "            # mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "\n",
    "        # print(open(validation_metrics_path,'r').read())\n",
    "        # return. Can put more info in here, but it should be in mlflow regardless\n",
    "        return {'status': 'ok', 'loss': best_stats['best_epoch_val_loss'], 'true_loss':best_stats['best_epoch_val_loss'] }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6a8ac90-eceb-44cb-a73f-8d55a76c66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run judicious-seal-716 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/e4561c61ade74b2bad21fc3ce669c473\n",
      "\n",
      "ðŸ§ª View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: 'float' object has no attribute 'get'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m evals_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m     10\u001b[0m max_evals \u001b[38;5;241m=\u001b[39m evals_done \u001b[38;5;241m+\u001b[39m TRIALS_PER_RUN\n\u001b[0;32m---> 11\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpistachio_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(TRIALS_FILE_LOCATION,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[1;32m     18\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(trials,outfile)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[19], line 44\u001b[0m, in \u001b[0;36mpistachio_objective\u001b[0;34m(kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m run_id \u001b[38;5;241m=\u001b[39m mlflow_run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# mlflow.log_params(kwargs)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# define datasets \u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# think these need to go in here, given that we're clearing the tf state\u001b[39;00m\n\u001b[1;32m     39\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m df_to_dataset(\n\u001b[1;32m     40\u001b[0m     train_df,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     42\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m     drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m---> 44\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m32\u001b[39m),\n\u001b[1;32m     45\u001b[0m     prefetch\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprefetch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m32\u001b[39m))\n\u001b[1;32m     47\u001b[0m valid_ds \u001b[38;5;241m=\u001b[39m df_to_dataset(\n\u001b[1;32m     48\u001b[0m     valid_df,\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m32\u001b[39m),\n\u001b[1;32m     53\u001b[0m     prefetch\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprefetch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m32\u001b[39m))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# get the model we'll train, adapting it on train data\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from hyperopt import Trials, fmin, tpe\n",
    "if os.path.exists(TRIALS_FILE_LOCATION):\n",
    "    trials = pickle.load(open(TRIALS_FILE_LOCATION,'rb'))\n",
    "else:\n",
    "    trials = Trials()\n",
    "\n",
    "\n",
    "evals_done = len(trials.trials)\n",
    "max_evals = evals_done + TRIALS_PER_RUN\n",
    "best = fmin(pistachio_objective,\n",
    "    space=hp.uniform('x', -10, 10),\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials)\n",
    "\n",
    "with open(TRIALS_FILE_LOCATION,'wb') as outfile:\n",
    "    pickle.dump(trials,outfile)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df3197b-18b2-4f33-b760-ab2c45de50fd",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "try this instead, dataset is weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d0672-0aab-42b6-8cdd-e1bdab5388c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('halting here')\n",
    "train_ds.cardinality().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4379442-c952-4857-9fea-270f6f86e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Normalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.metrics import Accuracy, AUC, Recall, Precision\n",
    "\n",
    "def get_pistachio_model(feature_columns: List[str], train_dataset: tf.data.Dataset, units: int=10):\n",
    "    \"\"\"build a pistachio model using functional api\"\"\"\n",
    "    def _get_feature_normalizers():\n",
    "        \"\"\"initialise and adapt the feature normalisers\"\"\"\n",
    "        print(f'preprocessing - initialising normalisers')\n",
    "        normalizers = {}\n",
    "        for feature in feature_columns:\n",
    "            normaliser =  Normalization(axis=None, name=f'normalizer_{feature}')\n",
    "            just_this_feature_ds = train_dataset.map(lambda x,y: x[feature])\n",
    "            normaliser.adapt(just_this_feature_ds)\n",
    "            normalizers[feature] = normaliser\n",
    "        return normalizers\n",
    "        \n",
    "    def _build_model(normalizers: Dict):\n",
    "        normalized_inputs = []\n",
    "        raw_inputs = []\n",
    "        for feature in feature_columns:\n",
    "            feature_input = tf.keras.Input(shape=(1,), name=feature)\n",
    "            raw_inputs.append(feature_input)\n",
    "            normalized_input = normalizers[feature](feature_input)\n",
    "            normalized_inputs.append(normalized_input)\n",
    "\n",
    "        input_layer = tf.keras.layers.concatenate(normalized_inputs)\n",
    "\n",
    "        # densely connected layers\n",
    "        d1 = Dense(\n",
    "            units,\n",
    "            activation='relu',\n",
    "            name='dense_1',\n",
    "            kernel_regularizer=tf.keras.regularizers.L1L2(l1=LAYER_1_L1, l2=LAYER_1_L2))\n",
    "        \n",
    "        d2 = Dense(\n",
    "            units,\n",
    "            activation='relu',\n",
    "            name='dense_2',\n",
    "            kernel_regularizer=tf.keras.regularizers.L1L2(l1=LAYER_2_L1, l2=LAYER_2_L2))\n",
    "        \n",
    "\n",
    "        # output layer\n",
    "        output_layer = Dense(1, activation='sigmoid', name='predicted_probability')\n",
    "        # http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines\n",
    "\n",
    "        # define graph\n",
    "        x = d1(input_layer)\n",
    "        x = d2(x)\n",
    "        output_probability = output_layer(x)\n",
    "        \n",
    "        model = tf.keras.Model(raw_inputs, output_probability)\n",
    "        return model\n",
    "    normalizers = _get_feature_normalizers()\n",
    "    model = _build_model(normalizers)\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e903376-6aee-4746-acac-02a597bacccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "logdir = './pistachio_model_logs'\n",
    "if os.path.exists(logdir):\n",
    "    shutil.rmtree(logdir)\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "checkpoint_dir = './pistachio_model_checkpoints/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "metrics = {\n",
    "    'predicted_probability': [\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.BinaryAccuracy()]\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(logdir, update_freq='batch'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=LR_PLATEAU_FACTOR, patience=LR_PLATEAU_PATIENCE, min_lr=MIN_LEARNING_RATE),\n",
    "    # tf.keras.callbacks.LearningRateScheduler(lambda epoch, lr: max(lr*LR_DECAY_RATE, MIN_LEARNING_RATE))\n",
    "    tf.keras.callbacks.EarlyStopping(patience=EARLY_STOPPING_PATIENCE)\n",
    "    # mlflow included later - based off mlflow runid\n",
    "    # checkpointing included later - uses mlflow runid\n",
    "]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# build the model\n",
    "model = get_pistachio_model(feature_columns, train_ds, units=UNITS)\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss={'predicted_probability': tf.keras.losses.BinaryCrossentropy(from_logits=False)},\n",
    "    metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba35485-86d6-46b1-ab20-a91b111d3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'PREFETCH': PREFETCH,\n",
    "    'SEED': SEED,\n",
    "    'UNITS': UNITS,\n",
    "    'EPOCHS': EPOCHS,\n",
    "    'LEARNING_RATE': LEARNING_RATE,\n",
    "    'LR_PLATEAU_FACTOR': LR_PLATEAU_FACTOR,\n",
    "    'LR_DECAY_RATE': LR_DECAY_RATE,\n",
    "    'MIN_LEARNING_RATE': MIN_LEARNING_RATE,\n",
    "    'FEATURE_COLUMNS': feature_columns,\n",
    "    'LAYER_1_L1':LAYER_1_L1,\n",
    "    'LAYER_1_L2':LAYER_1_L2,\n",
    "    'LAYER_2_L1':LAYER_2_L1,\n",
    "    'LAYER_2_L2':LAYER_2_L2\n",
    "}\n",
    "for k,v in params.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc51c5-8b35-4d42-9b1a-1af55cade546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI)\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "# don't autolog\n",
    "# mlflow.tensorflow.autolog()\n",
    "\n",
    "# if passing an existing run_id to mlflow.start_run, it treats it as resuming that run (update/change parameters, metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cd6a6-1960-43ba-b2a5-2f61b9ba587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(tags=MLFLOW_TAGS, description=MLFLOW_RUN_DESCRIPTION) as mlflow_run:\n",
    "    # append mlflow callback to callbacks\n",
    "    run_name = mlflow_run.info.run_name\n",
    "    run_id = mlflow_run.info.run_id\n",
    "    callbacks.append(mlflow.keras.MlflowCallback(mlflow_run))\n",
    "    # append model checkpoint to callbacks\n",
    "    checkpoint_path = os.path.join(checkpoint_dir,f'model_{mlflow_run.info.run_name}.model.keras')\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        initial_value_threshold=0.7,\n",
    "        save_best_only=True))       \n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=valid_ds)\n",
    "\n",
    "    mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36090c-84ed-4289-b9ba-4c22d7d22d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'run_name: {run_name}, run_id: {run_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410f226-8414-4e3e-b916-a990607e3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df['epoch'] = history_df.index\n",
    "history_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5137453-9c94-4a92-8c5c-617024ecccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55faea-872f-430f-b288-9158677f8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable, Tuple\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_metric(history_df: pd.DataFrame, metric_name:str):\n",
    "    '''plot metric vs epoch'''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    # train data value \n",
    "    if metric_name == 'learning_rate':\n",
    "        ax.plot(history_df.index, history_df[metric_name], color=sns.xkcd_rgb['merlot'], label=metric_name)\n",
    "    else:    \n",
    "        ax.plot(history_df.index, history_df[metric_name], color=sns.xkcd_rgb['merlot'], label=f'train_{metric_name}')\n",
    "        ax.plot(history_df.index, history_df[f'val_{metric_name}'], color=sns.xkcd_rgb['blurple'], label=f'val_{metric_name}')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'{metric_name} vs epoch')\n",
    "    return fig, ax\n",
    "\n",
    "sns.set()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4997196-7f6f-4d68-93e4-1eca5fe8a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_dir = f'./plots/{run_name}/'\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "metrics_to_plot = [\n",
    "    'learning_rate',\n",
    "    'auc',\n",
    "    'loss',\n",
    "    'binary_accuracy',\n",
    "    'recall',\n",
    "    'precision']\n",
    "\n",
    "metric_plots = {}\n",
    "for mm in metrics_to_plot:\n",
    "    metric_plots[mm] = plot_metric(history_df, mm);\n",
    "    fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "    print(fig_path)\n",
    "    metric_plots[mm][0].savefig(fig_path);\n",
    "                                 \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ced48-ee8b-4665-ac8f-3082debe740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plots[metrics_to_plot[0]][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b469bd-2bed-49ac-b760-bbedf3b99109",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plots[metrics_to_plot[1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7355c-61fc-4dfc-a001-ce5afd39d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plots[metrics_to_plot[2]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127466a-cdd2-4338-a7f9-3118195c6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plots[metrics_to_plot[3]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812151ae-f224-4a4e-bf96-4f6c5b0bb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plots[metrics_to_plot[4]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6ccb3-7b8f-4bcc-9641-1e04a37cf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plots[metrics_to_plot[5]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3738fc-9d90-49e2-851e-be0b4342cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add plots as artifacts\n",
    "val_metrics = [k for k in history_df.columns if k.startswith('val')]\n",
    "best_epoch = history_df.loc[history_df.val_loss == np.min(history_df.val_loss)][['epoch'] + val_metrics].copy()\n",
    "\n",
    "# best_epoch\n",
    "rename = {k:f'best_epoch_{k}' for k in val_metrics}\n",
    "rename['epoch'] = 'best_epoch'\n",
    "\n",
    "best_stats = best_epoch\\\n",
    "    .rename(columns=rename)\\\n",
    "    .to_dict(orient='records')[0]\n",
    "# best_stats\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_id=run_id) as mlflow_run:\n",
    "#     for mm in metrics_to_plot:\n",
    "#         # fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "    mlflow.log_artifacts(plot_dir, artifact_path='training_plots')\n",
    "    mlflow.log_metrics(best_stats)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb200564-f39a-4838-9950-68304b862ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a795eb1-b267-4175-bb1d-48a059ec54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "model.evaluate(valid_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014f4a5-cc76-43ae-991a-0aba40c3b96f",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ae52f-9435-4ed5-9992-f01168ffb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from earlier\n",
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "valid_features = {k: valid_df[k].values for k in feature_columns}\n",
    "valid_predictions = model.predict(valid_features)\n",
    "valid_df['predicted_prob'] = valid_predictions\n",
    "threshold = 0.5\n",
    "valid_df['predicted_class'] = valid_df.predicted_prob.map(lambda x: 0 if x < threshold else 1)\n",
    "# valid_df.head()\n",
    "# valid_predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1e3f7-17bc-40f1-be15-f6850977711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_ds, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad158e-b973-49e7-a3da-bf13b41f47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edd74b-897f-4d3c-84e7-35efe77abaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import scipy\n",
    "import statsmodels\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "\n",
    "import sys\n",
    "def get_roc_results(predicted_probs: List[float], actual_classes: List[float]) -> Tuple[List[float],List[float],List[float]]:\n",
    "    \"\"\"get roc curve definition\n",
    "\n",
    "    Args:\n",
    "        predicted_probs (List[float]): predicted probabilities\n",
    "        actual_classes (List[float]): actual binary labels\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List,List,List]: fpr, tpr, thresholds\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(actual_classes, predicted_probs)\n",
    "    if thresholds[0] == float('inf'):\n",
    "        thresholds[0] = sys.float_info.max\n",
    "\n",
    "    return fpr, tpr, thresholds\n",
    "\n",
    "#################################################################\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, thresholds, title: str=\"ROC curve\", xlabel='False Positive Rate', ylabel: str='True Positive Rate') -> Tuple[mpl.figure.Figure, mpl.axes.Axes]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        fpr (_type_): _description_\n",
    "        tpr (_type_): _description_\n",
    "        thresholds (_type_): _description_\n",
    "        title (str, optional): _description_. Defaults to \"ROC curve\".\n",
    "        xlabel (str, optional): _description_. Defaults to 'False Positive Rate'.\n",
    "        ylabel (str, optional): _description_. Defaults to 'True Positive Rate'.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[mpl.Figure, mpl.Axis]: _description_\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    ax.plot(fpr, tpr, color=sns.xkcd_rgb['blurple'], label='roc curve')\n",
    "    ax.plot([0.0, 1.0],[0.0, 1.0], color=sns.xkcd_rgb['merlot'], linestyle='--', label='random')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    # fig.show()\n",
    "    return fig, ax\n",
    "#################################################################\n",
    "def get_confusion_matrix(predicted_classes, actual_classes, normalise=None):\n",
    "    \"\"\"get confusion matrix\n",
    "    computes confusion matrix for binary classification\n",
    "\n",
    "    Args:\n",
    "        predicted_classes (_type_): _description_\n",
    "        actual_classes (_type_): _description_\n",
    "        normalise (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    matrix = confusion_matrix(actual_classes,predicted_classes, normalize=normalise)\n",
    "    return matrix\n",
    "#################################################################\n",
    "\n",
    "def make_confusion_matrix_plot(\n",
    "    predicted_classes,\n",
    "    actual_classes,\n",
    "    title:str = 'confusion matrix',\n",
    "    xlabel: str='predicted class',\n",
    "    ylabel: str='actual class',\n",
    "    class_names: List[str] = None,\n",
    "    normalise:str=None\n",
    "    ):\n",
    "    \"\"\" generate confusion matrix plot\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    ax.grid(False)\n",
    "    # cmap = sns.color_palette(\"magma_r\", as_cmap=True)\n",
    "    cmap = sns.light_palette(\"indigo\", as_cmap=True)\n",
    "\n",
    "    # cmap = 'viridis'\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes,predicted_classes, normalize=normalise)\n",
    "    ax.imshow(matrix, cmap=cmap)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            ax.text(i,j,f'{matrix[i,j]}')\n",
    "    # ax.plot([0.0, 1.0],[0.0, 1.0], color=sns.xkcd_rgb['merlot'], linestyle='--', label='random')\n",
    "    labels = class_names if class_names else ['0','1']\n",
    "\n",
    "    ax.set_xlim([-0.5, matrix.shape[0]- 0.5])\n",
    "    ax.set_ylim([matrix.shape[0]- 0.5, -0.5])\n",
    "    ax.set_xticks(np.arange(matrix.shape[0]))\n",
    "    ax.set_yticks(np.arange(matrix.shape[0]))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    # ax.legend()\n",
    "    # fig.show()\n",
    "    return fig, ax\n",
    "#################################################################\n",
    "def make_precision_recall_plot(predicted_probs, actual_classes, title: str=\"Precision-Recall Curve\", xlabel='Recall',ylabel: str='Precision',\n",
    "                              positive_rate:float=None):\n",
    "    \"\"\"make a roc curve\"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(actual_classes, predicted_probs)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    classifier_average_precision = average_precision_score(actual_classes, predicted_probs)\n",
    "    ax.plot(recall, precision, color=sns.xkcd_rgb['blurple'], label=f'precision recall curve (average precision = {classifier_average_precision:0.3f}')\n",
    "    if positive_rate:\n",
    "        ax.plot([0.0, 1.0],[positive_rate, positive_rate], color=sns.xkcd_rgb['merlot'], linestyle='--', label=f'positive response rate = {positive_rate:0.3f}')\n",
    "\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    # fig.show()\n",
    "    return fig, ax\n",
    "###########################################################\n",
    "\n",
    "def make_prob_calibration_plot(predicted_probs, actual_classes, n_bins: int=20, alpha: float = 0.05, title:str = 'probability calibration'):\n",
    "    \"\"\"bin records, check that proportion of labels in each bin matches mean probability of that bin\"\"\"\n",
    "    bins = pd.qcut(predicted_probs, n_bins, labels=False)\n",
    "    df = pd.DataFrame({'probability':predicted_probs, 'class':actual_classes, 'bin':bins})\n",
    "    df = df.sort_values(by='probability',ascending=False).reset_index(drop=True)\n",
    "    agged = df.groupby('bin').agg(\n",
    "        pred_prob=pd.NamedAgg('probability','mean'),\n",
    "        pred_std=pd.NamedAgg('probability','std'),\n",
    "        class_prob=pd.NamedAgg('class','mean'),\n",
    "        class_sum=pd.NamedAgg('class','sum'),\n",
    "        bin_size=pd.NamedAgg('class','count')\n",
    "    )\n",
    "    act_err_low, act_err_high = proportion_confint(agged.class_sum, agged.bin_size, method='wilson', alpha = alpha)\n",
    "    z_low = scipy.stats.norm.ppf(alpha/2)\n",
    "    z_high = scipy.stats.norm.ppf(1.0 - alpha/2)\n",
    "    agged['pred_low'] =  -z_low*agged['pred_std']/np.sqrt(agged['bin_size']) # agged['pred_prob'] +\n",
    "    agged['pred_high'] = z_high*agged['pred_std']/np.sqrt(agged['bin_size']) #+ agged['pred_prob'] +\n",
    "    agged['actual_error_high'] = np.maximum(act_err_high  - agged.class_prob,0)\n",
    "    agged['actual_error_low'] =  np.maximum(agged.class_prob - act_err_low,0)\n",
    "    agged.loc[np.abs(agged.actual_error_high) < 1e-10, 'actual_error_high'] = 0\n",
    "\n",
    "\n",
    "    # print(agged)\n",
    "    # print(agged)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.1,0.1, 0.8, 0.8])\n",
    "    ax.errorbar(\n",
    "        agged.pred_prob,\n",
    "        agged.class_prob,\n",
    "        yerr=[agged.actual_error_low, agged.actual_error_high],\n",
    "        xerr=[agged.pred_low,agged.pred_high],\n",
    "        fmt='.',\n",
    "        color=sns.xkcd_rgb['blurple'])\n",
    "    ax.plot([0.0,1.0],[0.0,1.0],'--',label='ideal', color=sns.xkcd_rgb['dark blue'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('predicted probability')\n",
    "    ax.set_ylabel('observed probabiilty')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe91e5-bff1-44e9-87d0-c5b06f0e44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18a8a9-846c-42fe-9360-ede0df07f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_results = get_roc_results(valid_df.predicted_prob, valid_df.Class)\n",
    "valid_auc_score = roc_auc_score(valid_df.Class, valid_df.predicted_prob)\n",
    "fig, ax = plot_roc_curve(*roc_results, title=f'validation data, auc_score = {valid_auc_score}');\n",
    "roc_plot_path = os.path.join(plot_dir, 'roc_curve.png')\n",
    "fig.savefig(roc_plot_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e19aa-c2de-4514-9e40-5e215b474e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = make_confusion_matrix_plot(valid_df.predicted_class, valid_df.Class)\n",
    "confusion_plot_path = os.path.join(plot_dir, 'confusion_matrix.png')\n",
    "fig.savefig(confusion_plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960b6e4-e847-4fb0-a9de-1328f4583ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_metrics_path = './saved_model_validation_metrics.txt'\n",
    "with open(validation_metrics_path,'w') as outfile:\n",
    "    outfile.write(f'accuracy: {accuracy_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "    outfile.write(f'precision: {precision_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "    outfile.write(f'recall: {recall_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "    outfile.write(f'f1_score: {f1_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "    outfile.write(f'roc_auc_score: {valid_auc_score}\\n')\n",
    "\n",
    "print(open(validation_metrics_path,'r').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfdf19-8d98-4eb2-a6e2-c05d21640742",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = make_precision_recall_plot(valid_df.predicted_prob, valid_df.Class, title='precision-recall')\n",
    "prec_rec_path = os.path.join(plot_dir,'precision_recall_curve.png')\n",
    "fig.savefig(prec_rec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c0ce7-6591-4d29-aeb4-93b0928aab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = make_prob_calibration_plot(valid_df.predicted_prob, valid_df.Class, title='pistachio classifier probability calibration')\n",
    "prob_cal_path = os.path.join(plot_dir,'probability_calibration.png')\n",
    "fig.savefig(prob_cal_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca134d-81a2-4925-a913-1e58b51ec189",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbcf8d-65a8-4865-9e1e-a06a7f773e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "def shap_wrapper(X):\n",
    "    feature_dict = {k:X[:,i] for i,k in enumerate(feature_columns)}\n",
    "    return model.predict(feature_dict).flatten()\n",
    "\n",
    "shap_n_samples = 50\n",
    "shap_explainer_samples = 50\n",
    "\n",
    "data_shap = train_df.loc[:,feature_columns]\n",
    "explainer = shap.KernelExplainer(shap_wrapper, data_shap.iloc[:shap_explainer_samples,:])\n",
    "shap_values = explainer.shap_values(data_shap.iloc[shap_explainer_samples:shap_explainer_samples+shap_n_samples, :], nsamples=200)\n",
    "# shap.force_plot(explainer.expected_value, shap_values, data_shap[237,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d3525-16e1-4b47-b261-1f78ed9f2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81858e7-edfd-4c76-a001-0fac60046b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.scatter(explainer)\n",
    "# shap.plots.bar(shap_values[0])\n",
    "shap_violin_path = os.path.join(plot_dir,'shap_violin.png')\n",
    "shap_bar_path = os.path.join(plot_dir,'shap_bar.png')\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"violin\", max_display=30, show=False)\n",
    "plt.savefig(shap_violin_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8022bc9-7de6-427a-ae34-f1277c45d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"bar\", max_display=30, show=False)\n",
    "plt.savefig(shap_bar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e5c7e-ad4c-44dc-9f74-e27635afcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=run_id) as mlflow_run:\n",
    "#     for mm in metrics_to_plot:\n",
    "#         # fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "    mlflow.log_artifact(roc_plot_path, artifact_path='evaluation_plots')\n",
    "    mlflow.log_artifact(confusion_plot_path, artifact_path='evaluation_plots')\n",
    "    mlflow.log_artifact(prob_cal_path, artifact_path='evaluation_plots')\n",
    "    mlflow.log_artifact(prec_rec_path, artifact_path='evaluation_plots')\n",
    "\n",
    "    mlflow.log_artifact(validation_metrics_path)\n",
    "    mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "    mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # mlflow.log_metrics(best_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad6598-ee20-4e4a-bd25-78936e8d5d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
