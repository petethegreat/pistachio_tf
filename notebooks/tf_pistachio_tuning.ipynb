{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67e146c-7741-4e5d-b3e5-152d1fcce01c",
   "metadata": {},
   "source": [
    "# tensorflow pistachio\n",
    "Tuning with hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d7921-a931-4947-85fa-036f43cf4653",
   "metadata": {},
   "source": [
    "## Links\n",
    "  - [notes on training/validation loss](https://siddiqueabusaleh.medium.com/why-my-training-loss-is-higher-than-validation-loss-is-the-reported-loss-even-accurate-8843e14a0756)\n",
    "  - [initialisation values](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines)\n",
    "  - [shap feature importance](https://shap.readthedocs.io/en/latest/tabular_examples.html#neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9645c12f-836e-43ef-a516-dd6134687a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 03:27:13.199168: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c077c-56e8-4081-b5dc-34945bd1fa61",
   "metadata": {},
   "source": [
    "## arff to csv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98bbd97-83f9-40e2-a125-e20d695ac0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19e49d4-8185-4a92-b60f-7e94609fccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/pistachio_16.csv exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from scipy.io import arff\n",
    "import os \n",
    "\n",
    "from pistachio.data import load_arff_file\n",
    "\n",
    "label_mapping = {'Kirmizi_Pistachio': 0, 'Siit_Pistachio': 1}\n",
    "\n",
    "\n",
    "arff_filename = './data/Pistachio_16_Features_Dataset.arff'\n",
    "csv_filename = './data/pistachio_16.csv'\n",
    "\n",
    "if not os.path.exists(csv_filename):\n",
    "    df = load_arff_file(arff_filename, label_mapping)\n",
    "    df.head()\n",
    "    df.to_csv(csv_filename, index=False, header=True)\n",
    "    print(f'wrote file to {csv_filename}')\n",
    "else:\n",
    "    print(f'{csv_filename} exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1321b8-3de5-4129-862a-7b503427c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7728108f-df68-4e88-bfd0-a9298262c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset\n",
    "# BATCH_SIZE = 16 \n",
    "# PREFETCH = tf.data.AUTOTUNE\n",
    "SEED=37\n",
    "\n",
    "# model parameters\n",
    "# UNITS = 12\n",
    "# LAYER_1_L1 = 2e-4\n",
    "# LAYER_1_L2 = 5e-3\n",
    "# LAYER_2_L1 = 2e-4\n",
    "# LAYER_2_L2 = 5e-3\n",
    "\n",
    "\n",
    "\n",
    "#model fitting\n",
    "# EPOCHS = 500\n",
    "# LEARNING_RATE = 0.001 # initial learning rate\n",
    "# LR_PLATEAU_FACTOR = 0.5\n",
    "# LR_PLATEAU_PATIENCE = 5\n",
    "# LR_DECAY_RATE = 0.8\n",
    "# MIN_LEARNING_RATE = 1e-6\n",
    "# EARLY_STOPPING_PATIENCE = 40\n",
    "\n",
    "\n",
    "# mlflow\n",
    "MLFLOW_URI = uri=\"http://pistachio_mlflow:5000\"\n",
    "MLFLOW_EXPERIMENT = \"pistachio_tf_tuning\"\n",
    "MLFLOW_RUN_DESCRIPTION = 'initial tuning of two layer model'\n",
    "MLFLOW_TAGS = {'architecture': f'two layers'}\n",
    "\n",
    "# hyperopt\n",
    "TRIALS_FILE_LOCATION = f'./trials/trials_{MLFLOW_EXPERIMENT}.pkl'\n",
    "if not os.path.exists(os.path.dirname(TRIALS_FILE_LOCATION)):\n",
    "    os.makedirs(os.path.dirname(TRIALS_FILE_LOCATION))\n",
    "    \n",
    "# will save trials object at this location\n",
    "TRIALS_PER_RUN = 5\n",
    "# run this many trials per notebook execution.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e66103-32dc-4820-8089-71b0f3b4b789",
   "metadata": {},
   "source": [
    "## dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7845cd-40fe-4406-9874-ca68bc501561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "df shape = (1288, 17)\n",
      "   Class  AREA\n",
      "0      0   738\n",
      "1      1   550\n",
      "validation\n",
      "df shape = (430, 17)\n",
      "   Class  AREA\n",
      "0      0   247\n",
      "1      1   183\n",
      "test\n",
      "df shape = (430, 17)\n",
      "   Class  AREA\n",
      "0      0   247\n",
      "1      1   183\n"
     ]
    }
   ],
   "source": [
    "from pistachio.data import read_or_generate_splits\n",
    "\n",
    "# define where train/test csvs will live\n",
    "split_data_path = f\"./data/seed_{SEED}/\"\n",
    "if not os.path.exists(split_data_path):\n",
    "    os.makedirs(split_data_path)\n",
    "\n",
    "train_df, valid_df, test_df = read_or_generate_splits(split_data_path, csv_filename, seed=SEED)\n",
    "\n",
    "for setname, df in zip(['train','validation','test'],[train_df, valid_df, test_df]):\n",
    "    print(setname)\n",
    "    print(f'df shape = {df.shape}')\n",
    "    agged = df.groupby('Class').agg({'AREA':'count'}).reset_index()\n",
    "    print(agged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f2aaff-b76c-4041-b30b-09399a3ec519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AREA',\n",
       " 'PERIMETER',\n",
       " 'MAJOR_AXIS',\n",
       " 'MINOR_AXIS',\n",
       " 'ECCENTRICITY',\n",
       " 'EQDIASQ',\n",
       " 'SOLIDITY',\n",
       " 'CONVEX_AREA',\n",
       " 'EXTENT',\n",
       " 'ASPECT_RATIO',\n",
       " 'ROUNDNESS',\n",
       " 'COMPACTNESS',\n",
       " 'SHAPEFACTOR_1',\n",
       " 'SHAPEFACTOR_2',\n",
       " 'SHAPEFACTOR_3',\n",
       " 'SHAPEFACTOR_4']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = list(train_df.columns)\n",
    "feature_columns.remove('Class')\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778ff87f-3a47-493f-8bdc-54309fc32215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pistachio.data import df_to_dataset\n",
    "# # create datasets\n",
    "# train_ds = df_to_dataset(train_df,'Class', shuffle=True, drop=True)\n",
    "# valid_ds = df_to_dataset(valid_df,'Class', shuffle=False, drop=False)\n",
    "# test_ds = df_to_dataset(test_df,'Class', shuffle=False, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf349e02-402e-49c1-8656-24e3a197e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.298317366548036"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.log(5e-3)\n",
    "# np.exp(-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0033c4dd-2a95-4b3c-b256-cdbb478cf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "# hyperopt search space/parameters\n",
    "hp_space = {\n",
    "    # model\n",
    "    'units': hp.randint('units', 5,12),\n",
    "    'layer_l1_reg': hp.loguniform('layer_l1_reg', -13.1,-6.214),\n",
    "    'layer_l2_reg':hp.loguniform('layer_l2_reg',-13.1,-6.214),\n",
    "    'feature_columns':feature_columns,\n",
    "    # fitting\n",
    "    'learning_rate': hp.loguniform('learning_rate', -11.5,-5.3),\n",
    "    'lr_plateau_factor': hp.uniform('lr_plateau_factor', 0.5, 0.95),\n",
    "    'lr_plateau_patience': 20,\n",
    "    'lr_decay_rate': 0.9,\n",
    "    'min_learning_rate': 5e-8,\n",
    "    'early_stopping_patience': 40,\n",
    "\n",
    "    # data/batch/epochs\n",
    "    'batch_size': 16,\n",
    "    'prefetch':  tf.data.AUTOTUNE,\n",
    "    'epochs': 300,\n",
    "    'seed':SEED\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0274feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pistachio.data import df_to_dataset\n",
    "from pistachio.model import get_pistachio_model\n",
    "from typing import Dict \n",
    "import mlflow\n",
    "# create datasets\n",
    "import mlflow\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, roc_curve\n",
    "\n",
    "from pistachio.evaluation import plot_metric, get_roc_results, plot_roc_curve, get_confusion_matrix\n",
    "from pistachio.evaluation import make_precision_recall_plot, make_prob_calibration_plot, make_confusion_matrix_plot\n",
    "sns.set()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI)\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "\n",
    "# define our hyperopt objective\n",
    "def pistachio_objective(params: Dict) -> Dict:\n",
    "    '''take model parameters, build, train and evaluate model, return loss value and other stats'''\n",
    "    #     units: int,\n",
    "    # layer_l1_reg: float,\n",
    "    # layer_l2_reg: float,\n",
    "    # feature_columns:feature_columns,\n",
    "    # learning_rate: float,\n",
    "    # lr_plateau_factor: float,\n",
    "    # lr_plateau_patience: int,\n",
    "    # lr_decay_rate: float,\n",
    "    # min_learning_rate: float,\n",
    "    # early_stopping_patience: int,\n",
    "    # batch_size: int,\n",
    "    # prefetch:  int,\n",
    "    # epochs: int,\n",
    "    # seed:int \n",
    "    \n",
    "    # reset tf state\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # start mlflow run\n",
    "    with  mlflow.start_run(tags=MLFLOW_TAGS, description=MLFLOW_RUN_DESCRIPTION) as mlflow_run:\n",
    "\n",
    "        run_name = mlflow_run.info.run_name\n",
    "        run_id = mlflow_run.info.run_id\n",
    "        # mlflow.log_params(kwargs)\n",
    "\n",
    "\n",
    "        # define datasets \n",
    "        # think these need to go in here, given that we're clearing the tf state\n",
    "        train_ds = df_to_dataset(\n",
    "            train_df,\n",
    "            'Class',\n",
    "            shuffle=True,\n",
    "            drop=True,\n",
    "            batch_size=params.get('batch_size'),\n",
    "            prefetch=params.get('prefetch'))\n",
    "\n",
    "        valid_ds = df_to_dataset(\n",
    "            valid_df,\n",
    "            'Class', \n",
    "            shuffle=False,\n",
    "            drop=False,\n",
    "            batch_size=params.get('batch_size'),\n",
    "            prefetch=params.get('prefetch'))\n",
    "        \n",
    "        # get the model we'll train, adapting it on train data\n",
    "        model = get_pistachio_model(\n",
    "            feature_columns=params.get('feature_columns'),\n",
    "            train_dataset=train_ds,\n",
    "            units=params.get('units',10),\n",
    "            layer_l1_reg=params.get('layer_l1_reg'),\n",
    "            layer_l2_reg=params.get('layer_l2_reg'))\n",
    "    \n",
    "        checkpoint_dir = './pistachio_model_checkpoints/'\n",
    "        checkpoint_path = os.path.join(checkpoint_dir,f'model_{mlflow_run.info.run_name}.model.keras')\n",
    "\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "        metrics = {\n",
    "        'predicted_probability': [\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.BinaryAccuracy()]}\n",
    "\n",
    "        callbacks = [\n",
    "            # tf.keras.callbacks.TensorBoard(logdir, update_freq='batch'),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', \n",
    "                factor=params.get('lr_plateau_factor'), \n",
    "                patience=params.get('lr_plateau_patience'), \n",
    "                min_lr=params.get('min_learning_rate')),\n",
    "            tf.keras.callbacks.EarlyStopping(patience=params.get('early_stopping_patience')),\n",
    "            # checkpoint\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                initial_value_threshold=9000,\n",
    "                save_best_only=True),\n",
    "            # mlflow\n",
    "            mlflow.keras.MlflowCallback(mlflow_run)]\n",
    "    \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=params.get('learning_rate'))\n",
    "\n",
    "        # compile model\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss={'predicted_probability': tf.keras.losses.BinaryCrossentropy(from_logits=False)},\n",
    "            metrics=metrics)\n",
    "        \n",
    "        # train model\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=params.get('epochs'),\n",
    "            callbacks=callbacks,\n",
    "            validation_data=valid_ds,\n",
    "            verbose=2)\n",
    "        \n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df['epoch'] = history_df.index\n",
    "        # history_df.columns\n",
    "\n",
    "        # plot training stuff\n",
    "        plot_dir = f'./plots/{run_name}/'\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        metrics_to_plot = [\n",
    "            'learning_rate',\n",
    "            'auc',\n",
    "            'loss',\n",
    "            'binary_accuracy',\n",
    "            'recall',\n",
    "            'precision']\n",
    "\n",
    "        metric_plots = {}\n",
    "        for mm in metrics_to_plot:\n",
    "            metric_plots[mm] = plot_metric(history_df, mm);\n",
    "            \n",
    "            fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "            print(fig_path)\n",
    "            metric_plots[mm][0].savefig(fig_path);\n",
    "            plt.close() \n",
    "        \n",
    "        # look at the best training epoch, get some metrics\n",
    "\n",
    "        val_metrics = [k for k in history_df.columns if k.startswith('val')]\n",
    "        best_epoch = history_df.loc[history_df.val_loss == np.min(history_df.val_loss)][['epoch'] + val_metrics].copy()\n",
    "\n",
    "        # best_epoch\n",
    "        rename = {k:f'best_epoch_{k}' for k in val_metrics}\n",
    "        rename['epoch'] = 'best_epoch'\n",
    "\n",
    "        best_stats = best_epoch\\\n",
    "            .rename(columns=rename)\\\n",
    "            .to_dict(orient='records')[0]\n",
    "        \n",
    "        # log these things\n",
    "        mlflow.log_artifacts(plot_dir, artifact_path='training_plots')\n",
    "        mlflow.log_metrics(best_stats)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # load the best version of the model\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "        # get predictions on validation set\n",
    "        valid_features = {k: valid_df[k].values for k in feature_columns}\n",
    "        valid_predictions = model.predict(valid_features)\n",
    "        valid_df['predicted_prob'] = valid_predictions\n",
    "        threshold = 0.5\n",
    "        valid_df['predicted_class'] = valid_df.predicted_prob.map(lambda x: 0 if x < threshold else 1)\n",
    "\n",
    "        try:           \n",
    "            validation_metrics_path = './saved_model_validation_metrics.txt'\n",
    "            valid_auc_score = roc_auc_score(valid_df.Class, valid_df.predicted_prob)\n",
    "            \n",
    "            with open(validation_metrics_path,'w') as outfile:\n",
    "                outfile.write(f'accuracy: {accuracy_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'precision: {precision_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'recall: {recall_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'f1_score: {f1_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'roc_auc_score: {valid_auc_score}\\n')\n",
    "            mlflow.log_artifact(validation_metrics_path)\n",
    "\n",
    "            # roc curve\n",
    "            roc_results = get_roc_results(valid_df.predicted_prob, valid_df.Class)\n",
    "            fig, ax = plot_roc_curve(*roc_results, title=f'validation data, auc_score = {valid_auc_score}');\n",
    "            roc_plot_path = os.path.join(plot_dir, 'roc_curve.png')\n",
    "            fig.savefig(roc_plot_path)\n",
    "            mlflow.log_artifact(roc_plot_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "    \n",
    "            # precision recall\n",
    "            fig, ax = make_precision_recall_plot(valid_df.predicted_prob, valid_df.Class, title='precision-recall')\n",
    "            prec_rec_path = os.path.join(plot_dir,'precision_recall_curve.png')\n",
    "            fig.savefig(prec_rec_path)\n",
    "            mlflow.log_artifact(prec_rec_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "    \n",
    "            # confusion matrix\n",
    "            fig, ax = make_confusion_matrix_plot(valid_df.predicted_class, valid_df.Class)\n",
    "            confusion_plot_path = os.path.join(plot_dir, 'confusion_matrix.png')\n",
    "            fig.savefig(confusion_plot_path)\n",
    "            mlflow.log_artifact(confusion_plot_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "    \n",
    "            # prob calibration\n",
    "            fig, ax = make_prob_calibration_plot(valid_df.predicted_prob, valid_df.Class, title='pistachio classifier probability calibration')\n",
    "            prob_cal_path = os.path.join(plot_dir,'probability_calibration.png')\n",
    "            fig.savefig(prob_cal_path)\n",
    "            mlflow.log_artifact(prob_cal_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "            # shap\n",
    "            def shap_wrapper(X):\n",
    "                feature_dict = {k:X[:,i] for i,k in enumerate(feature_columns)}\n",
    "                return model.predict(feature_dict).flatten()\n",
    "            shap_n_samples = 50\n",
    "            shap_explainer_samples = 50\n",
    "            shap_values_path = './shap_values.txt'\n",
    "\n",
    "            shap_violin_path = os.path.join(plot_dir,'shap_violin.png')\n",
    "            shap_bar_path = os.path.join(plot_dir,'shap_bar.png')\n",
    "            data_shap = train_df.loc[:,feature_columns]\n",
    "            explainer = shap.KernelExplainer(shap_wrapper, data_shap.iloc[:shap_explainer_samples,:])\n",
    "            shap_values = explainer.shap_values(data_shap.iloc[shap_explainer_samples:shap_explainer_samples+shap_n_samples, :], nsamples=200)\n",
    "            mlflow.log_artifact(prob_cal_path, artifact_path='evaluation_plots')\n",
    "\n",
    "            with open(shap_values_path,'w') as outfile:\n",
    "                outfile.write('SHAP values:\\n')\n",
    "                for k,v in zip(feature_columns, shap_values):\n",
    "                    outfile.write(f'{k}: {v}\\n')\n",
    "            mlflow.log_artifact(shap_values_path)\n",
    "\n",
    "            \n",
    "            shap.summary_plot(\n",
    "                shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"violin\", max_display=30, show=False)\n",
    "            plt.savefig(shap_violin_path)\n",
    "            plt.close()\n",
    "\n",
    "            shap.summary_plot(\n",
    "                shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"bar\", max_display=30, show=False)\n",
    "            plt.savefig(shap_bar_path)\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "            mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('exception during evaluation - may not have all plots available')\n",
    "    \n",
    "\n",
    "            # mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "            # mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "\n",
    "        # print(open(validation_metrics_path,'r').read())\n",
    "        # return. Can put more info in here, but it should be in mlflow regardless\n",
    "        return {'status': STATUS_OK, 'loss': best_stats['best_epoch_val_loss'], 'true_loss':best_stats['best_epoch_val_loss'] }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a8ac90-eceb-44cb-a73f-8d55a76c66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing - initialising normalisers               \n",
      " 67%|██████▋   | 10/15 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 03:27:16.887891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.894142: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.894378: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.895243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.895388: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.895517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.951665: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.951822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.951958: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-07 03:27:16.952067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5160 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2024-12-07 03:27:17.534961: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.576707: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.617434: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.656757: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.696138: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.734750: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.775142: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.814384: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.851388: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.888941: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.926191: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:17.965616: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:18.004687: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:18.042512: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:18.080477: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:27:18.117586: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                            \n",
      "\n",
      " 67%|██████▋   | 10/15 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733542039.544633   37600 service.cc:145] XLA service 0x7ae8f80042a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733542039.544662   37600 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "2024-12-07 03:27:19.587540: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-07 03:27:19.793233: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n",
      "I0000 00:00:1733542040.572290   37600 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 4s - 54ms/step - auc: 0.5762 - binary_accuracy: 0.5641 - loss: 0.6755 - precision: 0.2222 - recall: 0.0073 - val_auc: 0.5718 - val_binary_accuracy: 0.5628 - val_loss: 0.6749 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 2/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6045 - binary_accuracy: 0.5633 - loss: 0.6710 - precision: 0.2222 - recall: 0.0073 - val_auc: 0.6002 - val_binary_accuracy: 0.5651 - val_loss: 0.6703 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 3/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6339 - binary_accuracy: 0.5648 - loss: 0.6657 - precision: 0.2222 - recall: 0.0073 - val_auc: 0.6285 - val_binary_accuracy: 0.5651 - val_loss: 0.6659 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 4/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6601 - binary_accuracy: 0.5664 - loss: 0.6604 - precision: 0.2222 - recall: 0.0073 - val_auc: 0.6485 - val_binary_accuracy: 0.5651 - val_loss: 0.6615 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 5/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6850 - binary_accuracy: 0.5641 - loss: 0.6564 - precision: 0.2000 - recall: 0.0055 - val_auc: 0.6715 - val_binary_accuracy: 0.5674 - val_loss: 0.6573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 6/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7069 - binary_accuracy: 0.5680 - loss: 0.6510 - precision: 0.2143 - recall: 0.0055 - val_auc: 0.6946 - val_binary_accuracy: 0.5674 - val_loss: 0.6530 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 7/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7280 - binary_accuracy: 0.5656 - loss: 0.6470 - precision: 0.2143 - recall: 0.0055 - val_auc: 0.7155 - val_binary_accuracy: 0.5674 - val_loss: 0.6488 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 8/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7480 - binary_accuracy: 0.5664 - loss: 0.6423 - precision: 0.1818 - recall: 0.0036 - val_auc: 0.7305 - val_binary_accuracy: 0.5674 - val_loss: 0.6447 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 9/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7662 - binary_accuracy: 0.5711 - loss: 0.6367 - precision: 0.2222 - recall: 0.0037 - val_auc: 0.7472 - val_binary_accuracy: 0.5698 - val_loss: 0.6406 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 10/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7779 - binary_accuracy: 0.5719 - loss: 0.6326 - precision: 0.2222 - recall: 0.0037 - val_auc: 0.7595 - val_binary_accuracy: 0.5698 - val_loss: 0.6366 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 11/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7930 - binary_accuracy: 0.5711 - loss: 0.6283 - precision: 0.2500 - recall: 0.0037 - val_auc: 0.7738 - val_binary_accuracy: 0.5721 - val_loss: 0.6328 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 12/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8027 - binary_accuracy: 0.5672 - loss: 0.6258 - precision: 0.2500 - recall: 0.0036 - val_auc: 0.7856 - val_binary_accuracy: 0.5698 - val_loss: 0.6289 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 13/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8138 - binary_accuracy: 0.5672 - loss: 0.6208 - precision: 0.1250 - recall: 0.0018 - val_auc: 0.7940 - val_binary_accuracy: 0.5698 - val_loss: 0.6251 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 14/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8219 - binary_accuracy: 0.5695 - loss: 0.6169 - precision: 0.3000 - recall: 0.0055 - val_auc: 0.8033 - val_binary_accuracy: 0.5698 - val_loss: 0.6213 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 15/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8318 - binary_accuracy: 0.5727 - loss: 0.6121 - precision: 0.4167 - recall: 0.0092 - val_auc: 0.8145 - val_binary_accuracy: 0.5698 - val_loss: 0.6176 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 16/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8394 - binary_accuracy: 0.5742 - loss: 0.6084 - precision: 0.5333 - recall: 0.0147 - val_auc: 0.8219 - val_binary_accuracy: 0.5791 - val_loss: 0.6140 - val_precision: 0.6667 - val_recall: 0.0219 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 17/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8470 - binary_accuracy: 0.5766 - loss: 0.6044 - precision: 0.6111 - recall: 0.0201 - val_auc: 0.8291 - val_binary_accuracy: 0.5884 - val_loss: 0.6104 - val_precision: 0.8000 - val_recall: 0.0437 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 18/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8533 - binary_accuracy: 0.5938 - loss: 0.6000 - precision: 0.8250 - recall: 0.0604 - val_auc: 0.8345 - val_binary_accuracy: 0.6047 - val_loss: 0.6068 - val_precision: 0.8824 - val_recall: 0.0820 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 19/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8591 - binary_accuracy: 0.6070 - loss: 0.5966 - precision: 0.8143 - recall: 0.1042 - val_auc: 0.8400 - val_binary_accuracy: 0.6140 - val_loss: 0.6032 - val_precision: 0.8400 - val_recall: 0.1148 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 20/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8655 - binary_accuracy: 0.6266 - loss: 0.5923 - precision: 0.8557 - recall: 0.1517 - val_auc: 0.8450 - val_binary_accuracy: 0.6256 - val_loss: 0.5997 - val_precision: 0.8438 - val_recall: 0.1475 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 21/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8686 - binary_accuracy: 0.6422 - loss: 0.5896 - precision: 0.8640 - recall: 0.1967 - val_auc: 0.8486 - val_binary_accuracy: 0.6395 - val_loss: 0.5962 - val_precision: 0.8684 - val_recall: 0.1803 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 22/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8731 - binary_accuracy: 0.6617 - loss: 0.5850 - precision: 0.8800 - recall: 0.2413 - val_auc: 0.8534 - val_binary_accuracy: 0.6605 - val_loss: 0.5927 - val_precision: 0.8776 - val_recall: 0.2350 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 23/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8786 - binary_accuracy: 0.6789 - loss: 0.5806 - precision: 0.8736 - recall: 0.2907 - val_auc: 0.8591 - val_binary_accuracy: 0.6698 - val_loss: 0.5893 - val_precision: 0.9020 - val_recall: 0.2514 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 24/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8815 - binary_accuracy: 0.6875 - loss: 0.5781 - precision: 0.8744 - recall: 0.3169 - val_auc: 0.8619 - val_binary_accuracy: 0.6814 - val_loss: 0.5859 - val_precision: 0.9107 - val_recall: 0.2787 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 25/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8842 - binary_accuracy: 0.7039 - loss: 0.5730 - precision: 0.8848 - recall: 0.3516 - val_auc: 0.8642 - val_binary_accuracy: 0.6884 - val_loss: 0.5826 - val_precision: 0.9153 - val_recall: 0.2951 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 26/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8885 - binary_accuracy: 0.7148 - loss: 0.5690 - precision: 0.8846 - recall: 0.3798 - val_auc: 0.8681 - val_binary_accuracy: 0.7000 - val_loss: 0.5793 - val_precision: 0.9091 - val_recall: 0.3279 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 27/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8919 - binary_accuracy: 0.7203 - loss: 0.5660 - precision: 0.8893 - recall: 0.3960 - val_auc: 0.8699 - val_binary_accuracy: 0.7140 - val_loss: 0.5759 - val_precision: 0.8947 - val_recall: 0.3716 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 28/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8939 - binary_accuracy: 0.7312 - loss: 0.5615 - precision: 0.8915 - recall: 0.4212 - val_auc: 0.8714 - val_binary_accuracy: 0.7233 - val_loss: 0.5726 - val_precision: 0.9000 - val_recall: 0.3934 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 29/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8958 - binary_accuracy: 0.7375 - loss: 0.5577 - precision: 0.8910 - recall: 0.4357 - val_auc: 0.8750 - val_binary_accuracy: 0.7279 - val_loss: 0.5694 - val_precision: 0.8929 - val_recall: 0.4098 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 30/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8994 - binary_accuracy: 0.7445 - loss: 0.5543 - precision: 0.9018 - recall: 0.4526 - val_auc: 0.8764 - val_binary_accuracy: 0.7326 - val_loss: 0.5662 - val_precision: 0.8953 - val_recall: 0.4208 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 31/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9000 - binary_accuracy: 0.7500 - loss: 0.5507 - precision: 0.8924 - recall: 0.4707 - val_auc: 0.8793 - val_binary_accuracy: 0.7395 - val_loss: 0.5629 - val_precision: 0.8989 - val_recall: 0.4372 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 32/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9019 - binary_accuracy: 0.7547 - loss: 0.5474 - precision: 0.9000 - recall: 0.4780 - val_auc: 0.8808 - val_binary_accuracy: 0.7395 - val_loss: 0.5599 - val_precision: 0.8989 - val_recall: 0.4372 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 33/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9067 - binary_accuracy: 0.7625 - loss: 0.5426 - precision: 0.9033 - recall: 0.4963 - val_auc: 0.8827 - val_binary_accuracy: 0.7419 - val_loss: 0.5567 - val_precision: 0.9000 - val_recall: 0.4426 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 34/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9060 - binary_accuracy: 0.7641 - loss: 0.5395 - precision: 0.9013 - recall: 0.5018 - val_auc: 0.8848 - val_binary_accuracy: 0.7465 - val_loss: 0.5537 - val_precision: 0.8936 - val_recall: 0.4590 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 35/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9087 - binary_accuracy: 0.7695 - loss: 0.5351 - precision: 0.9032 - recall: 0.5138 - val_auc: 0.8858 - val_binary_accuracy: 0.7488 - val_loss: 0.5506 - val_precision: 0.8947 - val_recall: 0.4645 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 36/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9084 - binary_accuracy: 0.7734 - loss: 0.5326 - precision: 0.9048 - recall: 0.5229 - val_auc: 0.8879 - val_binary_accuracy: 0.7581 - val_loss: 0.5476 - val_precision: 0.8990 - val_recall: 0.4863 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 37/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9097 - binary_accuracy: 0.7773 - loss: 0.5296 - precision: 0.9068 - recall: 0.5338 - val_auc: 0.8897 - val_binary_accuracy: 0.7628 - val_loss: 0.5446 - val_precision: 0.9010 - val_recall: 0.4973 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 38/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9125 - binary_accuracy: 0.7805 - loss: 0.5252 - precision: 0.9024 - recall: 0.5431 - val_auc: 0.8906 - val_binary_accuracy: 0.7628 - val_loss: 0.5416 - val_precision: 0.8932 - val_recall: 0.5027 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 39/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9125 - binary_accuracy: 0.7828 - loss: 0.5224 - precision: 0.9009 - recall: 0.5505 - val_auc: 0.8923 - val_binary_accuracy: 0.7698 - val_loss: 0.5387 - val_precision: 0.8962 - val_recall: 0.5191 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 40/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9146 - binary_accuracy: 0.7883 - loss: 0.5190 - precision: 0.9035 - recall: 0.5649 - val_auc: 0.8927 - val_binary_accuracy: 0.7674 - val_loss: 0.5357 - val_precision: 0.8879 - val_recall: 0.5191 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 41/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9144 - binary_accuracy: 0.7875 - loss: 0.5166 - precision: 0.8963 - recall: 0.5686 - val_auc: 0.8940 - val_binary_accuracy: 0.7744 - val_loss: 0.5328 - val_precision: 0.8909 - val_recall: 0.5355 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 42/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9160 - binary_accuracy: 0.7867 - loss: 0.5125 - precision: 0.8911 - recall: 0.5696 - val_auc: 0.8954 - val_binary_accuracy: 0.7837 - val_loss: 0.5299 - val_precision: 0.8947 - val_recall: 0.5574 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 43/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9175 - binary_accuracy: 0.7875 - loss: 0.5086 - precision: 0.8889 - recall: 0.5725 - val_auc: 0.8965 - val_binary_accuracy: 0.7837 - val_loss: 0.5270 - val_precision: 0.8947 - val_recall: 0.5574 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 44/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9176 - binary_accuracy: 0.7922 - loss: 0.5057 - precision: 0.8864 - recall: 0.5872 - val_auc: 0.8975 - val_binary_accuracy: 0.7837 - val_loss: 0.5241 - val_precision: 0.8814 - val_recall: 0.5683 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 45/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9198 - binary_accuracy: 0.7969 - loss: 0.5020 - precision: 0.8907 - recall: 0.5971 - val_auc: 0.8985 - val_binary_accuracy: 0.7837 - val_loss: 0.5213 - val_precision: 0.8814 - val_recall: 0.5683 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 46/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9208 - binary_accuracy: 0.8008 - loss: 0.4985 - precision: 0.8901 - recall: 0.6081 - val_auc: 0.8998 - val_binary_accuracy: 0.7837 - val_loss: 0.5184 - val_precision: 0.8814 - val_recall: 0.5683 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 47/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9205 - binary_accuracy: 0.8016 - loss: 0.4963 - precision: 0.8859 - recall: 0.6128 - val_auc: 0.9003 - val_binary_accuracy: 0.7837 - val_loss: 0.5157 - val_precision: 0.8689 - val_recall: 0.5792 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 48/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9216 - binary_accuracy: 0.8070 - loss: 0.4932 - precision: 0.8889 - recall: 0.6277 - val_auc: 0.9012 - val_binary_accuracy: 0.7837 - val_loss: 0.5129 - val_precision: 0.8689 - val_recall: 0.5792 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 49/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9221 - binary_accuracy: 0.8109 - loss: 0.4905 - precision: 0.8903 - recall: 0.6369 - val_auc: 0.9023 - val_binary_accuracy: 0.7884 - val_loss: 0.5102 - val_precision: 0.8710 - val_recall: 0.5902 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 50/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9228 - binary_accuracy: 0.8148 - loss: 0.4872 - precision: 0.8911 - recall: 0.6447 - val_auc: 0.9031 - val_binary_accuracy: 0.7930 - val_loss: 0.5075 - val_precision: 0.8561 - val_recall: 0.6175 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 51/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9234 - binary_accuracy: 0.8195 - loss: 0.4837 - precision: 0.8928 - recall: 0.6557 - val_auc: 0.9041 - val_binary_accuracy: 0.7930 - val_loss: 0.5048 - val_precision: 0.8507 - val_recall: 0.6230 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 52/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9259 - binary_accuracy: 0.8273 - loss: 0.4786 - precision: 0.8968 - recall: 0.6710 - val_auc: 0.9050 - val_binary_accuracy: 0.8000 - val_loss: 0.5021 - val_precision: 0.8540 - val_recall: 0.6393 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 53/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9260 - binary_accuracy: 0.8273 - loss: 0.4762 - precision: 0.8916 - recall: 0.6777 - val_auc: 0.9054 - val_binary_accuracy: 0.7977 - val_loss: 0.4994 - val_precision: 0.8429 - val_recall: 0.6448 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 54/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9252 - binary_accuracy: 0.8289 - loss: 0.4746 - precision: 0.8905 - recall: 0.6837 - val_auc: 0.9068 - val_binary_accuracy: 0.8047 - val_loss: 0.4967 - val_precision: 0.8462 - val_recall: 0.6612 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 55/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9260 - binary_accuracy: 0.8313 - loss: 0.4713 - precision: 0.8910 - recall: 0.6886 - val_auc: 0.9065 - val_binary_accuracy: 0.8047 - val_loss: 0.4941 - val_precision: 0.8462 - val_recall: 0.6612 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 56/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9270 - binary_accuracy: 0.8352 - loss: 0.4681 - precision: 0.8907 - recall: 0.7002 - val_auc: 0.9075 - val_binary_accuracy: 0.8093 - val_loss: 0.4914 - val_precision: 0.8483 - val_recall: 0.6721 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 57/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9280 - binary_accuracy: 0.8359 - loss: 0.4643 - precision: 0.8874 - recall: 0.7057 - val_auc: 0.9079 - val_binary_accuracy: 0.8186 - val_loss: 0.4888 - val_precision: 0.8523 - val_recall: 0.6940 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 58/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9276 - binary_accuracy: 0.8391 - loss: 0.4622 - precision: 0.8861 - recall: 0.7138 - val_auc: 0.9088 - val_binary_accuracy: 0.8209 - val_loss: 0.4862 - val_precision: 0.8533 - val_recall: 0.6995 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 59/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9281 - binary_accuracy: 0.8398 - loss: 0.4585 - precision: 0.8809 - recall: 0.7206 - val_auc: 0.9096 - val_binary_accuracy: 0.8279 - val_loss: 0.4836 - val_precision: 0.8562 - val_recall: 0.7158 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 60/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9296 - binary_accuracy: 0.8422 - loss: 0.4559 - precision: 0.8859 - recall: 0.7239 - val_auc: 0.9100 - val_binary_accuracy: 0.8302 - val_loss: 0.4810 - val_precision: 0.8571 - val_recall: 0.7213 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 61/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9291 - binary_accuracy: 0.8453 - loss: 0.4537 - precision: 0.8835 - recall: 0.7349 - val_auc: 0.9102 - val_binary_accuracy: 0.8326 - val_loss: 0.4785 - val_precision: 0.8581 - val_recall: 0.7268 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 62/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9296 - binary_accuracy: 0.8453 - loss: 0.4506 - precision: 0.8816 - recall: 0.7363 - val_auc: 0.9110 - val_binary_accuracy: 0.8349 - val_loss: 0.4760 - val_precision: 0.8590 - val_recall: 0.7322 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 63/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9303 - binary_accuracy: 0.8461 - loss: 0.4472 - precision: 0.8769 - recall: 0.7436 - val_auc: 0.9115 - val_binary_accuracy: 0.8326 - val_loss: 0.4735 - val_precision: 0.8535 - val_recall: 0.7322 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 64/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9307 - binary_accuracy: 0.8484 - loss: 0.4442 - precision: 0.8790 - recall: 0.7468 - val_auc: 0.9122 - val_binary_accuracy: 0.8326 - val_loss: 0.4710 - val_precision: 0.8491 - val_recall: 0.7377 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 65/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9307 - binary_accuracy: 0.8523 - loss: 0.4425 - precision: 0.8809 - recall: 0.7569 - val_auc: 0.9127 - val_binary_accuracy: 0.8326 - val_loss: 0.4686 - val_precision: 0.8491 - val_recall: 0.7377 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 66/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9308 - binary_accuracy: 0.8562 - loss: 0.4396 - precision: 0.8800 - recall: 0.7670 - val_auc: 0.9128 - val_binary_accuracy: 0.8349 - val_loss: 0.4662 - val_precision: 0.8500 - val_recall: 0.7432 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 67/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9312 - binary_accuracy: 0.8578 - loss: 0.4367 - precision: 0.8808 - recall: 0.7711 - val_auc: 0.9137 - val_binary_accuracy: 0.8349 - val_loss: 0.4638 - val_precision: 0.8500 - val_recall: 0.7432 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 68/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9310 - binary_accuracy: 0.8578 - loss: 0.4351 - precision: 0.8813 - recall: 0.7719 - val_auc: 0.9138 - val_binary_accuracy: 0.8372 - val_loss: 0.4615 - val_precision: 0.8509 - val_recall: 0.7486 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 69/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9321 - binary_accuracy: 0.8617 - loss: 0.4311 - precision: 0.8849 - recall: 0.7761 - val_auc: 0.9143 - val_binary_accuracy: 0.8395 - val_loss: 0.4591 - val_precision: 0.8519 - val_recall: 0.7541 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 70/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9314 - binary_accuracy: 0.8602 - loss: 0.4299 - precision: 0.8804 - recall: 0.7792 - val_auc: 0.9142 - val_binary_accuracy: 0.8349 - val_loss: 0.4568 - val_precision: 0.8415 - val_recall: 0.7541 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 71/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9317 - binary_accuracy: 0.8625 - loss: 0.4268 - precision: 0.8809 - recall: 0.7843 - val_auc: 0.9145 - val_binary_accuracy: 0.8326 - val_loss: 0.4545 - val_precision: 0.8364 - val_recall: 0.7541 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 72/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9316 - binary_accuracy: 0.8648 - loss: 0.4247 - precision: 0.8814 - recall: 0.7894 - val_auc: 0.9149 - val_binary_accuracy: 0.8349 - val_loss: 0.4523 - val_precision: 0.8373 - val_recall: 0.7596 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 73/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9324 - binary_accuracy: 0.8680 - loss: 0.4219 - precision: 0.8828 - recall: 0.7974 - val_auc: 0.9151 - val_binary_accuracy: 0.8442 - val_loss: 0.4501 - val_precision: 0.8412 - val_recall: 0.7814 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 74/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9320 - binary_accuracy: 0.8656 - loss: 0.4187 - precision: 0.8776 - recall: 0.7934 - val_auc: 0.9150 - val_binary_accuracy: 0.8442 - val_loss: 0.4479 - val_precision: 0.8412 - val_recall: 0.7814 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 75/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9333 - binary_accuracy: 0.8680 - loss: 0.4163 - precision: 0.8810 - recall: 0.7989 - val_auc: 0.9156 - val_binary_accuracy: 0.8442 - val_loss: 0.4458 - val_precision: 0.8412 - val_recall: 0.7814 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 76/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9326 - binary_accuracy: 0.8672 - loss: 0.4145 - precision: 0.8790 - recall: 0.7985 - val_auc: 0.9160 - val_binary_accuracy: 0.8442 - val_loss: 0.4436 - val_precision: 0.8412 - val_recall: 0.7814 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 77/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9328 - binary_accuracy: 0.8687 - loss: 0.4126 - precision: 0.8800 - recall: 0.8029 - val_auc: 0.9160 - val_binary_accuracy: 0.8442 - val_loss: 0.4415 - val_precision: 0.8412 - val_recall: 0.7814 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 78/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9329 - binary_accuracy: 0.8680 - loss: 0.4104 - precision: 0.8782 - recall: 0.8029 - val_auc: 0.9158 - val_binary_accuracy: 0.8465 - val_loss: 0.4394 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 79/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9338 - binary_accuracy: 0.8680 - loss: 0.4075 - precision: 0.8780 - recall: 0.8026 - val_auc: 0.9163 - val_binary_accuracy: 0.8465 - val_loss: 0.4374 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 80/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9329 - binary_accuracy: 0.8672 - loss: 0.4064 - precision: 0.8765 - recall: 0.8029 - val_auc: 0.9166 - val_binary_accuracy: 0.8465 - val_loss: 0.4355 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 81/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9338 - binary_accuracy: 0.8687 - loss: 0.4024 - precision: 0.8760 - recall: 0.8051 - val_auc: 0.9165 - val_binary_accuracy: 0.8465 - val_loss: 0.4335 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 82/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9342 - binary_accuracy: 0.8711 - loss: 0.4005 - precision: 0.8787 - recall: 0.8095 - val_auc: 0.9170 - val_binary_accuracy: 0.8465 - val_loss: 0.4316 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 83/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9337 - binary_accuracy: 0.8695 - loss: 0.3994 - precision: 0.8755 - recall: 0.8099 - val_auc: 0.9170 - val_binary_accuracy: 0.8465 - val_loss: 0.4298 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 84/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9341 - binary_accuracy: 0.8711 - loss: 0.3962 - precision: 0.8755 - recall: 0.8128 - val_auc: 0.9172 - val_binary_accuracy: 0.8442 - val_loss: 0.4278 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 85/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9348 - binary_accuracy: 0.8719 - loss: 0.3933 - precision: 0.8772 - recall: 0.8128 - val_auc: 0.9177 - val_binary_accuracy: 0.8442 - val_loss: 0.4260 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 86/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9343 - binary_accuracy: 0.8703 - loss: 0.3917 - precision: 0.8752 - recall: 0.8110 - val_auc: 0.9177 - val_binary_accuracy: 0.8419 - val_loss: 0.4242 - val_precision: 0.8324 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 87/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9342 - binary_accuracy: 0.8703 - loss: 0.3911 - precision: 0.8772 - recall: 0.8099 - val_auc: 0.9178 - val_binary_accuracy: 0.8419 - val_loss: 0.4224 - val_precision: 0.8324 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 88/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9346 - binary_accuracy: 0.8703 - loss: 0.3880 - precision: 0.8755 - recall: 0.8114 - val_auc: 0.9181 - val_binary_accuracy: 0.8419 - val_loss: 0.4207 - val_precision: 0.8324 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 89/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9344 - binary_accuracy: 0.8680 - loss: 0.3866 - precision: 0.8703 - recall: 0.8114 - val_auc: 0.9183 - val_binary_accuracy: 0.8419 - val_loss: 0.4190 - val_precision: 0.8324 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 90/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9344 - binary_accuracy: 0.8687 - loss: 0.3851 - precision: 0.8703 - recall: 0.8128 - val_auc: 0.9189 - val_binary_accuracy: 0.8419 - val_loss: 0.4173 - val_precision: 0.8324 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 91/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9346 - binary_accuracy: 0.8687 - loss: 0.3829 - precision: 0.8689 - recall: 0.8147 - val_auc: 0.9189 - val_binary_accuracy: 0.8419 - val_loss: 0.4157 - val_precision: 0.8324 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 92/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9346 - binary_accuracy: 0.8687 - loss: 0.3811 - precision: 0.8677 - recall: 0.8168 - val_auc: 0.9189 - val_binary_accuracy: 0.8395 - val_loss: 0.4141 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 93/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9347 - binary_accuracy: 0.8695 - loss: 0.3800 - precision: 0.8671 - recall: 0.8212 - val_auc: 0.9190 - val_binary_accuracy: 0.8395 - val_loss: 0.4126 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 94/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8711 - loss: 0.3772 - precision: 0.8671 - recall: 0.8242 - val_auc: 0.9191 - val_binary_accuracy: 0.8442 - val_loss: 0.4111 - val_precision: 0.8295 - val_recall: 0.7978 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 95/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9358 - binary_accuracy: 0.8711 - loss: 0.3749 - precision: 0.8673 - recall: 0.8245 - val_auc: 0.9192 - val_binary_accuracy: 0.8442 - val_loss: 0.4095 - val_precision: 0.8295 - val_recall: 0.7978 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 96/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9363 - binary_accuracy: 0.8711 - loss: 0.3726 - precision: 0.8662 - recall: 0.8266 - val_auc: 0.9194 - val_binary_accuracy: 0.8465 - val_loss: 0.4081 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 97/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9356 - binary_accuracy: 0.8711 - loss: 0.3722 - precision: 0.8648 - recall: 0.8285 - val_auc: 0.9197 - val_binary_accuracy: 0.8465 - val_loss: 0.4067 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 98/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8695 - loss: 0.3697 - precision: 0.8640 - recall: 0.8245 - val_auc: 0.9198 - val_binary_accuracy: 0.8465 - val_loss: 0.4052 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 99/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9362 - binary_accuracy: 0.8695 - loss: 0.3680 - precision: 0.8640 - recall: 0.8245 - val_auc: 0.9199 - val_binary_accuracy: 0.8465 - val_loss: 0.4039 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 100/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9358 - binary_accuracy: 0.8695 - loss: 0.3678 - precision: 0.8631 - recall: 0.8270 - val_auc: 0.9199 - val_binary_accuracy: 0.8465 - val_loss: 0.4026 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 101/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9359 - binary_accuracy: 0.8687 - loss: 0.3656 - precision: 0.8590 - recall: 0.8275 - val_auc: 0.9202 - val_binary_accuracy: 0.8465 - val_loss: 0.4013 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 102/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9361 - binary_accuracy: 0.8680 - loss: 0.3644 - precision: 0.8593 - recall: 0.8263 - val_auc: 0.9202 - val_binary_accuracy: 0.8465 - val_loss: 0.4000 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 103/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9365 - binary_accuracy: 0.8672 - loss: 0.3617 - precision: 0.8571 - recall: 0.8257 - val_auc: 0.9204 - val_binary_accuracy: 0.8465 - val_loss: 0.3987 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 104/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9366 - binary_accuracy: 0.8672 - loss: 0.3609 - precision: 0.8561 - recall: 0.8278 - val_auc: 0.9203 - val_binary_accuracy: 0.8465 - val_loss: 0.3975 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 105/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8664 - loss: 0.3600 - precision: 0.8544 - recall: 0.8278 - val_auc: 0.9204 - val_binary_accuracy: 0.8442 - val_loss: 0.3963 - val_precision: 0.8295 - val_recall: 0.7978 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 106/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9367 - binary_accuracy: 0.8672 - loss: 0.3584 - precision: 0.8553 - recall: 0.8303 - val_auc: 0.9208 - val_binary_accuracy: 0.8442 - val_loss: 0.3952 - val_precision: 0.8295 - val_recall: 0.7978 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 107/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9374 - binary_accuracy: 0.8695 - loss: 0.3556 - precision: 0.8566 - recall: 0.8330 - val_auc: 0.9208 - val_binary_accuracy: 0.8465 - val_loss: 0.3940 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 108/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9375 - binary_accuracy: 0.8695 - loss: 0.3544 - precision: 0.8558 - recall: 0.8355 - val_auc: 0.9208 - val_binary_accuracy: 0.8465 - val_loss: 0.3929 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 109/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9375 - binary_accuracy: 0.8695 - loss: 0.3531 - precision: 0.8555 - recall: 0.8352 - val_auc: 0.9208 - val_binary_accuracy: 0.8465 - val_loss: 0.3918 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 110/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9383 - binary_accuracy: 0.8703 - loss: 0.3513 - precision: 0.8590 - recall: 0.8339 - val_auc: 0.9209 - val_binary_accuracy: 0.8442 - val_loss: 0.3908 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 111/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8695 - loss: 0.3519 - precision: 0.8561 - recall: 0.8358 - val_auc: 0.9210 - val_binary_accuracy: 0.8465 - val_loss: 0.3897 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 112/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9376 - binary_accuracy: 0.8695 - loss: 0.3497 - precision: 0.8539 - recall: 0.8367 - val_auc: 0.9212 - val_binary_accuracy: 0.8465 - val_loss: 0.3887 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 113/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8687 - loss: 0.3487 - precision: 0.8529 - recall: 0.8373 - val_auc: 0.9212 - val_binary_accuracy: 0.8465 - val_loss: 0.3878 - val_precision: 0.8268 - val_recall: 0.8087 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 114/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8687 - loss: 0.3478 - precision: 0.8529 - recall: 0.8373 - val_auc: 0.9214 - val_binary_accuracy: 0.8442 - val_loss: 0.3868 - val_precision: 0.8222 - val_recall: 0.8087 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 115/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9375 - binary_accuracy: 0.8680 - loss: 0.3470 - precision: 0.8513 - recall: 0.8373 - val_auc: 0.9215 - val_binary_accuracy: 0.8442 - val_loss: 0.3859 - val_precision: 0.8222 - val_recall: 0.8087 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 116/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9375 - binary_accuracy: 0.8680 - loss: 0.3456 - precision: 0.8502 - recall: 0.8361 - val_auc: 0.9216 - val_binary_accuracy: 0.8465 - val_loss: 0.3851 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 117/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9381 - binary_accuracy: 0.8687 - loss: 0.3439 - precision: 0.8516 - recall: 0.8391 - val_auc: 0.9218 - val_binary_accuracy: 0.8442 - val_loss: 0.3843 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 118/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8680 - loss: 0.3431 - precision: 0.8513 - recall: 0.8373 - val_auc: 0.9216 - val_binary_accuracy: 0.8442 - val_loss: 0.3834 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 119/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9385 - binary_accuracy: 0.8680 - loss: 0.3416 - precision: 0.8500 - recall: 0.8391 - val_auc: 0.9219 - val_binary_accuracy: 0.8442 - val_loss: 0.3827 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 120/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9384 - binary_accuracy: 0.8680 - loss: 0.3409 - precision: 0.8497 - recall: 0.8388 - val_auc: 0.9220 - val_binary_accuracy: 0.8442 - val_loss: 0.3819 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 121/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9382 - binary_accuracy: 0.8680 - loss: 0.3406 - precision: 0.8500 - recall: 0.8391 - val_auc: 0.9220 - val_binary_accuracy: 0.8442 - val_loss: 0.3812 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 122/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8687 - loss: 0.3389 - precision: 0.8503 - recall: 0.8410 - val_auc: 0.9217 - val_binary_accuracy: 0.8442 - val_loss: 0.3805 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 123/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8695 - loss: 0.3380 - precision: 0.8521 - recall: 0.8412 - val_auc: 0.9219 - val_binary_accuracy: 0.8442 - val_loss: 0.3799 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 124/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9389 - binary_accuracy: 0.8687 - loss: 0.3368 - precision: 0.8497 - recall: 0.8404 - val_auc: 0.9218 - val_binary_accuracy: 0.8442 - val_loss: 0.3792 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 125/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9383 - binary_accuracy: 0.8680 - loss: 0.3372 - precision: 0.8484 - recall: 0.8407 - val_auc: 0.9218 - val_binary_accuracy: 0.8442 - val_loss: 0.3785 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 126/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8687 - loss: 0.3354 - precision: 0.8506 - recall: 0.8412 - val_auc: 0.9215 - val_binary_accuracy: 0.8442 - val_loss: 0.3779 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 127/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8680 - loss: 0.3347 - precision: 0.8456 - recall: 0.8440 - val_auc: 0.9217 - val_binary_accuracy: 0.8442 - val_loss: 0.3774 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 128/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9397 - binary_accuracy: 0.8703 - loss: 0.3329 - precision: 0.8508 - recall: 0.8446 - val_auc: 0.9217 - val_binary_accuracy: 0.8442 - val_loss: 0.3768 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 129/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8687 - loss: 0.3331 - precision: 0.8487 - recall: 0.8425 - val_auc: 0.9219 - val_binary_accuracy: 0.8442 - val_loss: 0.3762 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 130/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8695 - loss: 0.3296 - precision: 0.8490 - recall: 0.8443 - val_auc: 0.9220 - val_binary_accuracy: 0.8442 - val_loss: 0.3757 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 131/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8680 - loss: 0.3313 - precision: 0.8456 - recall: 0.8440 - val_auc: 0.9222 - val_binary_accuracy: 0.8442 - val_loss: 0.3752 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 132/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9389 - binary_accuracy: 0.8680 - loss: 0.3319 - precision: 0.8474 - recall: 0.8428 - val_auc: 0.9221 - val_binary_accuracy: 0.8442 - val_loss: 0.3747 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 133/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8672 - loss: 0.3313 - precision: 0.8462 - recall: 0.8431 - val_auc: 0.9222 - val_binary_accuracy: 0.8442 - val_loss: 0.3743 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 134/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9398 - binary_accuracy: 0.8680 - loss: 0.3289 - precision: 0.8474 - recall: 0.8428 - val_auc: 0.9224 - val_binary_accuracy: 0.8442 - val_loss: 0.3738 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 135/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8672 - loss: 0.3304 - precision: 0.8464 - recall: 0.8434 - val_auc: 0.9225 - val_binary_accuracy: 0.8442 - val_loss: 0.3733 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 136/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9394 - binary_accuracy: 0.8680 - loss: 0.3290 - precision: 0.8474 - recall: 0.8428 - val_auc: 0.9226 - val_binary_accuracy: 0.8442 - val_loss: 0.3729 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 137/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9405 - binary_accuracy: 0.8687 - loss: 0.3266 - precision: 0.8471 - recall: 0.8440 - val_auc: 0.9228 - val_binary_accuracy: 0.8442 - val_loss: 0.3725 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 138/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9395 - binary_accuracy: 0.8672 - loss: 0.3278 - precision: 0.8456 - recall: 0.8425 - val_auc: 0.9228 - val_binary_accuracy: 0.8442 - val_loss: 0.3721 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 139/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9403 - binary_accuracy: 0.8680 - loss: 0.3255 - precision: 0.8456 - recall: 0.8440 - val_auc: 0.9227 - val_binary_accuracy: 0.8442 - val_loss: 0.3717 - val_precision: 0.8187 - val_recall: 0.8142 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 140/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8672 - loss: 0.3268 - precision: 0.8453 - recall: 0.8422 - val_auc: 0.9230 - val_binary_accuracy: 0.8465 - val_loss: 0.3713 - val_precision: 0.8197 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 141/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9401 - binary_accuracy: 0.8687 - loss: 0.3254 - precision: 0.8474 - recall: 0.8443 - val_auc: 0.9232 - val_binary_accuracy: 0.8465 - val_loss: 0.3710 - val_precision: 0.8197 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 142/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9399 - binary_accuracy: 0.8687 - loss: 0.3258 - precision: 0.8493 - recall: 0.8431 - val_auc: 0.9231 - val_binary_accuracy: 0.8465 - val_loss: 0.3706 - val_precision: 0.8197 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 143/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9401 - binary_accuracy: 0.8687 - loss: 0.3247 - precision: 0.8487 - recall: 0.8425 - val_auc: 0.9233 - val_binary_accuracy: 0.8465 - val_loss: 0.3703 - val_precision: 0.8197 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 144/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9400 - binary_accuracy: 0.8680 - loss: 0.3247 - precision: 0.8471 - recall: 0.8425 - val_auc: 0.9234 - val_binary_accuracy: 0.8465 - val_loss: 0.3699 - val_precision: 0.8197 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 145/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8703 - loss: 0.3220 - precision: 0.8493 - recall: 0.8462 - val_auc: 0.9233 - val_binary_accuracy: 0.8488 - val_loss: 0.3696 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 146/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9401 - binary_accuracy: 0.8687 - loss: 0.3237 - precision: 0.8474 - recall: 0.8443 - val_auc: 0.9234 - val_binary_accuracy: 0.8488 - val_loss: 0.3693 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 147/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8703 - loss: 0.3193 - precision: 0.8493 - recall: 0.8462 - val_auc: 0.9235 - val_binary_accuracy: 0.8465 - val_loss: 0.3691 - val_precision: 0.8197 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 148/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8695 - loss: 0.3211 - precision: 0.8503 - recall: 0.8425 - val_auc: 0.9234 - val_binary_accuracy: 0.8488 - val_loss: 0.3688 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 149/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9404 - binary_accuracy: 0.8680 - loss: 0.3217 - precision: 0.8469 - recall: 0.8422 - val_auc: 0.9236 - val_binary_accuracy: 0.8488 - val_loss: 0.3685 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 150/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9403 - binary_accuracy: 0.8687 - loss: 0.3219 - precision: 0.8474 - recall: 0.8443 - val_auc: 0.9236 - val_binary_accuracy: 0.8488 - val_loss: 0.3682 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 151/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8695 - loss: 0.3196 - precision: 0.8480 - recall: 0.8464 - val_auc: 0.9236 - val_binary_accuracy: 0.8488 - val_loss: 0.3680 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 152/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8687 - loss: 0.3197 - precision: 0.8471 - recall: 0.8440 - val_auc: 0.9238 - val_binary_accuracy: 0.8488 - val_loss: 0.3677 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 153/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9405 - binary_accuracy: 0.8687 - loss: 0.3209 - precision: 0.8490 - recall: 0.8428 - val_auc: 0.9238 - val_binary_accuracy: 0.8488 - val_loss: 0.3675 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 154/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9409 - binary_accuracy: 0.8680 - loss: 0.3194 - precision: 0.8459 - recall: 0.8443 - val_auc: 0.9239 - val_binary_accuracy: 0.8488 - val_loss: 0.3673 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 155/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9405 - binary_accuracy: 0.8680 - loss: 0.3198 - precision: 0.8466 - recall: 0.8419 - val_auc: 0.9239 - val_binary_accuracy: 0.8488 - val_loss: 0.3671 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 156/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8687 - loss: 0.3183 - precision: 0.8484 - recall: 0.8422 - val_auc: 0.9239 - val_binary_accuracy: 0.8488 - val_loss: 0.3669 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 157/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8711 - loss: 0.3173 - precision: 0.8527 - recall: 0.8449 - val_auc: 0.9239 - val_binary_accuracy: 0.8512 - val_loss: 0.3667 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 158/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8687 - loss: 0.3186 - precision: 0.8484 - recall: 0.8422 - val_auc: 0.9239 - val_binary_accuracy: 0.8512 - val_loss: 0.3665 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 159/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8703 - loss: 0.3165 - precision: 0.8480 - recall: 0.8480 - val_auc: 0.9238 - val_binary_accuracy: 0.8512 - val_loss: 0.3663 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 160/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8695 - loss: 0.3175 - precision: 0.8508 - recall: 0.8431 - val_auc: 0.9237 - val_binary_accuracy: 0.8512 - val_loss: 0.3662 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 161/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8687 - loss: 0.3171 - precision: 0.8490 - recall: 0.8428 - val_auc: 0.9236 - val_binary_accuracy: 0.8512 - val_loss: 0.3660 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 162/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8687 - loss: 0.3171 - precision: 0.8483 - recall: 0.8452 - val_auc: 0.9236 - val_binary_accuracy: 0.8512 - val_loss: 0.3658 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 163/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8680 - loss: 0.3178 - precision: 0.8464 - recall: 0.8449 - val_auc: 0.9236 - val_binary_accuracy: 0.8512 - val_loss: 0.3657 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 164/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8695 - loss: 0.3158 - precision: 0.8459 - recall: 0.8474 - val_auc: 0.9237 - val_binary_accuracy: 0.8512 - val_loss: 0.3656 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 165/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8687 - loss: 0.3165 - precision: 0.8464 - recall: 0.8464 - val_auc: 0.9237 - val_binary_accuracy: 0.8512 - val_loss: 0.3654 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 166/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8687 - loss: 0.3158 - precision: 0.8464 - recall: 0.8464 - val_auc: 0.9238 - val_binary_accuracy: 0.8512 - val_loss: 0.3652 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 167/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8695 - loss: 0.3142 - precision: 0.8446 - recall: 0.8493 - val_auc: 0.9238 - val_binary_accuracy: 0.8512 - val_loss: 0.3651 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 168/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8680 - loss: 0.3162 - precision: 0.8449 - recall: 0.8464 - val_auc: 0.9237 - val_binary_accuracy: 0.8512 - val_loss: 0.3649 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 169/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8695 - loss: 0.3145 - precision: 0.8474 - recall: 0.8459 - val_auc: 0.9238 - val_binary_accuracy: 0.8512 - val_loss: 0.3649 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 170/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8680 - loss: 0.3159 - precision: 0.8457 - recall: 0.8473 - val_auc: 0.9240 - val_binary_accuracy: 0.8512 - val_loss: 0.3647 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 171/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8687 - loss: 0.3159 - precision: 0.8459 - recall: 0.8459 - val_auc: 0.9239 - val_binary_accuracy: 0.8512 - val_loss: 0.3646 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 172/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9433 - binary_accuracy: 0.8719 - loss: 0.3115 - precision: 0.8511 - recall: 0.8480 - val_auc: 0.9238 - val_binary_accuracy: 0.8512 - val_loss: 0.3645 - val_precision: 0.8216 - val_recall: 0.8306 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 173/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8695 - loss: 0.3146 - precision: 0.8462 - recall: 0.8477 - val_auc: 0.9239 - val_binary_accuracy: 0.8488 - val_loss: 0.3644 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 174/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8703 - loss: 0.3128 - precision: 0.8493 - recall: 0.8462 - val_auc: 0.9239 - val_binary_accuracy: 0.8488 - val_loss: 0.3643 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 175/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9431 - binary_accuracy: 0.8703 - loss: 0.3116 - precision: 0.8473 - recall: 0.8504 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3642 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 176/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8703 - loss: 0.3135 - precision: 0.8477 - recall: 0.8477 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3641 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 177/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8695 - loss: 0.3145 - precision: 0.8474 - recall: 0.8459 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3640 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 178/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8703 - loss: 0.3148 - precision: 0.8488 - recall: 0.8488 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3639 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 179/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8711 - loss: 0.3139 - precision: 0.8493 - recall: 0.8477 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3638 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 180/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8719 - loss: 0.3127 - precision: 0.8519 - recall: 0.8488 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3637 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 181/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8719 - loss: 0.3139 - precision: 0.8498 - recall: 0.8498 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3636 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 182/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8719 - loss: 0.3126 - precision: 0.8495 - recall: 0.8495 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3635 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 183/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8711 - loss: 0.3133 - precision: 0.8498 - recall: 0.8483 - val_auc: 0.9242 - val_binary_accuracy: 0.8488 - val_loss: 0.3634 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 184/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8719 - loss: 0.3118 - precision: 0.8504 - recall: 0.8504 - val_auc: 0.9242 - val_binary_accuracy: 0.8488 - val_loss: 0.3633 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 185/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8727 - loss: 0.3122 - precision: 0.8532 - recall: 0.8485 - val_auc: 0.9241 - val_binary_accuracy: 0.8488 - val_loss: 0.3633 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 186/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8727 - loss: 0.3123 - precision: 0.8519 - recall: 0.8504 - val_auc: 0.9243 - val_binary_accuracy: 0.8488 - val_loss: 0.3631 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 187/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8727 - loss: 0.3124 - precision: 0.8519 - recall: 0.8504 - val_auc: 0.9244 - val_binary_accuracy: 0.8488 - val_loss: 0.3631 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 188/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8727 - loss: 0.3124 - precision: 0.8516 - recall: 0.8501 - val_auc: 0.9244 - val_binary_accuracy: 0.8488 - val_loss: 0.3630 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 189/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8742 - loss: 0.3107 - precision: 0.8532 - recall: 0.8516 - val_auc: 0.9244 - val_binary_accuracy: 0.8488 - val_loss: 0.3629 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 190/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8742 - loss: 0.3106 - precision: 0.8550 - recall: 0.8504 - val_auc: 0.9245 - val_binary_accuracy: 0.8488 - val_loss: 0.3628 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 191/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8734 - loss: 0.3117 - precision: 0.8516 - recall: 0.8516 - val_auc: 0.9243 - val_binary_accuracy: 0.8512 - val_loss: 0.3627 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 192/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8734 - loss: 0.3116 - precision: 0.8516 - recall: 0.8516 - val_auc: 0.9245 - val_binary_accuracy: 0.8512 - val_loss: 0.3626 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 193/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8727 - loss: 0.3120 - precision: 0.8516 - recall: 0.8501 - val_auc: 0.9245 - val_binary_accuracy: 0.8512 - val_loss: 0.3625 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 194/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8734 - loss: 0.3102 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9245 - val_binary_accuracy: 0.8512 - val_loss: 0.3625 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 195/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8734 - loss: 0.3107 - precision: 0.8535 - recall: 0.8504 - val_auc: 0.9246 - val_binary_accuracy: 0.8512 - val_loss: 0.3624 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 196/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9437 - binary_accuracy: 0.8734 - loss: 0.3087 - precision: 0.8516 - recall: 0.8516 - val_auc: 0.9248 - val_binary_accuracy: 0.8512 - val_loss: 0.3623 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 197/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9438 - binary_accuracy: 0.8734 - loss: 0.3087 - precision: 0.8516 - recall: 0.8516 - val_auc: 0.9248 - val_binary_accuracy: 0.8512 - val_loss: 0.3623 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 198/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8727 - loss: 0.3115 - precision: 0.8516 - recall: 0.8501 - val_auc: 0.9248 - val_binary_accuracy: 0.8512 - val_loss: 0.3621 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 199/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8742 - loss: 0.3089 - precision: 0.8535 - recall: 0.8519 - val_auc: 0.9248 - val_binary_accuracy: 0.8512 - val_loss: 0.3621 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 200/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8727 - loss: 0.3111 - precision: 0.8516 - recall: 0.8501 - val_auc: 0.9246 - val_binary_accuracy: 0.8488 - val_loss: 0.3620 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 201/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9449 - binary_accuracy: 0.8758 - loss: 0.3049 - precision: 0.8522 - recall: 0.8569 - val_auc: 0.9247 - val_binary_accuracy: 0.8488 - val_loss: 0.3619 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 202/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8734 - loss: 0.3109 - precision: 0.8527 - recall: 0.8527 - val_auc: 0.9247 - val_binary_accuracy: 0.8488 - val_loss: 0.3619 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 203/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8758 - loss: 0.3072 - precision: 0.8553 - recall: 0.8537 - val_auc: 0.9247 - val_binary_accuracy: 0.8488 - val_loss: 0.3618 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 204/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8742 - loss: 0.3087 - precision: 0.8522 - recall: 0.8537 - val_auc: 0.9248 - val_binary_accuracy: 0.8488 - val_loss: 0.3617 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 205/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9431 - binary_accuracy: 0.8742 - loss: 0.3101 - precision: 0.8535 - recall: 0.8519 - val_auc: 0.9249 - val_binary_accuracy: 0.8488 - val_loss: 0.3617 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 206/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8734 - loss: 0.3102 - precision: 0.8516 - recall: 0.8516 - val_auc: 0.9248 - val_binary_accuracy: 0.8488 - val_loss: 0.3616 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 207/300                                          \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9431 - binary_accuracy: 0.8742 - loss: 0.3103 - precision: 0.8537 - recall: 0.8522 - val_auc: 0.9248 - val_binary_accuracy: 0.8488 - val_loss: 0.3616 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 208/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8750 - loss: 0.3098 - precision: 0.8537 - recall: 0.8537 - val_auc: 0.9249 - val_binary_accuracy: 0.8488 - val_loss: 0.3615 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 209/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8742 - loss: 0.3094 - precision: 0.8529 - recall: 0.8514 - val_auc: 0.9249 - val_binary_accuracy: 0.8488 - val_loss: 0.3614 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 210/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8734 - loss: 0.3097 - precision: 0.8519 - recall: 0.8519 - val_auc: 0.9249 - val_binary_accuracy: 0.8488 - val_loss: 0.3613 - val_precision: 0.8242 - val_recall: 0.8197 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 211/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8750 - loss: 0.3070 - precision: 0.8540 - recall: 0.8540 - val_auc: 0.9250 - val_binary_accuracy: 0.8512 - val_loss: 0.3612 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 212/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9439 - binary_accuracy: 0.8766 - loss: 0.3076 - precision: 0.8574 - recall: 0.8543 - val_auc: 0.9249 - val_binary_accuracy: 0.8512 - val_loss: 0.3611 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 213/300                                          \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9447 - binary_accuracy: 0.8766 - loss: 0.3058 - precision: 0.8550 - recall: 0.8550 - val_auc: 0.9250 - val_binary_accuracy: 0.8535 - val_loss: 0.3612 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 214/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9437 - binary_accuracy: 0.8750 - loss: 0.3085 - precision: 0.8548 - recall: 0.8516 - val_auc: 0.9250 - val_binary_accuracy: 0.8535 - val_loss: 0.3611 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 215/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8750 - loss: 0.3083 - precision: 0.8540 - recall: 0.8540 - val_auc: 0.9251 - val_binary_accuracy: 0.8535 - val_loss: 0.3610 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 216/300                                          \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9444 - binary_accuracy: 0.8766 - loss: 0.3066 - precision: 0.8571 - recall: 0.8540 - val_auc: 0.9250 - val_binary_accuracy: 0.8535 - val_loss: 0.3610 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 217/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9435 - binary_accuracy: 0.8742 - loss: 0.3086 - precision: 0.8537 - recall: 0.8522 - val_auc: 0.9250 - val_binary_accuracy: 0.8535 - val_loss: 0.3609 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 218/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8742 - loss: 0.3088 - precision: 0.8529 - recall: 0.8514 - val_auc: 0.9250 - val_binary_accuracy: 0.8535 - val_loss: 0.3609 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 219/300                                          \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9432 - binary_accuracy: 0.8734 - loss: 0.3095 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9251 - val_binary_accuracy: 0.8535 - val_loss: 0.3609 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 220/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8734 - loss: 0.3087 - precision: 0.8524 - recall: 0.8493 - val_auc: 0.9250 - val_binary_accuracy: 0.8535 - val_loss: 0.3607 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 221/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8734 - loss: 0.3084 - precision: 0.8532 - recall: 0.8501 - val_auc: 0.9250 - val_binary_accuracy: 0.8535 - val_loss: 0.3607 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 222/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8750 - loss: 0.3052 - precision: 0.8553 - recall: 0.8522 - val_auc: 0.9251 - val_binary_accuracy: 0.8535 - val_loss: 0.3606 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 223/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9435 - binary_accuracy: 0.8734 - loss: 0.3087 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9252 - val_binary_accuracy: 0.8535 - val_loss: 0.3606 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 224/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9437 - binary_accuracy: 0.8734 - loss: 0.3080 - precision: 0.8535 - recall: 0.8504 - val_auc: 0.9253 - val_binary_accuracy: 0.8535 - val_loss: 0.3605 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 225/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8734 - loss: 0.3065 - precision: 0.8532 - recall: 0.8501 - val_auc: 0.9254 - val_binary_accuracy: 0.8535 - val_loss: 0.3605 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 226/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8742 - loss: 0.3084 - precision: 0.8535 - recall: 0.8519 - val_auc: 0.9255 - val_binary_accuracy: 0.8535 - val_loss: 0.3605 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 227/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8742 - loss: 0.3082 - precision: 0.8532 - recall: 0.8516 - val_auc: 0.9255 - val_binary_accuracy: 0.8535 - val_loss: 0.3604 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 228/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8750 - loss: 0.3066 - precision: 0.8532 - recall: 0.8532 - val_auc: 0.9254 - val_binary_accuracy: 0.8535 - val_loss: 0.3603 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 229/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9438 - binary_accuracy: 0.8734 - loss: 0.3079 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9253 - val_binary_accuracy: 0.8512 - val_loss: 0.3603 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 230/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9439 - binary_accuracy: 0.8742 - loss: 0.3073 - precision: 0.8545 - recall: 0.8498 - val_auc: 0.9253 - val_binary_accuracy: 0.8512 - val_loss: 0.3603 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 231/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8758 - loss: 0.3057 - precision: 0.8566 - recall: 0.8519 - val_auc: 0.9253 - val_binary_accuracy: 0.8512 - val_loss: 0.3601 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 232/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8742 - loss: 0.3066 - precision: 0.8550 - recall: 0.8504 - val_auc: 0.9254 - val_binary_accuracy: 0.8512 - val_loss: 0.3601 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 233/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8758 - loss: 0.3032 - precision: 0.8553 - recall: 0.8537 - val_auc: 0.9255 - val_binary_accuracy: 0.8512 - val_loss: 0.3600 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 234/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9437 - binary_accuracy: 0.8734 - loss: 0.3075 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9256 - val_binary_accuracy: 0.8512 - val_loss: 0.3600 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 235/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9438 - binary_accuracy: 0.8734 - loss: 0.3072 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9256 - val_binary_accuracy: 0.8512 - val_loss: 0.3599 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 236/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9441 - binary_accuracy: 0.8742 - loss: 0.3064 - precision: 0.8545 - recall: 0.8498 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3598 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 237/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9440 - binary_accuracy: 0.8742 - loss: 0.3071 - precision: 0.8537 - recall: 0.8522 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3598 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 238/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8750 - loss: 0.3038 - precision: 0.8548 - recall: 0.8516 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3597 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 239/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9440 - binary_accuracy: 0.8734 - loss: 0.3072 - precision: 0.8532 - recall: 0.8501 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3596 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 240/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9439 - binary_accuracy: 0.8734 - loss: 0.3074 - precision: 0.8535 - recall: 0.8504 - val_auc: 0.9258 - val_binary_accuracy: 0.8512 - val_loss: 0.3596 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 241/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8750 - loss: 0.3047 - precision: 0.8548 - recall: 0.8516 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3595 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 242/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8742 - loss: 0.3058 - precision: 0.8532 - recall: 0.8516 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3594 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 243/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9440 - binary_accuracy: 0.8734 - loss: 0.3071 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3593 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 244/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9440 - binary_accuracy: 0.8734 - loss: 0.3071 - precision: 0.8529 - recall: 0.8498 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3593 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 245/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8742 - loss: 0.3065 - precision: 0.8529 - recall: 0.8514 - val_auc: 0.9258 - val_binary_accuracy: 0.8512 - val_loss: 0.3592 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 246/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9441 - binary_accuracy: 0.8734 - loss: 0.3065 - precision: 0.8527 - recall: 0.8495 - val_auc: 0.9259 - val_binary_accuracy: 0.8512 - val_loss: 0.3592 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 247/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9447 - binary_accuracy: 0.8742 - loss: 0.3055 - precision: 0.8553 - recall: 0.8506 - val_auc: 0.9258 - val_binary_accuracy: 0.8512 - val_loss: 0.3591 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 248/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8742 - loss: 0.3056 - precision: 0.8550 - recall: 0.8504 - val_auc: 0.9256 - val_binary_accuracy: 0.8512 - val_loss: 0.3590 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 249/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8734 - loss: 0.3063 - precision: 0.8527 - recall: 0.8495 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3589 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 250/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8734 - loss: 0.3057 - precision: 0.8535 - recall: 0.8504 - val_auc: 0.9258 - val_binary_accuracy: 0.8512 - val_loss: 0.3589 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 251/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8750 - loss: 0.3042 - precision: 0.8532 - recall: 0.8532 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3588 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 252/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8758 - loss: 0.3038 - precision: 0.8566 - recall: 0.8519 - val_auc: 0.9258 - val_binary_accuracy: 0.8512 - val_loss: 0.3588 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 253/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8766 - loss: 0.3020 - precision: 0.8585 - recall: 0.8522 - val_auc: 0.9257 - val_binary_accuracy: 0.8512 - val_loss: 0.3587 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 254/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8742 - loss: 0.3065 - precision: 0.8545 - recall: 0.8498 - val_auc: 0.9259 - val_binary_accuracy: 0.8512 - val_loss: 0.3586 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 255/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8750 - loss: 0.3052 - precision: 0.8561 - recall: 0.8498 - val_auc: 0.9259 - val_binary_accuracy: 0.8512 - val_loss: 0.3586 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 256/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8750 - loss: 0.3045 - precision: 0.8542 - recall: 0.8511 - val_auc: 0.9259 - val_binary_accuracy: 0.8512 - val_loss: 0.3586 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 257/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8758 - loss: 0.3049 - precision: 0.8579 - recall: 0.8501 - val_auc: 0.9259 - val_binary_accuracy: 0.8512 - val_loss: 0.3585 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 258/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8750 - loss: 0.3032 - precision: 0.8566 - recall: 0.8504 - val_auc: 0.9260 - val_binary_accuracy: 0.8512 - val_loss: 0.3584 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 259/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8750 - loss: 0.3042 - precision: 0.8545 - recall: 0.8514 - val_auc: 0.9260 - val_binary_accuracy: 0.8512 - val_loss: 0.3584 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 260/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8742 - loss: 0.3058 - precision: 0.8548 - recall: 0.8501 - val_auc: 0.9259 - val_binary_accuracy: 0.8512 - val_loss: 0.3583 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 261/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8742 - loss: 0.3056 - precision: 0.8545 - recall: 0.8498 - val_auc: 0.9260 - val_binary_accuracy: 0.8512 - val_loss: 0.3583 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 262/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8758 - loss: 0.3035 - precision: 0.8566 - recall: 0.8519 - val_auc: 0.9260 - val_binary_accuracy: 0.8535 - val_loss: 0.3583 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 263/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8742 - loss: 0.3048 - precision: 0.8542 - recall: 0.8495 - val_auc: 0.9260 - val_binary_accuracy: 0.8535 - val_loss: 0.3582 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 264/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9449 - binary_accuracy: 0.8750 - loss: 0.3045 - precision: 0.8564 - recall: 0.8501 - val_auc: 0.9260 - val_binary_accuracy: 0.8535 - val_loss: 0.3581 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 265/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8766 - loss: 0.3034 - precision: 0.8569 - recall: 0.8537 - val_auc: 0.9259 - val_binary_accuracy: 0.8535 - val_loss: 0.3580 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 266/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8766 - loss: 0.3019 - precision: 0.8582 - recall: 0.8519 - val_auc: 0.9260 - val_binary_accuracy: 0.8535 - val_loss: 0.3580 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 267/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8758 - loss: 0.3033 - precision: 0.8582 - recall: 0.8504 - val_auc: 0.9261 - val_binary_accuracy: 0.8535 - val_loss: 0.3579 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 268/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9447 - binary_accuracy: 0.8750 - loss: 0.3051 - precision: 0.8561 - recall: 0.8498 - val_auc: 0.9261 - val_binary_accuracy: 0.8535 - val_loss: 0.3579 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 269/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8758 - loss: 0.3034 - precision: 0.8566 - recall: 0.8519 - val_auc: 0.9261 - val_binary_accuracy: 0.8535 - val_loss: 0.3578 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 270/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8758 - loss: 0.3034 - precision: 0.8579 - recall: 0.8501 - val_auc: 0.9262 - val_binary_accuracy: 0.8535 - val_loss: 0.3578 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 271/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8758 - loss: 0.3035 - precision: 0.8564 - recall: 0.8516 - val_auc: 0.9261 - val_binary_accuracy: 0.8535 - val_loss: 0.3577 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 272/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9449 - binary_accuracy: 0.8750 - loss: 0.3049 - precision: 0.8564 - recall: 0.8501 - val_auc: 0.9262 - val_binary_accuracy: 0.8535 - val_loss: 0.3577 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 273/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8758 - loss: 0.3043 - precision: 0.8579 - recall: 0.8501 - val_auc: 0.9263 - val_binary_accuracy: 0.8535 - val_loss: 0.3575 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 274/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8781 - loss: 0.3020 - precision: 0.8595 - recall: 0.8532 - val_auc: 0.9261 - val_binary_accuracy: 0.8535 - val_loss: 0.3575 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 275/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8750 - loss: 0.3043 - precision: 0.8566 - recall: 0.8504 - val_auc: 0.9262 - val_binary_accuracy: 0.8535 - val_loss: 0.3575 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 276/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9449 - binary_accuracy: 0.8758 - loss: 0.3044 - precision: 0.8566 - recall: 0.8519 - val_auc: 0.9262 - val_binary_accuracy: 0.8535 - val_loss: 0.3574 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 277/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8758 - loss: 0.3038 - precision: 0.8574 - recall: 0.8495 - val_auc: 0.9263 - val_binary_accuracy: 0.8535 - val_loss: 0.3574 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 278/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8781 - loss: 0.3026 - precision: 0.8619 - recall: 0.8525 - val_auc: 0.9264 - val_binary_accuracy: 0.8535 - val_loss: 0.3574 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 279/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8781 - loss: 0.3005 - precision: 0.8616 - recall: 0.8522 - val_auc: 0.9264 - val_binary_accuracy: 0.8535 - val_loss: 0.3572 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 280/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9452 - binary_accuracy: 0.8758 - loss: 0.3036 - precision: 0.8561 - recall: 0.8514 - val_auc: 0.9263 - val_binary_accuracy: 0.8535 - val_loss: 0.3572 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 281/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8766 - loss: 0.3029 - precision: 0.8595 - recall: 0.8501 - val_auc: 0.9263 - val_binary_accuracy: 0.8535 - val_loss: 0.3571 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 282/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8758 - loss: 0.3029 - precision: 0.8593 - recall: 0.8483 - val_auc: 0.9264 - val_binary_accuracy: 0.8535 - val_loss: 0.3571 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 283/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8750 - loss: 0.3043 - precision: 0.8577 - recall: 0.8483 - val_auc: 0.9264 - val_binary_accuracy: 0.8535 - val_loss: 0.3571 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 284/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8773 - loss: 0.3026 - precision: 0.8595 - recall: 0.8516 - val_auc: 0.9263 - val_binary_accuracy: 0.8535 - val_loss: 0.3569 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 285/300                                          \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9452 - binary_accuracy: 0.8750 - loss: 0.3035 - precision: 0.8561 - recall: 0.8498 - val_auc: 0.9264 - val_binary_accuracy: 0.8535 - val_loss: 0.3570 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 286/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8750 - loss: 0.3042 - precision: 0.8579 - recall: 0.8485 - val_auc: 0.9266 - val_binary_accuracy: 0.8535 - val_loss: 0.3569 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 287/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9449 - binary_accuracy: 0.8758 - loss: 0.3043 - precision: 0.8587 - recall: 0.8477 - val_auc: 0.9265 - val_binary_accuracy: 0.8535 - val_loss: 0.3568 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 288/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8766 - loss: 0.3006 - precision: 0.8590 - recall: 0.8495 - val_auc: 0.9265 - val_binary_accuracy: 0.8535 - val_loss: 0.3568 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 289/300                                          \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9474 - binary_accuracy: 0.8773 - loss: 0.2977 - precision: 0.8600 - recall: 0.8522 - val_auc: 0.9266 - val_binary_accuracy: 0.8535 - val_loss: 0.3568 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 290/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8773 - loss: 0.3023 - precision: 0.8611 - recall: 0.8501 - val_auc: 0.9265 - val_binary_accuracy: 0.8535 - val_loss: 0.3567 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 291/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8773 - loss: 0.3033 - precision: 0.8590 - recall: 0.8511 - val_auc: 0.9266 - val_binary_accuracy: 0.8535 - val_loss: 0.3567 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 292/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8773 - loss: 0.3024 - precision: 0.8611 - recall: 0.8501 - val_auc: 0.9266 - val_binary_accuracy: 0.8535 - val_loss: 0.3566 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 293/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8773 - loss: 0.3022 - precision: 0.8609 - recall: 0.8498 - val_auc: 0.9265 - val_binary_accuracy: 0.8535 - val_loss: 0.3566 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 294/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8773 - loss: 0.3029 - precision: 0.8609 - recall: 0.8498 - val_auc: 0.9265 - val_binary_accuracy: 0.8535 - val_loss: 0.3566 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 295/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8781 - loss: 0.3020 - precision: 0.8595 - recall: 0.8532 - val_auc: 0.9266 - val_binary_accuracy: 0.8535 - val_loss: 0.3565 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 296/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8773 - loss: 0.3030 - precision: 0.8593 - recall: 0.8514 - val_auc: 0.9267 - val_binary_accuracy: 0.8535 - val_loss: 0.3564 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 297/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9452 - binary_accuracy: 0.8766 - loss: 0.3037 - precision: 0.8595 - recall: 0.8501 - val_auc: 0.9266 - val_binary_accuracy: 0.8535 - val_loss: 0.3564 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 298/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8766 - loss: 0.3032 - precision: 0.8593 - recall: 0.8498 - val_auc: 0.9267 - val_binary_accuracy: 0.8535 - val_loss: 0.3563 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 299/300                                          \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9458 - binary_accuracy: 0.8773 - loss: 0.3019 - precision: 0.8609 - recall: 0.8498 - val_auc: 0.9266 - val_binary_accuracy: 0.8535 - val_loss: 0.3564 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "Epoch 300/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8766 - loss: 0.3031 - precision: 0.8587 - recall: 0.8493 - val_auc: 0.9267 - val_binary_accuracy: 0.8535 - val_loss: 0.3563 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 2.7440e-05\n",
      "\n",
      "./plots/enchanting-carp-570/learning_rate_vs_epoch.png \n",
      "./plots/enchanting-carp-570/auc_vs_epoch.png           \n",
      "./plots/enchanting-carp-570/loss_vs_epoch.png          \n",
      "./plots/enchanting-carp-570/binary_accuracy_vs_epoch.png\n",
      "./plots/enchanting-carp-570/recall_vs_epoch.png        \n",
      "./plots/enchanting-carp-570/precision_vs_epoch.png     \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 510ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\n",
      " 67%|██████▋   | 10/15 [01:18<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
      "\n",
      " 67%|██████▋   | 10/15 [01:19<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c7c8758a414760bd7efa5ab4bee7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m196/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m196/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m194/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 21ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step\n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 66/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "🏃 View run enchanting-carp-570 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/efca182aad4d4bbfbd7c88470d760624\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 73%|███████▎  | 11/15 [02:05<08:21, 125.30s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 03:29:22.240007: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.282216: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.322950: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.367855: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.407062: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.447010: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.488380: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.527530: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.568369: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.607094: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.647445: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.686371: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.730862: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.773736: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.814496: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:29:22.856094: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 4s - 53ms/step - auc: 0.1335 - binary_accuracy: 0.2484 - loss: 0.9081 - precision: 0.1312 - recall: 0.1355 - val_auc: 0.1599 - val_binary_accuracy: 0.2512 - val_loss: 0.8896 - val_precision: 0.1399 - val_recall: 0.1475 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1380 - binary_accuracy: 0.2562 - loss: 0.9001 - precision: 0.1362 - recall: 0.1392 - val_auc: 0.1641 - val_binary_accuracy: 0.2651 - val_loss: 0.8821 - val_precision: 0.1481 - val_recall: 0.1530 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1409 - binary_accuracy: 0.2617 - loss: 0.8928 - precision: 0.1326 - recall: 0.1319 - val_auc: 0.1678 - val_binary_accuracy: 0.2744 - val_loss: 0.8749 - val_precision: 0.1514 - val_recall: 0.1530 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1455 - binary_accuracy: 0.2703 - loss: 0.8846 - precision: 0.1340 - recall: 0.1300 - val_auc: 0.1722 - val_binary_accuracy: 0.2791 - val_loss: 0.8677 - val_precision: 0.1492 - val_recall: 0.1475 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1492 - binary_accuracy: 0.2789 - loss: 0.8783 - precision: 0.1379 - recall: 0.1321 - val_auc: 0.1760 - val_binary_accuracy: 0.2907 - val_loss: 0.8607 - val_precision: 0.1534 - val_recall: 0.1475 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1561 - binary_accuracy: 0.2859 - loss: 0.8699 - precision: 0.1387 - recall: 0.1305 - val_auc: 0.1812 - val_binary_accuracy: 0.2953 - val_loss: 0.8540 - val_precision: 0.1512 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1601 - binary_accuracy: 0.2891 - loss: 0.8626 - precision: 0.1355 - recall: 0.1250 - val_auc: 0.1869 - val_binary_accuracy: 0.3047 - val_loss: 0.8473 - val_precision: 0.1548 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1645 - binary_accuracy: 0.2961 - loss: 0.8575 - precision: 0.1420 - recall: 0.1277 - val_auc: 0.1925 - val_binary_accuracy: 0.3070 - val_loss: 0.8409 - val_precision: 0.1515 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1703 - binary_accuracy: 0.3094 - loss: 0.8499 - precision: 0.1447 - recall: 0.1266 - val_auc: 0.1993 - val_binary_accuracy: 0.3116 - val_loss: 0.8345 - val_precision: 0.1534 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1774 - binary_accuracy: 0.3156 - loss: 0.8428 - precision: 0.1459 - recall: 0.1245 - val_auc: 0.2048 - val_binary_accuracy: 0.3163 - val_loss: 0.8282 - val_precision: 0.1553 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1843 - binary_accuracy: 0.3242 - loss: 0.8371 - precision: 0.1501 - recall: 0.1241 - val_auc: 0.2116 - val_binary_accuracy: 0.3279 - val_loss: 0.8221 - val_precision: 0.1603 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1911 - binary_accuracy: 0.3305 - loss: 0.8300 - precision: 0.1521 - recall: 0.1245 - val_auc: 0.2177 - val_binary_accuracy: 0.3326 - val_loss: 0.8161 - val_precision: 0.1623 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1958 - binary_accuracy: 0.3414 - loss: 0.8251 - precision: 0.1558 - recall: 0.1225 - val_auc: 0.2244 - val_binary_accuracy: 0.3395 - val_loss: 0.8102 - val_precision: 0.1611 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2041 - binary_accuracy: 0.3508 - loss: 0.8185 - precision: 0.1599 - recall: 0.1227 - val_auc: 0.2317 - val_binary_accuracy: 0.3442 - val_loss: 0.8045 - val_precision: 0.1633 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2124 - binary_accuracy: 0.3602 - loss: 0.8123 - precision: 0.1679 - recall: 0.1264 - val_auc: 0.2379 - val_binary_accuracy: 0.3535 - val_loss: 0.7988 - val_precision: 0.1678 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2188 - binary_accuracy: 0.3695 - loss: 0.8071 - precision: 0.1734 - recall: 0.1261 - val_auc: 0.2463 - val_binary_accuracy: 0.3605 - val_loss: 0.7932 - val_precision: 0.1714 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2293 - binary_accuracy: 0.3805 - loss: 0.8004 - precision: 0.1809 - recall: 0.1282 - val_auc: 0.2540 - val_binary_accuracy: 0.3721 - val_loss: 0.7878 - val_precision: 0.1825 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2375 - binary_accuracy: 0.3891 - loss: 0.7958 - precision: 0.1855 - recall: 0.1259 - val_auc: 0.2630 - val_binary_accuracy: 0.3721 - val_loss: 0.7824 - val_precision: 0.1778 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2460 - binary_accuracy: 0.4008 - loss: 0.7904 - precision: 0.1961 - recall: 0.1298 - val_auc: 0.2705 - val_binary_accuracy: 0.3860 - val_loss: 0.7772 - val_precision: 0.1860 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2556 - binary_accuracy: 0.4102 - loss: 0.7847 - precision: 0.2029 - recall: 0.1298 - val_auc: 0.2787 - val_binary_accuracy: 0.4023 - val_loss: 0.7720 - val_precision: 0.1967 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2649 - binary_accuracy: 0.4172 - loss: 0.7803 - precision: 0.2151 - recall: 0.1345 - val_auc: 0.2877 - val_binary_accuracy: 0.4163 - val_loss: 0.7669 - val_precision: 0.2119 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2782 - binary_accuracy: 0.4289 - loss: 0.7738 - precision: 0.2242 - recall: 0.1348 - val_auc: 0.2983 - val_binary_accuracy: 0.4209 - val_loss: 0.7619 - val_precision: 0.2155 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2887 - binary_accuracy: 0.4352 - loss: 0.7681 - precision: 0.2284 - recall: 0.1353 - val_auc: 0.3093 - val_binary_accuracy: 0.4279 - val_loss: 0.7570 - val_precision: 0.2212 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3013 - binary_accuracy: 0.4391 - loss: 0.7622 - precision: 0.2303 - recall: 0.1335 - val_auc: 0.3200 - val_binary_accuracy: 0.4279 - val_loss: 0.7521 - val_precision: 0.2212 - val_recall: 0.1366 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3099 - binary_accuracy: 0.4453 - loss: 0.7583 - precision: 0.2345 - recall: 0.1316 - val_auc: 0.3319 - val_binary_accuracy: 0.4395 - val_loss: 0.7473 - val_precision: 0.2264 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3201 - binary_accuracy: 0.4516 - loss: 0.7532 - precision: 0.2408 - recall: 0.1316 - val_auc: 0.3432 - val_binary_accuracy: 0.4442 - val_loss: 0.7426 - val_precision: 0.2255 - val_recall: 0.1257 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3333 - binary_accuracy: 0.4617 - loss: 0.7488 - precision: 0.2561 - recall: 0.1350 - val_auc: 0.3547 - val_binary_accuracy: 0.4512 - val_loss: 0.7380 - val_precision: 0.2323 - val_recall: 0.1257 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3472 - binary_accuracy: 0.4695 - loss: 0.7432 - precision: 0.2660 - recall: 0.1371 - val_auc: 0.3666 - val_binary_accuracy: 0.4674 - val_loss: 0.7334 - val_precision: 0.2553 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3595 - binary_accuracy: 0.4766 - loss: 0.7384 - precision: 0.2754 - recall: 0.1392 - val_auc: 0.3794 - val_binary_accuracy: 0.4744 - val_loss: 0.7288 - val_precision: 0.2637 - val_recall: 0.1311 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3739 - binary_accuracy: 0.4836 - loss: 0.7336 - precision: 0.2873 - recall: 0.1408 - val_auc: 0.3927 - val_binary_accuracy: 0.4837 - val_loss: 0.7243 - val_precision: 0.2857 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3850 - binary_accuracy: 0.4875 - loss: 0.7287 - precision: 0.2890 - recall: 0.1394 - val_auc: 0.4060 - val_binary_accuracy: 0.4930 - val_loss: 0.7198 - val_precision: 0.2989 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3975 - binary_accuracy: 0.4945 - loss: 0.7247 - precision: 0.3023 - recall: 0.1431 - val_auc: 0.4183 - val_binary_accuracy: 0.4930 - val_loss: 0.7155 - val_precision: 0.2989 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4131 - binary_accuracy: 0.4961 - loss: 0.7203 - precision: 0.3068 - recall: 0.1405 - val_auc: 0.4316 - val_binary_accuracy: 0.4930 - val_loss: 0.7112 - val_precision: 0.2989 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4247 - binary_accuracy: 0.5102 - loss: 0.7153 - precision: 0.3264 - recall: 0.1434 - val_auc: 0.4449 - val_binary_accuracy: 0.4953 - val_loss: 0.7070 - val_precision: 0.3023 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4423 - binary_accuracy: 0.5141 - loss: 0.7109 - precision: 0.3447 - recall: 0.1475 - val_auc: 0.4574 - val_binary_accuracy: 0.4953 - val_loss: 0.7027 - val_precision: 0.3023 - val_recall: 0.1421 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4546 - binary_accuracy: 0.5258 - loss: 0.7062 - precision: 0.3652 - recall: 0.1541 - val_auc: 0.4712 - val_binary_accuracy: 0.5000 - val_loss: 0.6985 - val_precision: 0.3140 - val_recall: 0.1475 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4692 - binary_accuracy: 0.5297 - loss: 0.7022 - precision: 0.3805 - recall: 0.1569 - val_auc: 0.4844 - val_binary_accuracy: 0.5023 - val_loss: 0.6944 - val_precision: 0.3176 - val_recall: 0.1475 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4816 - binary_accuracy: 0.5336 - loss: 0.6977 - precision: 0.3839 - recall: 0.1578 - val_auc: 0.4968 - val_binary_accuracy: 0.5140 - val_loss: 0.6904 - val_precision: 0.3452 - val_recall: 0.1585 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4967 - binary_accuracy: 0.5398 - loss: 0.6931 - precision: 0.4000 - recall: 0.1615 - val_auc: 0.5113 - val_binary_accuracy: 0.5233 - val_loss: 0.6864 - val_precision: 0.3721 - val_recall: 0.1749 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5101 - binary_accuracy: 0.5437 - loss: 0.6894 - precision: 0.4136 - recall: 0.1667 - val_auc: 0.5226 - val_binary_accuracy: 0.5372 - val_loss: 0.6824 - val_precision: 0.4048 - val_recall: 0.1858 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5244 - binary_accuracy: 0.5469 - loss: 0.6857 - precision: 0.4245 - recall: 0.1642 - val_auc: 0.5358 - val_binary_accuracy: 0.5372 - val_loss: 0.6785 - val_precision: 0.4048 - val_recall: 0.1858 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5399 - binary_accuracy: 0.5555 - loss: 0.6805 - precision: 0.4450 - recall: 0.1703 - val_auc: 0.5485 - val_binary_accuracy: 0.5465 - val_loss: 0.6747 - val_precision: 0.4268 - val_recall: 0.1913 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5519 - binary_accuracy: 0.5547 - loss: 0.6777 - precision: 0.4498 - recall: 0.1712 - val_auc: 0.5599 - val_binary_accuracy: 0.5605 - val_loss: 0.6709 - val_precision: 0.4615 - val_recall: 0.1967 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5631 - binary_accuracy: 0.5602 - loss: 0.6737 - precision: 0.4645 - recall: 0.1788 - val_auc: 0.5742 - val_binary_accuracy: 0.5698 - val_loss: 0.6671 - val_precision: 0.4872 - val_recall: 0.2077 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5794 - binary_accuracy: 0.5656 - loss: 0.6684 - precision: 0.4764 - recall: 0.1850 - val_auc: 0.5839 - val_binary_accuracy: 0.5721 - val_loss: 0.6633 - val_precision: 0.4935 - val_recall: 0.2077 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5896 - binary_accuracy: 0.5688 - loss: 0.6661 - precision: 0.4928 - recall: 0.1876 - val_auc: 0.5973 - val_binary_accuracy: 0.5721 - val_loss: 0.6597 - val_precision: 0.4933 - val_recall: 0.2022 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6034 - binary_accuracy: 0.5758 - loss: 0.6609 - precision: 0.5047 - recall: 0.1982 - val_auc: 0.6076 - val_binary_accuracy: 0.5837 - val_loss: 0.6562 - val_precision: 0.5263 - val_recall: 0.2186 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6180 - binary_accuracy: 0.5813 - loss: 0.6568 - precision: 0.5209 - recall: 0.2055 - val_auc: 0.6176 - val_binary_accuracy: 0.5837 - val_loss: 0.6526 - val_precision: 0.5263 - val_recall: 0.2186 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6316 - binary_accuracy: 0.5859 - loss: 0.6529 - precision: 0.5377 - recall: 0.2088 - val_auc: 0.6292 - val_binary_accuracy: 0.5814 - val_loss: 0.6491 - val_precision: 0.5200 - val_recall: 0.2131 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6408 - binary_accuracy: 0.5852 - loss: 0.6496 - precision: 0.5359 - recall: 0.2051 - val_auc: 0.6384 - val_binary_accuracy: 0.5837 - val_loss: 0.6457 - val_precision: 0.5263 - val_recall: 0.2186 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6539 - binary_accuracy: 0.5875 - loss: 0.6462 - precision: 0.5446 - recall: 0.2121 - val_auc: 0.6481 - val_binary_accuracy: 0.5884 - val_loss: 0.6423 - val_precision: 0.5385 - val_recall: 0.2295 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6645 - binary_accuracy: 0.5938 - loss: 0.6428 - precision: 0.5646 - recall: 0.2157 - val_auc: 0.6587 - val_binary_accuracy: 0.5953 - val_loss: 0.6390 - val_precision: 0.5584 - val_recall: 0.2350 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6752 - binary_accuracy: 0.5953 - loss: 0.6393 - precision: 0.5673 - recall: 0.2161 - val_auc: 0.6683 - val_binary_accuracy: 0.5953 - val_loss: 0.6358 - val_precision: 0.5584 - val_recall: 0.2350 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6847 - binary_accuracy: 0.5984 - loss: 0.6355 - precision: 0.5735 - recall: 0.2220 - val_auc: 0.6785 - val_binary_accuracy: 0.5977 - val_loss: 0.6325 - val_precision: 0.5658 - val_recall: 0.2350 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6939 - binary_accuracy: 0.5992 - loss: 0.6323 - precision: 0.5767 - recall: 0.2271 - val_auc: 0.6873 - val_binary_accuracy: 0.6023 - val_loss: 0.6293 - val_precision: 0.5769 - val_recall: 0.2459 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7047 - binary_accuracy: 0.6008 - loss: 0.6285 - precision: 0.5787 - recall: 0.2294 - val_auc: 0.6969 - val_binary_accuracy: 0.6023 - val_loss: 0.6261 - val_precision: 0.5789 - val_recall: 0.2404 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7135 - binary_accuracy: 0.6062 - loss: 0.6258 - precision: 0.5982 - recall: 0.2395 - val_auc: 0.7069 - val_binary_accuracy: 0.6047 - val_loss: 0.6230 - val_precision: 0.5844 - val_recall: 0.2459 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7227 - binary_accuracy: 0.6133 - loss: 0.6215 - precision: 0.6109 - recall: 0.2482 - val_auc: 0.7150 - val_binary_accuracy: 0.6116 - val_loss: 0.6200 - val_precision: 0.6026 - val_recall: 0.2568 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7324 - binary_accuracy: 0.6156 - loss: 0.6184 - precision: 0.6233 - recall: 0.2541 - val_auc: 0.7252 - val_binary_accuracy: 0.6093 - val_loss: 0.6170 - val_precision: 0.5974 - val_recall: 0.2514 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7413 - binary_accuracy: 0.6187 - loss: 0.6154 - precision: 0.6339 - recall: 0.2591 - val_auc: 0.7327 - val_binary_accuracy: 0.6163 - val_loss: 0.6140 - val_precision: 0.6184 - val_recall: 0.2568 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7458 - binary_accuracy: 0.6187 - loss: 0.6134 - precision: 0.6356 - recall: 0.2605 - val_auc: 0.7413 - val_binary_accuracy: 0.6163 - val_loss: 0.6111 - val_precision: 0.6184 - val_recall: 0.2568 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7542 - binary_accuracy: 0.6195 - loss: 0.6096 - precision: 0.6356 - recall: 0.2609 - val_auc: 0.7487 - val_binary_accuracy: 0.6186 - val_loss: 0.6082 - val_precision: 0.6267 - val_recall: 0.2568 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7612 - binary_accuracy: 0.6195 - loss: 0.6063 - precision: 0.6364 - recall: 0.2559 - val_auc: 0.7555 - val_binary_accuracy: 0.6186 - val_loss: 0.6054 - val_precision: 0.6203 - val_recall: 0.2678 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7678 - binary_accuracy: 0.6242 - loss: 0.6023 - precision: 0.6468 - recall: 0.2587 - val_auc: 0.7622 - val_binary_accuracy: 0.6256 - val_loss: 0.6026 - val_precision: 0.6375 - val_recall: 0.2787 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7737 - binary_accuracy: 0.6250 - loss: 0.6000 - precision: 0.6545 - recall: 0.2628 - val_auc: 0.7691 - val_binary_accuracy: 0.6256 - val_loss: 0.5999 - val_precision: 0.6375 - val_recall: 0.2787 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7811 - binary_accuracy: 0.6258 - loss: 0.5962 - precision: 0.6530 - recall: 0.2619 - val_auc: 0.7758 - val_binary_accuracy: 0.6279 - val_loss: 0.5971 - val_precision: 0.6456 - val_recall: 0.2787 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7881 - binary_accuracy: 0.6281 - loss: 0.5932 - precision: 0.6621 - recall: 0.2651 - val_auc: 0.7827 - val_binary_accuracy: 0.6302 - val_loss: 0.5944 - val_precision: 0.6500 - val_recall: 0.2842 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7923 - binary_accuracy: 0.6273 - loss: 0.5904 - precision: 0.6592 - recall: 0.2682 - val_auc: 0.7888 - val_binary_accuracy: 0.6349 - val_loss: 0.5917 - val_precision: 0.6585 - val_recall: 0.2951 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7950 - binary_accuracy: 0.6289 - loss: 0.5882 - precision: 0.6637 - recall: 0.2701 - val_auc: 0.7935 - val_binary_accuracy: 0.6395 - val_loss: 0.5891 - val_precision: 0.6707 - val_recall: 0.3005 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7994 - binary_accuracy: 0.6281 - loss: 0.5857 - precision: 0.6607 - recall: 0.2701 - val_auc: 0.7970 - val_binary_accuracy: 0.6465 - val_loss: 0.5864 - val_precision: 0.6867 - val_recall: 0.3115 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8070 - binary_accuracy: 0.6336 - loss: 0.5824 - precision: 0.6786 - recall: 0.2769 - val_auc: 0.8017 - val_binary_accuracy: 0.6442 - val_loss: 0.5839 - val_precision: 0.6829 - val_recall: 0.3060 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8100 - binary_accuracy: 0.6344 - loss: 0.5789 - precision: 0.6696 - recall: 0.2821 - val_auc: 0.8065 - val_binary_accuracy: 0.6465 - val_loss: 0.5814 - val_precision: 0.6867 - val_recall: 0.3115 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8164 - binary_accuracy: 0.6398 - loss: 0.5745 - precision: 0.6783 - recall: 0.2873 - val_auc: 0.8117 - val_binary_accuracy: 0.6488 - val_loss: 0.5789 - val_precision: 0.6905 - val_recall: 0.3169 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8194 - binary_accuracy: 0.6414 - loss: 0.5726 - precision: 0.6870 - recall: 0.2899 - val_auc: 0.8148 - val_binary_accuracy: 0.6535 - val_loss: 0.5765 - val_precision: 0.7024 - val_recall: 0.3224 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8226 - binary_accuracy: 0.6445 - loss: 0.5704 - precision: 0.6907 - recall: 0.2991 - val_auc: 0.8192 - val_binary_accuracy: 0.6558 - val_loss: 0.5741 - val_precision: 0.7059 - val_recall: 0.3279 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8268 - binary_accuracy: 0.6445 - loss: 0.5680 - precision: 0.6933 - recall: 0.3016 - val_auc: 0.8233 - val_binary_accuracy: 0.6581 - val_loss: 0.5717 - val_precision: 0.7143 - val_recall: 0.3279 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8301 - binary_accuracy: 0.6508 - loss: 0.5654 - precision: 0.7066 - recall: 0.3126 - val_auc: 0.8268 - val_binary_accuracy: 0.6605 - val_loss: 0.5694 - val_precision: 0.7176 - val_recall: 0.3333 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8336 - binary_accuracy: 0.6547 - loss: 0.5634 - precision: 0.7202 - recall: 0.3188 - val_auc: 0.8294 - val_binary_accuracy: 0.6628 - val_loss: 0.5671 - val_precision: 0.7262 - val_recall: 0.3333 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8376 - binary_accuracy: 0.6617 - loss: 0.5595 - precision: 0.7287 - recall: 0.3297 - val_auc: 0.8328 - val_binary_accuracy: 0.6628 - val_loss: 0.5649 - val_precision: 0.7262 - val_recall: 0.3333 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8407 - binary_accuracy: 0.6672 - loss: 0.5572 - precision: 0.7371 - recall: 0.3394 - val_auc: 0.8360 - val_binary_accuracy: 0.6628 - val_loss: 0.5627 - val_precision: 0.7262 - val_recall: 0.3333 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8434 - binary_accuracy: 0.6648 - loss: 0.5551 - precision: 0.7315 - recall: 0.3431 - val_auc: 0.8402 - val_binary_accuracy: 0.6698 - val_loss: 0.5605 - val_precision: 0.7356 - val_recall: 0.3497 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8459 - binary_accuracy: 0.6719 - loss: 0.5520 - precision: 0.7385 - recall: 0.3529 - val_auc: 0.8421 - val_binary_accuracy: 0.6767 - val_loss: 0.5584 - val_precision: 0.7444 - val_recall: 0.3661 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8488 - binary_accuracy: 0.6734 - loss: 0.5505 - precision: 0.7452 - recall: 0.3583 - val_auc: 0.8444 - val_binary_accuracy: 0.6791 - val_loss: 0.5563 - val_precision: 0.7473 - val_recall: 0.3716 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8506 - binary_accuracy: 0.6766 - loss: 0.5478 - precision: 0.7444 - recall: 0.3640 - val_auc: 0.8470 - val_binary_accuracy: 0.6791 - val_loss: 0.5542 - val_precision: 0.7419 - val_recall: 0.3770 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8557 - binary_accuracy: 0.6828 - loss: 0.5458 - precision: 0.7581 - recall: 0.3825 - val_auc: 0.8492 - val_binary_accuracy: 0.6814 - val_loss: 0.5522 - val_precision: 0.7447 - val_recall: 0.3825 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 86/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8566 - binary_accuracy: 0.6867 - loss: 0.5438 - precision: 0.7561 - recall: 0.3960 - val_auc: 0.8510 - val_binary_accuracy: 0.6907 - val_loss: 0.5501 - val_precision: 0.7604 - val_recall: 0.3989 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 87/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8595 - binary_accuracy: 0.6906 - loss: 0.5408 - precision: 0.7621 - recall: 0.4033 - val_auc: 0.8533 - val_binary_accuracy: 0.6953 - val_loss: 0.5481 - val_precision: 0.7708 - val_recall: 0.4044 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 88/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8621 - binary_accuracy: 0.6961 - loss: 0.5388 - precision: 0.7713 - recall: 0.4124 - val_auc: 0.8553 - val_binary_accuracy: 0.7023 - val_loss: 0.5461 - val_precision: 0.7835 - val_recall: 0.4153 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 89/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8652 - binary_accuracy: 0.7039 - loss: 0.5359 - precision: 0.7774 - recall: 0.4286 - val_auc: 0.8578 - val_binary_accuracy: 0.7070 - val_loss: 0.5441 - val_precision: 0.7879 - val_recall: 0.4262 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 90/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8669 - binary_accuracy: 0.7086 - loss: 0.5343 - precision: 0.7806 - recall: 0.4424 - val_auc: 0.8607 - val_binary_accuracy: 0.7116 - val_loss: 0.5422 - val_precision: 0.7921 - val_recall: 0.4372 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 91/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8678 - binary_accuracy: 0.7141 - loss: 0.5327 - precision: 0.7855 - recall: 0.4552 - val_auc: 0.8617 - val_binary_accuracy: 0.7186 - val_loss: 0.5403 - val_precision: 0.7925 - val_recall: 0.4590 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 92/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8713 - binary_accuracy: 0.7219 - loss: 0.5289 - precision: 0.7926 - recall: 0.4697 - val_auc: 0.8641 - val_binary_accuracy: 0.7279 - val_loss: 0.5384 - val_precision: 0.8000 - val_recall: 0.4809 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 93/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8729 - binary_accuracy: 0.7258 - loss: 0.5283 - precision: 0.7934 - recall: 0.4845 - val_auc: 0.8658 - val_binary_accuracy: 0.7372 - val_loss: 0.5365 - val_precision: 0.8070 - val_recall: 0.5027 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 94/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8757 - binary_accuracy: 0.7312 - loss: 0.5259 - precision: 0.7982 - recall: 0.4982 - val_auc: 0.8676 - val_binary_accuracy: 0.7442 - val_loss: 0.5347 - val_precision: 0.8120 - val_recall: 0.5191 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 95/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8779 - binary_accuracy: 0.7422 - loss: 0.5222 - precision: 0.8034 - recall: 0.5193 - val_auc: 0.8694 - val_binary_accuracy: 0.7465 - val_loss: 0.5328 - val_precision: 0.8136 - val_recall: 0.5246 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 96/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8789 - binary_accuracy: 0.7484 - loss: 0.5223 - precision: 0.8098 - recall: 0.5418 - val_auc: 0.8704 - val_binary_accuracy: 0.7512 - val_loss: 0.5311 - val_precision: 0.8167 - val_recall: 0.5355 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 97/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8812 - binary_accuracy: 0.7602 - loss: 0.5191 - precision: 0.8153 - recall: 0.5659 - val_auc: 0.8720 - val_binary_accuracy: 0.7628 - val_loss: 0.5292 - val_precision: 0.8240 - val_recall: 0.5628 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 98/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8840 - binary_accuracy: 0.7695 - loss: 0.5170 - precision: 0.8214 - recall: 0.5887 - val_auc: 0.8737 - val_binary_accuracy: 0.7698 - val_loss: 0.5275 - val_precision: 0.8281 - val_recall: 0.5792 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 99/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8848 - binary_accuracy: 0.7727 - loss: 0.5154 - precision: 0.8221 - recall: 0.5985 - val_auc: 0.8743 - val_binary_accuracy: 0.7814 - val_loss: 0.5257 - val_precision: 0.8346 - val_recall: 0.6066 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 100/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8869 - binary_accuracy: 0.7781 - loss: 0.5130 - precision: 0.8263 - recall: 0.6088 - val_auc: 0.8755 - val_binary_accuracy: 0.7837 - val_loss: 0.5240 - val_precision: 0.8309 - val_recall: 0.6175 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 101/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8882 - binary_accuracy: 0.7844 - loss: 0.5113 - precision: 0.8265 - recall: 0.6271 - val_auc: 0.8765 - val_binary_accuracy: 0.7837 - val_loss: 0.5223 - val_precision: 0.8261 - val_recall: 0.6230 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 102/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8898 - binary_accuracy: 0.7922 - loss: 0.5092 - precision: 0.8337 - recall: 0.6417 - val_auc: 0.8780 - val_binary_accuracy: 0.7884 - val_loss: 0.5206 - val_precision: 0.8286 - val_recall: 0.6339 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 103/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8919 - binary_accuracy: 0.7937 - loss: 0.5078 - precision: 0.8333 - recall: 0.6478 - val_auc: 0.8789 - val_binary_accuracy: 0.7884 - val_loss: 0.5190 - val_precision: 0.8286 - val_recall: 0.6339 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 104/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8931 - binary_accuracy: 0.7992 - loss: 0.5064 - precision: 0.8349 - recall: 0.6630 - val_auc: 0.8798 - val_binary_accuracy: 0.7953 - val_loss: 0.5173 - val_precision: 0.8322 - val_recall: 0.6503 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 105/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8948 - binary_accuracy: 0.8117 - loss: 0.5021 - precision: 0.8404 - recall: 0.6875 - val_auc: 0.8803 - val_binary_accuracy: 0.7930 - val_loss: 0.5157 - val_precision: 0.8264 - val_recall: 0.6503 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 106/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8946 - binary_accuracy: 0.8094 - loss: 0.5026 - precision: 0.8404 - recall: 0.6837 - val_auc: 0.8813 - val_binary_accuracy: 0.7930 - val_loss: 0.5141 - val_precision: 0.8264 - val_recall: 0.6503 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 107/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8964 - binary_accuracy: 0.8094 - loss: 0.5000 - precision: 0.8393 - recall: 0.6861 - val_auc: 0.8827 - val_binary_accuracy: 0.7953 - val_loss: 0.5126 - val_precision: 0.8276 - val_recall: 0.6557 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 108/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8980 - binary_accuracy: 0.8141 - loss: 0.4974 - precision: 0.8392 - recall: 0.6978 - val_auc: 0.8844 - val_binary_accuracy: 0.8000 - val_loss: 0.5110 - val_precision: 0.8299 - val_recall: 0.6667 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 109/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8995 - binary_accuracy: 0.8148 - loss: 0.4953 - precision: 0.8392 - recall: 0.6991 - val_auc: 0.8848 - val_binary_accuracy: 0.8023 - val_loss: 0.5095 - val_precision: 0.8267 - val_recall: 0.6776 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 110/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8997 - binary_accuracy: 0.8164 - loss: 0.4938 - precision: 0.8399 - recall: 0.7028 - val_auc: 0.8853 - val_binary_accuracy: 0.8047 - val_loss: 0.5080 - val_precision: 0.8278 - val_recall: 0.6831 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 111/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9012 - binary_accuracy: 0.8195 - loss: 0.4933 - precision: 0.8427 - recall: 0.7122 - val_auc: 0.8861 - val_binary_accuracy: 0.8047 - val_loss: 0.5065 - val_precision: 0.8278 - val_recall: 0.6831 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 112/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9019 - binary_accuracy: 0.8203 - loss: 0.4920 - precision: 0.8433 - recall: 0.7145 - val_auc: 0.8867 - val_binary_accuracy: 0.8047 - val_loss: 0.5050 - val_precision: 0.8278 - val_recall: 0.6831 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 113/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9014 - binary_accuracy: 0.8219 - loss: 0.4898 - precision: 0.8412 - recall: 0.7179 - val_auc: 0.8876 - val_binary_accuracy: 0.8047 - val_loss: 0.5036 - val_precision: 0.8278 - val_recall: 0.6831 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 114/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9028 - binary_accuracy: 0.8234 - loss: 0.4879 - precision: 0.8422 - recall: 0.7221 - val_auc: 0.8881 - val_binary_accuracy: 0.8047 - val_loss: 0.5022 - val_precision: 0.8278 - val_recall: 0.6831 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 115/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9048 - binary_accuracy: 0.8234 - loss: 0.4854 - precision: 0.8448 - recall: 0.7179 - val_auc: 0.8891 - val_binary_accuracy: 0.8047 - val_loss: 0.5007 - val_precision: 0.8278 - val_recall: 0.6831 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 116/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9049 - binary_accuracy: 0.8273 - loss: 0.4842 - precision: 0.8468 - recall: 0.7276 - val_auc: 0.8895 - val_binary_accuracy: 0.8070 - val_loss: 0.4993 - val_precision: 0.8289 - val_recall: 0.6885 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 117/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9048 - binary_accuracy: 0.8273 - loss: 0.4834 - precision: 0.8450 - recall: 0.7289 - val_auc: 0.8908 - val_binary_accuracy: 0.8047 - val_loss: 0.4979 - val_precision: 0.8235 - val_recall: 0.6885 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 118/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9067 - binary_accuracy: 0.8289 - loss: 0.4812 - precision: 0.8460 - recall: 0.7331 - val_auc: 0.8916 - val_binary_accuracy: 0.8070 - val_loss: 0.4965 - val_precision: 0.8247 - val_recall: 0.6940 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 119/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9058 - binary_accuracy: 0.8320 - loss: 0.4793 - precision: 0.8463 - recall: 0.7390 - val_auc: 0.8924 - val_binary_accuracy: 0.8070 - val_loss: 0.4951 - val_precision: 0.8247 - val_recall: 0.6940 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 120/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9090 - binary_accuracy: 0.8336 - loss: 0.4759 - precision: 0.8455 - recall: 0.7445 - val_auc: 0.8925 - val_binary_accuracy: 0.8070 - val_loss: 0.4937 - val_precision: 0.8247 - val_recall: 0.6940 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 121/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9082 - binary_accuracy: 0.8313 - loss: 0.4765 - precision: 0.8476 - recall: 0.7395 - val_auc: 0.8935 - val_binary_accuracy: 0.8093 - val_loss: 0.4923 - val_precision: 0.8258 - val_recall: 0.6995 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 122/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9076 - binary_accuracy: 0.8320 - loss: 0.4756 - precision: 0.8441 - recall: 0.7436 - val_auc: 0.8943 - val_binary_accuracy: 0.8116 - val_loss: 0.4909 - val_precision: 0.8269 - val_recall: 0.7049 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 123/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9086 - binary_accuracy: 0.8328 - loss: 0.4727 - precision: 0.8441 - recall: 0.7450 - val_auc: 0.8948 - val_binary_accuracy: 0.8140 - val_loss: 0.4895 - val_precision: 0.8280 - val_recall: 0.7104 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 124/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9113 - binary_accuracy: 0.8352 - loss: 0.4705 - precision: 0.8479 - recall: 0.7468 - val_auc: 0.8953 - val_binary_accuracy: 0.8140 - val_loss: 0.4881 - val_precision: 0.8280 - val_recall: 0.7104 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 125/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9099 - binary_accuracy: 0.8344 - loss: 0.4699 - precision: 0.8454 - recall: 0.7495 - val_auc: 0.8959 - val_binary_accuracy: 0.8093 - val_loss: 0.4867 - val_precision: 0.8176 - val_recall: 0.7104 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 126/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9101 - binary_accuracy: 0.8359 - loss: 0.4688 - precision: 0.8460 - recall: 0.7532 - val_auc: 0.8963 - val_binary_accuracy: 0.8116 - val_loss: 0.4853 - val_precision: 0.8188 - val_recall: 0.7158 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 127/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9115 - binary_accuracy: 0.8359 - loss: 0.4665 - precision: 0.8457 - recall: 0.7527 - val_auc: 0.8967 - val_binary_accuracy: 0.8116 - val_loss: 0.4839 - val_precision: 0.8188 - val_recall: 0.7158 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 128/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9123 - binary_accuracy: 0.8367 - loss: 0.4654 - precision: 0.8463 - recall: 0.7550 - val_auc: 0.8978 - val_binary_accuracy: 0.8140 - val_loss: 0.4825 - val_precision: 0.8199 - val_recall: 0.7213 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 129/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9108 - binary_accuracy: 0.8344 - loss: 0.4654 - precision: 0.8425 - recall: 0.7532 - val_auc: 0.8980 - val_binary_accuracy: 0.8116 - val_loss: 0.4811 - val_precision: 0.8110 - val_recall: 0.7268 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 130/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9122 - binary_accuracy: 0.8391 - loss: 0.4628 - precision: 0.8458 - recall: 0.7623 - val_auc: 0.8987 - val_binary_accuracy: 0.8116 - val_loss: 0.4797 - val_precision: 0.8110 - val_recall: 0.7268 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 131/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9133 - binary_accuracy: 0.8398 - loss: 0.4598 - precision: 0.8452 - recall: 0.7629 - val_auc: 0.8991 - val_binary_accuracy: 0.8116 - val_loss: 0.4782 - val_precision: 0.8110 - val_recall: 0.7268 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 132/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9133 - binary_accuracy: 0.8414 - loss: 0.4594 - precision: 0.8482 - recall: 0.7660 - val_auc: 0.8999 - val_binary_accuracy: 0.8116 - val_loss: 0.4768 - val_precision: 0.8110 - val_recall: 0.7268 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 133/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9141 - binary_accuracy: 0.8422 - loss: 0.4578 - precision: 0.8482 - recall: 0.7674 - val_auc: 0.9005 - val_binary_accuracy: 0.8140 - val_loss: 0.4753 - val_precision: 0.8121 - val_recall: 0.7322 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 134/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9141 - binary_accuracy: 0.8430 - loss: 0.4555 - precision: 0.8462 - recall: 0.7698 - val_auc: 0.9010 - val_binary_accuracy: 0.8116 - val_loss: 0.4738 - val_precision: 0.8072 - val_recall: 0.7322 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 135/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9140 - binary_accuracy: 0.8406 - loss: 0.4552 - precision: 0.8444 - recall: 0.7670 - val_auc: 0.9018 - val_binary_accuracy: 0.8140 - val_loss: 0.4723 - val_precision: 0.8084 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 136/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9142 - binary_accuracy: 0.8430 - loss: 0.4543 - precision: 0.8463 - recall: 0.7737 - val_auc: 0.9021 - val_binary_accuracy: 0.8116 - val_loss: 0.4708 - val_precision: 0.8036 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 137/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9164 - binary_accuracy: 0.8469 - loss: 0.4508 - precision: 0.8472 - recall: 0.7821 - val_auc: 0.9031 - val_binary_accuracy: 0.8093 - val_loss: 0.4693 - val_precision: 0.8024 - val_recall: 0.7322 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 138/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9165 - binary_accuracy: 0.8453 - loss: 0.4494 - precision: 0.8466 - recall: 0.7784 - val_auc: 0.9033 - val_binary_accuracy: 0.8093 - val_loss: 0.4678 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 139/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9159 - binary_accuracy: 0.8461 - loss: 0.4486 - precision: 0.8455 - recall: 0.7821 - val_auc: 0.9039 - val_binary_accuracy: 0.8093 - val_loss: 0.4662 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 140/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9164 - binary_accuracy: 0.8461 - loss: 0.4472 - precision: 0.8445 - recall: 0.7843 - val_auc: 0.9043 - val_binary_accuracy: 0.8093 - val_loss: 0.4647 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 141/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9167 - binary_accuracy: 0.8469 - loss: 0.4457 - precision: 0.8445 - recall: 0.7857 - val_auc: 0.9047 - val_binary_accuracy: 0.8093 - val_loss: 0.4631 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 142/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9176 - binary_accuracy: 0.8477 - loss: 0.4439 - precision: 0.8438 - recall: 0.7898 - val_auc: 0.9052 - val_binary_accuracy: 0.8093 - val_loss: 0.4615 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 143/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9177 - binary_accuracy: 0.8477 - loss: 0.4423 - precision: 0.8424 - recall: 0.7916 - val_auc: 0.9058 - val_binary_accuracy: 0.8093 - val_loss: 0.4600 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 144/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9192 - binary_accuracy: 0.8500 - loss: 0.4397 - precision: 0.8460 - recall: 0.7934 - val_auc: 0.9055 - val_binary_accuracy: 0.8093 - val_loss: 0.4584 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 145/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9189 - binary_accuracy: 0.8484 - loss: 0.4382 - precision: 0.8414 - recall: 0.7952 - val_auc: 0.9060 - val_binary_accuracy: 0.8116 - val_loss: 0.4568 - val_precision: 0.8000 - val_recall: 0.7432 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 146/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9195 - binary_accuracy: 0.8492 - loss: 0.4368 - precision: 0.8420 - recall: 0.7974 - val_auc: 0.9070 - val_binary_accuracy: 0.8140 - val_loss: 0.4553 - val_precision: 0.8012 - val_recall: 0.7486 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 147/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9193 - binary_accuracy: 0.8500 - loss: 0.4352 - precision: 0.8407 - recall: 0.8007 - val_auc: 0.9075 - val_binary_accuracy: 0.8163 - val_loss: 0.4537 - val_precision: 0.8023 - val_recall: 0.7541 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 148/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9209 - binary_accuracy: 0.8484 - loss: 0.4316 - precision: 0.8369 - recall: 0.8000 - val_auc: 0.9077 - val_binary_accuracy: 0.8186 - val_loss: 0.4521 - val_precision: 0.8035 - val_recall: 0.7596 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 149/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9204 - binary_accuracy: 0.8484 - loss: 0.4312 - precision: 0.8369 - recall: 0.8000 - val_auc: 0.9076 - val_binary_accuracy: 0.8186 - val_loss: 0.4506 - val_precision: 0.8035 - val_recall: 0.7596 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 150/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9204 - binary_accuracy: 0.8477 - loss: 0.4300 - precision: 0.8369 - recall: 0.7985 - val_auc: 0.9080 - val_binary_accuracy: 0.8186 - val_loss: 0.4490 - val_precision: 0.8035 - val_recall: 0.7596 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 151/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9208 - binary_accuracy: 0.8477 - loss: 0.4285 - precision: 0.8372 - recall: 0.7989 - val_auc: 0.9089 - val_binary_accuracy: 0.8186 - val_loss: 0.4475 - val_precision: 0.8035 - val_recall: 0.7596 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 152/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9211 - binary_accuracy: 0.8477 - loss: 0.4267 - precision: 0.8352 - recall: 0.8000 - val_auc: 0.9092 - val_binary_accuracy: 0.8209 - val_loss: 0.4460 - val_precision: 0.8046 - val_recall: 0.7650 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 153/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9221 - binary_accuracy: 0.8484 - loss: 0.4247 - precision: 0.8375 - recall: 0.8007 - val_auc: 0.9090 - val_binary_accuracy: 0.8209 - val_loss: 0.4445 - val_precision: 0.8046 - val_recall: 0.7650 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 154/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9219 - binary_accuracy: 0.8484 - loss: 0.4229 - precision: 0.8359 - recall: 0.8022 - val_auc: 0.9092 - val_binary_accuracy: 0.8233 - val_loss: 0.4429 - val_precision: 0.8057 - val_recall: 0.7705 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 155/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9224 - binary_accuracy: 0.8500 - loss: 0.4204 - precision: 0.8369 - recall: 0.8029 - val_auc: 0.9101 - val_binary_accuracy: 0.8233 - val_loss: 0.4414 - val_precision: 0.8057 - val_recall: 0.7705 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 156/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9224 - binary_accuracy: 0.8500 - loss: 0.4198 - precision: 0.8375 - recall: 0.8037 - val_auc: 0.9105 - val_binary_accuracy: 0.8256 - val_loss: 0.4399 - val_precision: 0.8068 - val_recall: 0.7760 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 157/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9230 - binary_accuracy: 0.8500 - loss: 0.4181 - precision: 0.8384 - recall: 0.8047 - val_auc: 0.9109 - val_binary_accuracy: 0.8256 - val_loss: 0.4384 - val_precision: 0.8068 - val_recall: 0.7760 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 158/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9230 - binary_accuracy: 0.8492 - loss: 0.4169 - precision: 0.8349 - recall: 0.8059 - val_auc: 0.9110 - val_binary_accuracy: 0.8256 - val_loss: 0.4370 - val_precision: 0.8068 - val_recall: 0.7760 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 159/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9242 - binary_accuracy: 0.8508 - loss: 0.4140 - precision: 0.8352 - recall: 0.8092 - val_auc: 0.9114 - val_binary_accuracy: 0.8279 - val_loss: 0.4355 - val_precision: 0.8079 - val_recall: 0.7814 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 160/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9248 - binary_accuracy: 0.8516 - loss: 0.4126 - precision: 0.8377 - recall: 0.8102 - val_auc: 0.9118 - val_binary_accuracy: 0.8302 - val_loss: 0.4340 - val_precision: 0.8090 - val_recall: 0.7869 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 161/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9248 - binary_accuracy: 0.8508 - loss: 0.4108 - precision: 0.8346 - recall: 0.8117 - val_auc: 0.9122 - val_binary_accuracy: 0.8302 - val_loss: 0.4326 - val_precision: 0.8090 - val_recall: 0.7869 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 162/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9248 - binary_accuracy: 0.8508 - loss: 0.4105 - precision: 0.8365 - recall: 0.8106 - val_auc: 0.9125 - val_binary_accuracy: 0.8326 - val_loss: 0.4312 - val_precision: 0.8101 - val_recall: 0.7923 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 163/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9249 - binary_accuracy: 0.8492 - loss: 0.4093 - precision: 0.8330 - recall: 0.8102 - val_auc: 0.9126 - val_binary_accuracy: 0.8349 - val_loss: 0.4297 - val_precision: 0.8111 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 164/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9254 - binary_accuracy: 0.8500 - loss: 0.4068 - precision: 0.8327 - recall: 0.8114 - val_auc: 0.9133 - val_binary_accuracy: 0.8326 - val_loss: 0.4283 - val_precision: 0.8066 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 165/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9254 - binary_accuracy: 0.8484 - loss: 0.4055 - precision: 0.8315 - recall: 0.8102 - val_auc: 0.9134 - val_binary_accuracy: 0.8326 - val_loss: 0.4269 - val_precision: 0.8066 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 166/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9258 - binary_accuracy: 0.8484 - loss: 0.4036 - precision: 0.8315 - recall: 0.8102 - val_auc: 0.9137 - val_binary_accuracy: 0.8302 - val_loss: 0.4255 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 167/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9266 - binary_accuracy: 0.8500 - loss: 0.4014 - precision: 0.8327 - recall: 0.8114 - val_auc: 0.9140 - val_binary_accuracy: 0.8302 - val_loss: 0.4241 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 168/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9280 - binary_accuracy: 0.8492 - loss: 0.3994 - precision: 0.8315 - recall: 0.8117 - val_auc: 0.9140 - val_binary_accuracy: 0.8302 - val_loss: 0.4228 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 169/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9269 - binary_accuracy: 0.8477 - loss: 0.3987 - precision: 0.8284 - recall: 0.8117 - val_auc: 0.9142 - val_binary_accuracy: 0.8302 - val_loss: 0.4214 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 170/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9280 - binary_accuracy: 0.8492 - loss: 0.3964 - precision: 0.8318 - recall: 0.8120 - val_auc: 0.9146 - val_binary_accuracy: 0.8302 - val_loss: 0.4201 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 171/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9273 - binary_accuracy: 0.8492 - loss: 0.3954 - precision: 0.8302 - recall: 0.8135 - val_auc: 0.9150 - val_binary_accuracy: 0.8302 - val_loss: 0.4188 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 172/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9295 - binary_accuracy: 0.8508 - loss: 0.3904 - precision: 0.8278 - recall: 0.8202 - val_auc: 0.9151 - val_binary_accuracy: 0.8302 - val_loss: 0.4175 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 173/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9274 - binary_accuracy: 0.8484 - loss: 0.3930 - precision: 0.8271 - recall: 0.8150 - val_auc: 0.9152 - val_binary_accuracy: 0.8302 - val_loss: 0.4162 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 174/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9288 - binary_accuracy: 0.8500 - loss: 0.3902 - precision: 0.8305 - recall: 0.8154 - val_auc: 0.9157 - val_binary_accuracy: 0.8326 - val_loss: 0.4150 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 175/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9283 - binary_accuracy: 0.8500 - loss: 0.3904 - precision: 0.8284 - recall: 0.8193 - val_auc: 0.9156 - val_binary_accuracy: 0.8326 - val_loss: 0.4138 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 176/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9285 - binary_accuracy: 0.8516 - loss: 0.3884 - precision: 0.8287 - recall: 0.8227 - val_auc: 0.9156 - val_binary_accuracy: 0.8326 - val_loss: 0.4125 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 177/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9286 - binary_accuracy: 0.8508 - loss: 0.3866 - precision: 0.8284 - recall: 0.8208 - val_auc: 0.9160 - val_binary_accuracy: 0.8302 - val_loss: 0.4113 - val_precision: 0.7989 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 178/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9287 - binary_accuracy: 0.8508 - loss: 0.3857 - precision: 0.8287 - recall: 0.8212 - val_auc: 0.9163 - val_binary_accuracy: 0.8302 - val_loss: 0.4101 - val_precision: 0.7989 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 179/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9300 - binary_accuracy: 0.8523 - loss: 0.3829 - precision: 0.8278 - recall: 0.8263 - val_auc: 0.9164 - val_binary_accuracy: 0.8302 - val_loss: 0.4089 - val_precision: 0.7989 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 180/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9297 - binary_accuracy: 0.8523 - loss: 0.3819 - precision: 0.8278 - recall: 0.8263 - val_auc: 0.9166 - val_binary_accuracy: 0.8302 - val_loss: 0.4077 - val_precision: 0.7989 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 181/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9300 - binary_accuracy: 0.8508 - loss: 0.3807 - precision: 0.8278 - recall: 0.8233 - val_auc: 0.9168 - val_binary_accuracy: 0.8302 - val_loss: 0.4065 - val_precision: 0.7989 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 182/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9298 - binary_accuracy: 0.8539 - loss: 0.3795 - precision: 0.8278 - recall: 0.8294 - val_auc: 0.9172 - val_binary_accuracy: 0.8256 - val_loss: 0.4054 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 183/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9303 - binary_accuracy: 0.8531 - loss: 0.3778 - precision: 0.8251 - recall: 0.8312 - val_auc: 0.9173 - val_binary_accuracy: 0.8256 - val_loss: 0.4043 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 184/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9299 - binary_accuracy: 0.8531 - loss: 0.3773 - precision: 0.8263 - recall: 0.8294 - val_auc: 0.9172 - val_binary_accuracy: 0.8256 - val_loss: 0.4032 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 185/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9299 - binary_accuracy: 0.8547 - loss: 0.3765 - precision: 0.8270 - recall: 0.8330 - val_auc: 0.9174 - val_binary_accuracy: 0.8256 - val_loss: 0.4021 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 186/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9302 - binary_accuracy: 0.8547 - loss: 0.3758 - precision: 0.8282 - recall: 0.8342 - val_auc: 0.9178 - val_binary_accuracy: 0.8256 - val_loss: 0.4011 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 187/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9309 - binary_accuracy: 0.8562 - loss: 0.3737 - precision: 0.8300 - recall: 0.8361 - val_auc: 0.9174 - val_binary_accuracy: 0.8256 - val_loss: 0.4000 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 188/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9319 - binary_accuracy: 0.8578 - loss: 0.3708 - precision: 0.8285 - recall: 0.8407 - val_auc: 0.9177 - val_binary_accuracy: 0.8256 - val_loss: 0.3990 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 189/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9319 - binary_accuracy: 0.8586 - loss: 0.3706 - precision: 0.8321 - recall: 0.8397 - val_auc: 0.9176 - val_binary_accuracy: 0.8256 - val_loss: 0.3980 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 190/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9311 - binary_accuracy: 0.8570 - loss: 0.3698 - precision: 0.8276 - recall: 0.8382 - val_auc: 0.9178 - val_binary_accuracy: 0.8256 - val_loss: 0.3970 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 191/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9313 - binary_accuracy: 0.8578 - loss: 0.3689 - precision: 0.8303 - recall: 0.8394 - val_auc: 0.9178 - val_binary_accuracy: 0.8256 - val_loss: 0.3960 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 192/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9323 - binary_accuracy: 0.8586 - loss: 0.3665 - precision: 0.8315 - recall: 0.8391 - val_auc: 0.9181 - val_binary_accuracy: 0.8256 - val_loss: 0.3950 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 193/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9322 - binary_accuracy: 0.8586 - loss: 0.3653 - precision: 0.8300 - recall: 0.8407 - val_auc: 0.9183 - val_binary_accuracy: 0.8279 - val_loss: 0.3941 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 194/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9319 - binary_accuracy: 0.8578 - loss: 0.3652 - precision: 0.8285 - recall: 0.8407 - val_auc: 0.9181 - val_binary_accuracy: 0.8279 - val_loss: 0.3931 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 195/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9322 - binary_accuracy: 0.8578 - loss: 0.3637 - precision: 0.8285 - recall: 0.8407 - val_auc: 0.9185 - val_binary_accuracy: 0.8279 - val_loss: 0.3922 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 196/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9335 - binary_accuracy: 0.8602 - loss: 0.3611 - precision: 0.8324 - recall: 0.8431 - val_auc: 0.9187 - val_binary_accuracy: 0.8279 - val_loss: 0.3913 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 197/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9320 - binary_accuracy: 0.8586 - loss: 0.3627 - precision: 0.8291 - recall: 0.8428 - val_auc: 0.9186 - val_binary_accuracy: 0.8302 - val_loss: 0.3904 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 198/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9324 - binary_accuracy: 0.8586 - loss: 0.3609 - precision: 0.8288 - recall: 0.8425 - val_auc: 0.9189 - val_binary_accuracy: 0.8302 - val_loss: 0.3896 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 199/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9340 - binary_accuracy: 0.8617 - loss: 0.3574 - precision: 0.8309 - recall: 0.8477 - val_auc: 0.9189 - val_binary_accuracy: 0.8302 - val_loss: 0.3887 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 200/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9332 - binary_accuracy: 0.8602 - loss: 0.3583 - precision: 0.8306 - recall: 0.8443 - val_auc: 0.9190 - val_binary_accuracy: 0.8302 - val_loss: 0.3878 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 201/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9336 - binary_accuracy: 0.8609 - loss: 0.3563 - precision: 0.8291 - recall: 0.8474 - val_auc: 0.9192 - val_binary_accuracy: 0.8302 - val_loss: 0.3870 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 202/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9331 - binary_accuracy: 0.8602 - loss: 0.3570 - precision: 0.8312 - recall: 0.8449 - val_auc: 0.9191 - val_binary_accuracy: 0.8302 - val_loss: 0.3862 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 203/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9339 - binary_accuracy: 0.8617 - loss: 0.3548 - precision: 0.8318 - recall: 0.8485 - val_auc: 0.9193 - val_binary_accuracy: 0.8326 - val_loss: 0.3854 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 204/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9330 - binary_accuracy: 0.8586 - loss: 0.3553 - precision: 0.8262 - recall: 0.8459 - val_auc: 0.9194 - val_binary_accuracy: 0.8326 - val_loss: 0.3847 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 205/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9335 - binary_accuracy: 0.8594 - loss: 0.3544 - precision: 0.8283 - recall: 0.8464 - val_auc: 0.9197 - val_binary_accuracy: 0.8326 - val_loss: 0.3839 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 206/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9339 - binary_accuracy: 0.8586 - loss: 0.3533 - precision: 0.8274 - recall: 0.8470 - val_auc: 0.9197 - val_binary_accuracy: 0.8326 - val_loss: 0.3832 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 207/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9344 - binary_accuracy: 0.8602 - loss: 0.3514 - precision: 0.8256 - recall: 0.8514 - val_auc: 0.9196 - val_binary_accuracy: 0.8326 - val_loss: 0.3825 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 208/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9337 - binary_accuracy: 0.8586 - loss: 0.3516 - precision: 0.8253 - recall: 0.8480 - val_auc: 0.9199 - val_binary_accuracy: 0.8326 - val_loss: 0.3818 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 209/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9341 - binary_accuracy: 0.8602 - loss: 0.3500 - precision: 0.8256 - recall: 0.8514 - val_auc: 0.9200 - val_binary_accuracy: 0.8302 - val_loss: 0.3811 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 210/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9345 - binary_accuracy: 0.8602 - loss: 0.3493 - precision: 0.8280 - recall: 0.8506 - val_auc: 0.9199 - val_binary_accuracy: 0.8302 - val_loss: 0.3805 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 211/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9349 - binary_accuracy: 0.8609 - loss: 0.3476 - precision: 0.8289 - recall: 0.8501 - val_auc: 0.9198 - val_binary_accuracy: 0.8302 - val_loss: 0.3798 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 212/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9341 - binary_accuracy: 0.8602 - loss: 0.3479 - precision: 0.8253 - recall: 0.8511 - val_auc: 0.9201 - val_binary_accuracy: 0.8302 - val_loss: 0.3792 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 213/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8617 - loss: 0.3457 - precision: 0.8271 - recall: 0.8529 - val_auc: 0.9201 - val_binary_accuracy: 0.8302 - val_loss: 0.3786 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 214/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9344 - binary_accuracy: 0.8602 - loss: 0.3468 - precision: 0.8256 - recall: 0.8514 - val_auc: 0.9203 - val_binary_accuracy: 0.8279 - val_loss: 0.3780 - val_precision: 0.7884 - val_recall: 0.8142 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 215/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9347 - binary_accuracy: 0.8609 - loss: 0.3457 - precision: 0.8274 - recall: 0.8516 - val_auc: 0.9204 - val_binary_accuracy: 0.8302 - val_loss: 0.3774 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 216/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9355 - binary_accuracy: 0.8633 - loss: 0.3435 - precision: 0.8295 - recall: 0.8553 - val_auc: 0.9206 - val_binary_accuracy: 0.8302 - val_loss: 0.3768 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 217/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8617 - loss: 0.3436 - precision: 0.8283 - recall: 0.8540 - val_auc: 0.9205 - val_binary_accuracy: 0.8302 - val_loss: 0.3763 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 218/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8625 - loss: 0.3426 - precision: 0.8289 - recall: 0.8532 - val_auc: 0.9207 - val_binary_accuracy: 0.8302 - val_loss: 0.3757 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 219/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9357 - binary_accuracy: 0.8625 - loss: 0.3420 - precision: 0.8272 - recall: 0.8574 - val_auc: 0.9207 - val_binary_accuracy: 0.8302 - val_loss: 0.3751 - val_precision: 0.7895 - val_recall: 0.8197 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 220/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8617 - loss: 0.3421 - precision: 0.8269 - recall: 0.8556 - val_auc: 0.9208 - val_binary_accuracy: 0.8326 - val_loss: 0.3746 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 221/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8609 - loss: 0.3416 - precision: 0.8265 - recall: 0.8537 - val_auc: 0.9209 - val_binary_accuracy: 0.8326 - val_loss: 0.3741 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 222/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9355 - binary_accuracy: 0.8633 - loss: 0.3406 - precision: 0.8289 - recall: 0.8577 - val_auc: 0.9210 - val_binary_accuracy: 0.8326 - val_loss: 0.3736 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 223/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9353 - binary_accuracy: 0.8625 - loss: 0.3406 - precision: 0.8278 - recall: 0.8579 - val_auc: 0.9211 - val_binary_accuracy: 0.8326 - val_loss: 0.3731 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 224/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9354 - binary_accuracy: 0.8625 - loss: 0.3397 - precision: 0.8272 - recall: 0.8574 - val_auc: 0.9212 - val_binary_accuracy: 0.8326 - val_loss: 0.3726 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 225/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9359 - binary_accuracy: 0.8633 - loss: 0.3380 - precision: 0.8283 - recall: 0.8571 - val_auc: 0.9214 - val_binary_accuracy: 0.8326 - val_loss: 0.3722 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 226/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9357 - binary_accuracy: 0.8633 - loss: 0.3381 - precision: 0.8269 - recall: 0.8587 - val_auc: 0.9212 - val_binary_accuracy: 0.8326 - val_loss: 0.3718 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 227/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9358 - binary_accuracy: 0.8633 - loss: 0.3375 - precision: 0.8275 - recall: 0.8592 - val_auc: 0.9213 - val_binary_accuracy: 0.8326 - val_loss: 0.3713 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 228/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9359 - binary_accuracy: 0.8648 - loss: 0.3367 - precision: 0.8289 - recall: 0.8608 - val_auc: 0.9212 - val_binary_accuracy: 0.8326 - val_loss: 0.3709 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 229/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9368 - binary_accuracy: 0.8648 - loss: 0.3349 - precision: 0.8316 - recall: 0.8574 - val_auc: 0.9214 - val_binary_accuracy: 0.8349 - val_loss: 0.3705 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 230/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9363 - binary_accuracy: 0.8633 - loss: 0.3350 - precision: 0.8280 - recall: 0.8569 - val_auc: 0.9216 - val_binary_accuracy: 0.8349 - val_loss: 0.3701 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 231/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9357 - binary_accuracy: 0.8633 - loss: 0.3357 - precision: 0.8269 - recall: 0.8587 - val_auc: 0.9215 - val_binary_accuracy: 0.8349 - val_loss: 0.3697 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 232/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8617 - loss: 0.3344 - precision: 0.8260 - recall: 0.8577 - val_auc: 0.9215 - val_binary_accuracy: 0.8349 - val_loss: 0.3693 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 233/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9356 - binary_accuracy: 0.8617 - loss: 0.3351 - precision: 0.8257 - recall: 0.8574 - val_auc: 0.9215 - val_binary_accuracy: 0.8349 - val_loss: 0.3690 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 234/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9367 - binary_accuracy: 0.8625 - loss: 0.3320 - precision: 0.8269 - recall: 0.8571 - val_auc: 0.9217 - val_binary_accuracy: 0.8349 - val_loss: 0.3686 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 235/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9367 - binary_accuracy: 0.8625 - loss: 0.3319 - precision: 0.8280 - recall: 0.8553 - val_auc: 0.9216 - val_binary_accuracy: 0.8349 - val_loss: 0.3683 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 236/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8617 - loss: 0.3327 - precision: 0.8269 - recall: 0.8556 - val_auc: 0.9217 - val_binary_accuracy: 0.8349 - val_loss: 0.3679 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 237/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8609 - loss: 0.3329 - precision: 0.8251 - recall: 0.8553 - val_auc: 0.9219 - val_binary_accuracy: 0.8349 - val_loss: 0.3676 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 238/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8617 - loss: 0.3307 - precision: 0.8269 - recall: 0.8556 - val_auc: 0.9218 - val_binary_accuracy: 0.8372 - val_loss: 0.3673 - val_precision: 0.7927 - val_recall: 0.8361 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 239/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8617 - loss: 0.3315 - precision: 0.8257 - recall: 0.8574 - val_auc: 0.9220 - val_binary_accuracy: 0.8372 - val_loss: 0.3670 - val_precision: 0.7927 - val_recall: 0.8361 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 240/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9363 - binary_accuracy: 0.8617 - loss: 0.3313 - precision: 0.8260 - recall: 0.8577 - val_auc: 0.9219 - val_binary_accuracy: 0.8349 - val_loss: 0.3667 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 241/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8625 - loss: 0.3296 - precision: 0.8260 - recall: 0.8592 - val_auc: 0.9219 - val_binary_accuracy: 0.8349 - val_loss: 0.3664 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 242/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9363 - binary_accuracy: 0.8617 - loss: 0.3304 - precision: 0.8251 - recall: 0.8569 - val_auc: 0.9222 - val_binary_accuracy: 0.8349 - val_loss: 0.3661 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 243/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9374 - binary_accuracy: 0.8633 - loss: 0.3282 - precision: 0.8283 - recall: 0.8571 - val_auc: 0.9223 - val_binary_accuracy: 0.8349 - val_loss: 0.3658 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 244/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8641 - loss: 0.3277 - precision: 0.8319 - recall: 0.8561 - val_auc: 0.9221 - val_binary_accuracy: 0.8349 - val_loss: 0.3655 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 245/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9378 - binary_accuracy: 0.8648 - loss: 0.3271 - precision: 0.8304 - recall: 0.8592 - val_auc: 0.9221 - val_binary_accuracy: 0.8349 - val_loss: 0.3653 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 246/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9372 - binary_accuracy: 0.8641 - loss: 0.3276 - precision: 0.8307 - recall: 0.8579 - val_auc: 0.9220 - val_binary_accuracy: 0.8349 - val_loss: 0.3650 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 247/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8648 - loss: 0.3242 - precision: 0.8289 - recall: 0.8608 - val_auc: 0.9222 - val_binary_accuracy: 0.8349 - val_loss: 0.3647 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 248/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8656 - loss: 0.3256 - precision: 0.8298 - recall: 0.8603 - val_auc: 0.9223 - val_binary_accuracy: 0.8349 - val_loss: 0.3645 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 249/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8656 - loss: 0.3276 - precision: 0.8292 - recall: 0.8626 - val_auc: 0.9223 - val_binary_accuracy: 0.8349 - val_loss: 0.3643 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 250/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8664 - loss: 0.3252 - precision: 0.8304 - recall: 0.8624 - val_auc: 0.9225 - val_binary_accuracy: 0.8349 - val_loss: 0.3640 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 251/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9374 - binary_accuracy: 0.8664 - loss: 0.3259 - precision: 0.8292 - recall: 0.8642 - val_auc: 0.9225 - val_binary_accuracy: 0.8349 - val_loss: 0.3638 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 252/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9373 - binary_accuracy: 0.8664 - loss: 0.3262 - precision: 0.8313 - recall: 0.8631 - val_auc: 0.9224 - val_binary_accuracy: 0.8349 - val_loss: 0.3636 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 253/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9376 - binary_accuracy: 0.8672 - loss: 0.3252 - precision: 0.8310 - recall: 0.8645 - val_auc: 0.9224 - val_binary_accuracy: 0.8349 - val_loss: 0.3634 - val_precision: 0.7917 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 254/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9382 - binary_accuracy: 0.8680 - loss: 0.3234 - precision: 0.8322 - recall: 0.8642 - val_auc: 0.9224 - val_binary_accuracy: 0.8326 - val_loss: 0.3632 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 255/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9371 - binary_accuracy: 0.8664 - loss: 0.3257 - precision: 0.8310 - recall: 0.8629 - val_auc: 0.9224 - val_binary_accuracy: 0.8326 - val_loss: 0.3630 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 256/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8672 - loss: 0.3246 - precision: 0.8330 - recall: 0.8634 - val_auc: 0.9225 - val_binary_accuracy: 0.8302 - val_loss: 0.3628 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 257/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8664 - loss: 0.3238 - precision: 0.8304 - recall: 0.8624 - val_auc: 0.9225 - val_binary_accuracy: 0.8302 - val_loss: 0.3626 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 258/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8672 - loss: 0.3233 - precision: 0.8307 - recall: 0.8642 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3624 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 259/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9382 - binary_accuracy: 0.8672 - loss: 0.3226 - precision: 0.8319 - recall: 0.8624 - val_auc: 0.9226 - val_binary_accuracy: 0.8302 - val_loss: 0.3623 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 260/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9384 - binary_accuracy: 0.8656 - loss: 0.3220 - precision: 0.8289 - recall: 0.8624 - val_auc: 0.9226 - val_binary_accuracy: 0.8302 - val_loss: 0.3621 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 261/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8648 - loss: 0.3232 - precision: 0.8292 - recall: 0.8611 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3620 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 262/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8672 - loss: 0.3212 - precision: 0.8327 - recall: 0.8631 - val_auc: 0.9226 - val_binary_accuracy: 0.8302 - val_loss: 0.3618 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 263/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8648 - loss: 0.3223 - precision: 0.8292 - recall: 0.8611 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3616 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 264/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8648 - loss: 0.3219 - precision: 0.8283 - recall: 0.8603 - val_auc: 0.9228 - val_binary_accuracy: 0.8302 - val_loss: 0.3614 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 265/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9384 - binary_accuracy: 0.8656 - loss: 0.3214 - precision: 0.8298 - recall: 0.8631 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3613 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 266/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9383 - binary_accuracy: 0.8656 - loss: 0.3211 - precision: 0.8304 - recall: 0.8608 - val_auc: 0.9226 - val_binary_accuracy: 0.8302 - val_loss: 0.3611 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 267/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8648 - loss: 0.3218 - precision: 0.8289 - recall: 0.8608 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3610 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 268/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9385 - binary_accuracy: 0.8648 - loss: 0.3206 - precision: 0.8283 - recall: 0.8603 - val_auc: 0.9228 - val_binary_accuracy: 0.8302 - val_loss: 0.3608 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 269/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8648 - loss: 0.3193 - precision: 0.8289 - recall: 0.8608 - val_auc: 0.9228 - val_binary_accuracy: 0.8302 - val_loss: 0.3607 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 270/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8656 - loss: 0.3198 - precision: 0.8289 - recall: 0.8624 - val_auc: 0.9229 - val_binary_accuracy: 0.8302 - val_loss: 0.3605 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 271/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9394 - binary_accuracy: 0.8656 - loss: 0.3181 - precision: 0.8336 - recall: 0.8579 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3604 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 272/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9390 - binary_accuracy: 0.8664 - loss: 0.3188 - precision: 0.8330 - recall: 0.8590 - val_auc: 0.9226 - val_binary_accuracy: 0.8302 - val_loss: 0.3603 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 273/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8656 - loss: 0.3194 - precision: 0.8319 - recall: 0.8592 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3602 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 274/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9382 - binary_accuracy: 0.8641 - loss: 0.3202 - precision: 0.8298 - recall: 0.8571 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3600 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 275/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9394 - binary_accuracy: 0.8672 - loss: 0.3174 - precision: 0.8330 - recall: 0.8606 - val_auc: 0.9228 - val_binary_accuracy: 0.8302 - val_loss: 0.3599 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 276/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8664 - loss: 0.3191 - precision: 0.8322 - recall: 0.8611 - val_auc: 0.9228 - val_binary_accuracy: 0.8302 - val_loss: 0.3598 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 277/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9390 - binary_accuracy: 0.8672 - loss: 0.3184 - precision: 0.8339 - recall: 0.8613 - val_auc: 0.9227 - val_binary_accuracy: 0.8302 - val_loss: 0.3597 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 278/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8672 - loss: 0.3177 - precision: 0.8342 - recall: 0.8616 - val_auc: 0.9228 - val_binary_accuracy: 0.8326 - val_loss: 0.3596 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 279/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9389 - binary_accuracy: 0.8664 - loss: 0.3181 - precision: 0.8333 - recall: 0.8592 - val_auc: 0.9229 - val_binary_accuracy: 0.8326 - val_loss: 0.3595 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 280/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9386 - binary_accuracy: 0.8656 - loss: 0.3190 - precision: 0.8319 - recall: 0.8592 - val_auc: 0.9229 - val_binary_accuracy: 0.8326 - val_loss: 0.3594 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 281/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8664 - loss: 0.3182 - precision: 0.8336 - recall: 0.8595 - val_auc: 0.9229 - val_binary_accuracy: 0.8326 - val_loss: 0.3593 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 282/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8656 - loss: 0.3175 - precision: 0.8319 - recall: 0.8592 - val_auc: 0.9230 - val_binary_accuracy: 0.8326 - val_loss: 0.3592 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 283/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8641 - loss: 0.3183 - precision: 0.8292 - recall: 0.8566 - val_auc: 0.9230 - val_binary_accuracy: 0.8326 - val_loss: 0.3591 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 284/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9390 - binary_accuracy: 0.8656 - loss: 0.3174 - precision: 0.8313 - recall: 0.8587 - val_auc: 0.9228 - val_binary_accuracy: 0.8326 - val_loss: 0.3590 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 285/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8641 - loss: 0.3180 - precision: 0.8298 - recall: 0.8571 - val_auc: 0.9228 - val_binary_accuracy: 0.8326 - val_loss: 0.3589 - val_precision: 0.7906 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 286/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8641 - loss: 0.3178 - precision: 0.8292 - recall: 0.8566 - val_auc: 0.9229 - val_binary_accuracy: 0.8349 - val_loss: 0.3589 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 287/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8656 - loss: 0.3170 - precision: 0.8316 - recall: 0.8590 - val_auc: 0.9229 - val_binary_accuracy: 0.8349 - val_loss: 0.3588 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 288/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8648 - loss: 0.3170 - precision: 0.8301 - recall: 0.8590 - val_auc: 0.9229 - val_binary_accuracy: 0.8349 - val_loss: 0.3587 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 289/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9389 - binary_accuracy: 0.8641 - loss: 0.3178 - precision: 0.8304 - recall: 0.8577 - val_auc: 0.9230 - val_binary_accuracy: 0.8349 - val_loss: 0.3586 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 290/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8641 - loss: 0.3169 - precision: 0.8304 - recall: 0.8577 - val_auc: 0.9231 - val_binary_accuracy: 0.8349 - val_loss: 0.3585 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 291/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9400 - binary_accuracy: 0.8656 - loss: 0.3149 - precision: 0.8330 - recall: 0.8574 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3584 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 292/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9399 - binary_accuracy: 0.8641 - loss: 0.3150 - precision: 0.8304 - recall: 0.8577 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3583 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 293/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9395 - binary_accuracy: 0.8641 - loss: 0.3156 - precision: 0.8286 - recall: 0.8590 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3583 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 294/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8633 - loss: 0.3167 - precision: 0.8286 - recall: 0.8574 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3582 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 295/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9403 - binary_accuracy: 0.8648 - loss: 0.3137 - precision: 0.8298 - recall: 0.8587 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3581 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 296/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9398 - binary_accuracy: 0.8648 - loss: 0.3152 - precision: 0.8304 - recall: 0.8592 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3580 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 297/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9405 - binary_accuracy: 0.8664 - loss: 0.3133 - precision: 0.8307 - recall: 0.8626 - val_auc: 0.9233 - val_binary_accuracy: 0.8349 - val_loss: 0.3580 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 298/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9409 - binary_accuracy: 0.8656 - loss: 0.3124 - precision: 0.8304 - recall: 0.8608 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3579 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 299/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8656 - loss: 0.3108 - precision: 0.8304 - recall: 0.8608 - val_auc: 0.9232 - val_binary_accuracy: 0.8349 - val_loss: 0.3578 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "Epoch 300/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9394 - binary_accuracy: 0.8648 - loss: 0.3154 - precision: 0.8298 - recall: 0.8587 - val_auc: 0.9233 - val_binary_accuracy: 0.8349 - val_loss: 0.3577 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 1.8642e-05\n",
      "\n",
      "./plots/abrasive-bug-506/learning_rate_vs_epoch.png                               \n",
      "./plots/abrasive-bug-506/auc_vs_epoch.png                                         \n",
      "./plots/abrasive-bug-506/loss_vs_epoch.png                                        \n",
      "./plots/abrasive-bug-506/binary_accuracy_vs_epoch.png                             \n",
      "./plots/abrasive-bug-506/recall_vs_epoch.png                                      \n",
      "./plots/abrasive-bug-506/precision_vs_epoch.png                                   \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 506ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step         \n",
      "\n",
      " 73%|███████▎  | 11/15 [03:26<08:21, 125.30s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step         \n",
      "\n",
      " 73%|███████▎  | 11/15 [03:27<08:21, 125.30s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dd1e0bfbcb46a0a74bf4627dd240c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m229/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m288/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m259/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m229/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m288/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m229/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m259/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 66/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run abrasive-bug-506 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/b8ab4365d3de42b68491468114552692\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 80%|████████  | 12/15 [04:13<06:20, 126.86s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 03:31:30.191455: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.237984: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.282270: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.327650: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.369073: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.411985: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.455139: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.496755: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.537276: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.578067: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.620964: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.661451: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.704030: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.745351: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.786015: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:31:30.826466: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 4s - 56ms/step - auc: 0.7119 - binary_accuracy: 0.4961 - loss: 0.8138 - precision: 0.4586 - recall: 0.9927 - val_auc: 0.8610 - val_binary_accuracy: 0.6349 - val_loss: 0.7338 - val_precision: 0.5394 - val_recall: 0.9727 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9001 - binary_accuracy: 0.7453 - loss: 0.6743 - precision: 0.6365 - recall: 0.9396 - val_auc: 0.9047 - val_binary_accuracy: 0.8023 - val_loss: 0.6346 - val_precision: 0.7076 - val_recall: 0.9126 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9275 - binary_accuracy: 0.8281 - loss: 0.5778 - precision: 0.7489 - recall: 0.8972 - val_auc: 0.9184 - val_binary_accuracy: 0.8186 - val_loss: 0.5592 - val_precision: 0.7612 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9328 - binary_accuracy: 0.8586 - loss: 0.5103 - precision: 0.8098 - recall: 0.8736 - val_auc: 0.9240 - val_binary_accuracy: 0.8395 - val_loss: 0.5052 - val_precision: 0.8000 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9356 - binary_accuracy: 0.8633 - loss: 0.4654 - precision: 0.8298 - recall: 0.8556 - val_auc: 0.9263 - val_binary_accuracy: 0.8372 - val_loss: 0.4728 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9385 - binary_accuracy: 0.8719 - loss: 0.4363 - precision: 0.8478 - recall: 0.8540 - val_auc: 0.9276 - val_binary_accuracy: 0.8349 - val_loss: 0.4550 - val_precision: 0.8077 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8711 - loss: 0.4212 - precision: 0.8519 - recall: 0.8440 - val_auc: 0.9278 - val_binary_accuracy: 0.8395 - val_loss: 0.4457 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9407 - binary_accuracy: 0.8734 - loss: 0.4102 - precision: 0.8614 - recall: 0.8394 - val_auc: 0.9287 - val_binary_accuracy: 0.8395 - val_loss: 0.4384 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8750 - loss: 0.4047 - precision: 0.8619 - recall: 0.8431 - val_auc: 0.9293 - val_binary_accuracy: 0.8419 - val_loss: 0.4340 - val_precision: 0.8286 - val_recall: 0.7923 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8742 - loss: 0.3981 - precision: 0.8639 - recall: 0.8370 - val_auc: 0.9302 - val_binary_accuracy: 0.8442 - val_loss: 0.4295 - val_precision: 0.8295 - val_recall: 0.7978 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8766 - loss: 0.3968 - precision: 0.8654 - recall: 0.8434 - val_auc: 0.9304 - val_binary_accuracy: 0.8442 - val_loss: 0.4263 - val_precision: 0.8295 - val_recall: 0.7978 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8734 - loss: 0.3928 - precision: 0.8590 - recall: 0.8401 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.4234 - val_precision: 0.8333 - val_recall: 0.7923 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8758 - loss: 0.3893 - precision: 0.8630 - recall: 0.8425 - val_auc: 0.9310 - val_binary_accuracy: 0.8442 - val_loss: 0.4198 - val_precision: 0.8333 - val_recall: 0.7923 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9433 - binary_accuracy: 0.8742 - loss: 0.3861 - precision: 0.8601 - recall: 0.8428 - val_auc: 0.9317 - val_binary_accuracy: 0.8465 - val_loss: 0.4177 - val_precision: 0.8382 - val_recall: 0.7923 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8773 - loss: 0.3816 - precision: 0.8658 - recall: 0.8419 - val_auc: 0.9320 - val_binary_accuracy: 0.8512 - val_loss: 0.4149 - val_precision: 0.8439 - val_recall: 0.7978 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8789 - loss: 0.3791 - precision: 0.8662 - recall: 0.8488 - val_auc: 0.9323 - val_binary_accuracy: 0.8488 - val_loss: 0.4123 - val_precision: 0.8391 - val_recall: 0.7978 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8781 - loss: 0.3745 - precision: 0.8668 - recall: 0.8446 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.4107 - val_precision: 0.8488 - val_recall: 0.7978 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8781 - loss: 0.3748 - precision: 0.8668 - recall: 0.8446 - val_auc: 0.9326 - val_binary_accuracy: 0.8535 - val_loss: 0.4081 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8797 - loss: 0.3713 - precision: 0.8689 - recall: 0.8467 - val_auc: 0.9331 - val_binary_accuracy: 0.8535 - val_loss: 0.4057 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8773 - loss: 0.3704 - precision: 0.8630 - recall: 0.8488 - val_auc: 0.9330 - val_binary_accuracy: 0.8535 - val_loss: 0.4040 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8789 - loss: 0.3680 - precision: 0.8627 - recall: 0.8516 - val_auc: 0.9330 - val_binary_accuracy: 0.8581 - val_loss: 0.4031 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8789 - loss: 0.3659 - precision: 0.8712 - recall: 0.8410 - val_auc: 0.9334 - val_binary_accuracy: 0.8512 - val_loss: 0.4008 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8758 - loss: 0.3643 - precision: 0.8617 - recall: 0.8443 - val_auc: 0.9333 - val_binary_accuracy: 0.8488 - val_loss: 0.3999 - val_precision: 0.8352 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9466 - binary_accuracy: 0.8781 - loss: 0.3615 - precision: 0.8682 - recall: 0.8428 - val_auc: 0.9335 - val_binary_accuracy: 0.8535 - val_loss: 0.3980 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8805 - loss: 0.3604 - precision: 0.8670 - recall: 0.8495 - val_auc: 0.9338 - val_binary_accuracy: 0.8558 - val_loss: 0.3964 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9465 - binary_accuracy: 0.8781 - loss: 0.3589 - precision: 0.8657 - recall: 0.8467 - val_auc: 0.9338 - val_binary_accuracy: 0.8535 - val_loss: 0.3951 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8766 - loss: 0.3583 - precision: 0.8644 - recall: 0.8422 - val_auc: 0.9337 - val_binary_accuracy: 0.8535 - val_loss: 0.3936 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9496 - binary_accuracy: 0.8844 - loss: 0.3485 - precision: 0.8767 - recall: 0.8477 - val_auc: 0.9338 - val_binary_accuracy: 0.8535 - val_loss: 0.3923 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9482 - binary_accuracy: 0.8813 - loss: 0.3503 - precision: 0.8717 - recall: 0.8462 - val_auc: 0.9343 - val_binary_accuracy: 0.8535 - val_loss: 0.3900 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9472 - binary_accuracy: 0.8805 - loss: 0.3524 - precision: 0.8731 - recall: 0.8428 - val_auc: 0.9342 - val_binary_accuracy: 0.8535 - val_loss: 0.3898 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8813 - loss: 0.3505 - precision: 0.8705 - recall: 0.8483 - val_auc: 0.9342 - val_binary_accuracy: 0.8535 - val_loss: 0.3877 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9473 - binary_accuracy: 0.8805 - loss: 0.3499 - precision: 0.8731 - recall: 0.8428 - val_auc: 0.9343 - val_binary_accuracy: 0.8535 - val_loss: 0.3868 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8820 - loss: 0.3461 - precision: 0.8724 - recall: 0.8485 - val_auc: 0.9339 - val_binary_accuracy: 0.8535 - val_loss: 0.3858 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8836 - loss: 0.3461 - precision: 0.8755 - recall: 0.8483 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3848 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9487 - binary_accuracy: 0.8836 - loss: 0.3435 - precision: 0.8764 - recall: 0.8459 - val_auc: 0.9344 - val_binary_accuracy: 0.8558 - val_loss: 0.3840 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9486 - binary_accuracy: 0.8844 - loss: 0.3439 - precision: 0.8727 - recall: 0.8535 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3837 - val_precision: 0.8506 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9481 - binary_accuracy: 0.8828 - loss: 0.3443 - precision: 0.8741 - recall: 0.8485 - val_auc: 0.9343 - val_binary_accuracy: 0.8558 - val_loss: 0.3823 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8828 - loss: 0.3430 - precision: 0.8755 - recall: 0.8467 - val_auc: 0.9343 - val_binary_accuracy: 0.8558 - val_loss: 0.3819 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9481 - binary_accuracy: 0.8852 - loss: 0.3427 - precision: 0.8800 - recall: 0.8462 - val_auc: 0.9342 - val_binary_accuracy: 0.8558 - val_loss: 0.3807 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8883 - loss: 0.3394 - precision: 0.8769 - recall: 0.8592 - val_auc: 0.9342 - val_binary_accuracy: 0.8581 - val_loss: 0.3802 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9484 - binary_accuracy: 0.8852 - loss: 0.3405 - precision: 0.8717 - recall: 0.8574 - val_auc: 0.9339 - val_binary_accuracy: 0.8581 - val_loss: 0.3791 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8836 - loss: 0.3405 - precision: 0.8771 - recall: 0.8467 - val_auc: 0.9342 - val_binary_accuracy: 0.8558 - val_loss: 0.3782 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8906 - loss: 0.3371 - precision: 0.8771 - recall: 0.8642 - val_auc: 0.9345 - val_binary_accuracy: 0.8581 - val_loss: 0.3776 - val_precision: 0.8506 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9486 - binary_accuracy: 0.8836 - loss: 0.3383 - precision: 0.8786 - recall: 0.8449 - val_auc: 0.9343 - val_binary_accuracy: 0.8581 - val_loss: 0.3765 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8867 - loss: 0.3376 - precision: 0.8720 - recall: 0.8608 - val_auc: 0.9346 - val_binary_accuracy: 0.8581 - val_loss: 0.3759 - val_precision: 0.8506 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8836 - loss: 0.3352 - precision: 0.8808 - recall: 0.8404 - val_auc: 0.9344 - val_binary_accuracy: 0.8581 - val_loss: 0.3754 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9488 - binary_accuracy: 0.8875 - loss: 0.3354 - precision: 0.8797 - recall: 0.8540 - val_auc: 0.9344 - val_binary_accuracy: 0.8581 - val_loss: 0.3745 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8875 - loss: 0.3325 - precision: 0.8778 - recall: 0.8553 - val_auc: 0.9344 - val_binary_accuracy: 0.8581 - val_loss: 0.3741 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9492 - binary_accuracy: 0.8891 - loss: 0.3331 - precision: 0.8818 - recall: 0.8561 - val_auc: 0.9340 - val_binary_accuracy: 0.8535 - val_loss: 0.3743 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9488 - binary_accuracy: 0.8852 - loss: 0.3337 - precision: 0.8774 - recall: 0.8501 - val_auc: 0.9338 - val_binary_accuracy: 0.8581 - val_loss: 0.3731 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8891 - loss: 0.3329 - precision: 0.8785 - recall: 0.8592 - val_auc: 0.9341 - val_binary_accuracy: 0.8605 - val_loss: 0.3723 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9488 - binary_accuracy: 0.8836 - loss: 0.3325 - precision: 0.8769 - recall: 0.8464 - val_auc: 0.9339 - val_binary_accuracy: 0.8558 - val_loss: 0.3725 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9489 - binary_accuracy: 0.8844 - loss: 0.3321 - precision: 0.8774 - recall: 0.8485 - val_auc: 0.9346 - val_binary_accuracy: 0.8605 - val_loss: 0.3713 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9489 - binary_accuracy: 0.8875 - loss: 0.3308 - precision: 0.8790 - recall: 0.8532 - val_auc: 0.9343 - val_binary_accuracy: 0.8605 - val_loss: 0.3710 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9496 - binary_accuracy: 0.8883 - loss: 0.3292 - precision: 0.8795 - recall: 0.8553 - val_auc: 0.9344 - val_binary_accuracy: 0.8605 - val_loss: 0.3701 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9494 - binary_accuracy: 0.8891 - loss: 0.3292 - precision: 0.8853 - recall: 0.8495 - val_auc: 0.9343 - val_binary_accuracy: 0.8605 - val_loss: 0.3697 - val_precision: 0.8436 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9499 - binary_accuracy: 0.8883 - loss: 0.3272 - precision: 0.8771 - recall: 0.8595 - val_auc: 0.9341 - val_binary_accuracy: 0.8605 - val_loss: 0.3695 - val_precision: 0.8514 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9503 - binary_accuracy: 0.8883 - loss: 0.3262 - precision: 0.8859 - recall: 0.8488 - val_auc: 0.9342 - val_binary_accuracy: 0.8605 - val_loss: 0.3698 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8906 - loss: 0.3279 - precision: 0.8792 - recall: 0.8631 - val_auc: 0.9338 - val_binary_accuracy: 0.8581 - val_loss: 0.3693 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9488 - binary_accuracy: 0.8867 - loss: 0.3286 - precision: 0.8805 - recall: 0.8498 - val_auc: 0.9342 - val_binary_accuracy: 0.8581 - val_loss: 0.3681 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8898 - loss: 0.3270 - precision: 0.8872 - recall: 0.8498 - val_auc: 0.9335 - val_binary_accuracy: 0.8581 - val_loss: 0.3688 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8906 - loss: 0.3269 - precision: 0.8773 - recall: 0.8645 - val_auc: 0.9344 - val_binary_accuracy: 0.8605 - val_loss: 0.3669 - val_precision: 0.8514 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8883 - loss: 0.3268 - precision: 0.8836 - recall: 0.8495 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3670 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9503 - binary_accuracy: 0.8898 - loss: 0.3235 - precision: 0.8828 - recall: 0.8553 - val_auc: 0.9342 - val_binary_accuracy: 0.8581 - val_loss: 0.3666 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9501 - binary_accuracy: 0.8875 - loss: 0.3234 - precision: 0.8836 - recall: 0.8480 - val_auc: 0.9345 - val_binary_accuracy: 0.8605 - val_loss: 0.3652 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9499 - binary_accuracy: 0.8898 - loss: 0.3237 - precision: 0.8843 - recall: 0.8535 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3647 - val_precision: 0.8523 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9494 - binary_accuracy: 0.8867 - loss: 0.3243 - precision: 0.8771 - recall: 0.8529 - val_auc: 0.9345 - val_binary_accuracy: 0.8581 - val_loss: 0.3649 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9496 - binary_accuracy: 0.8867 - loss: 0.3238 - precision: 0.8828 - recall: 0.8491 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3633 - val_precision: 0.8514 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9499 - binary_accuracy: 0.8898 - loss: 0.3227 - precision: 0.8830 - recall: 0.8556 - val_auc: 0.9349 - val_binary_accuracy: 0.8605 - val_loss: 0.3630 - val_precision: 0.8514 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9499 - binary_accuracy: 0.8859 - loss: 0.3232 - precision: 0.8838 - recall: 0.8452 - val_auc: 0.9345 - val_binary_accuracy: 0.8581 - val_loss: 0.3630 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8883 - loss: 0.3231 - precision: 0.8809 - recall: 0.8535 - val_auc: 0.9348 - val_binary_accuracy: 0.8605 - val_loss: 0.3617 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9505 - binary_accuracy: 0.8859 - loss: 0.3194 - precision: 0.8741 - recall: 0.8548 - val_auc: 0.9348 - val_binary_accuracy: 0.8628 - val_loss: 0.3621 - val_precision: 0.8563 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9500 - binary_accuracy: 0.8859 - loss: 0.3219 - precision: 0.8865 - recall: 0.8412 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3609 - val_precision: 0.8523 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9501 - binary_accuracy: 0.8891 - loss: 0.3211 - precision: 0.8799 - recall: 0.8574 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3616 - val_precision: 0.8514 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8883 - loss: 0.3220 - precision: 0.8819 - recall: 0.8511 - val_auc: 0.9346 - val_binary_accuracy: 0.8605 - val_loss: 0.3612 - val_precision: 0.8475 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8867 - loss: 0.3214 - precision: 0.8792 - recall: 0.8519 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3603 - val_precision: 0.8563 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9504 - binary_accuracy: 0.8883 - loss: 0.3189 - precision: 0.8801 - recall: 0.8561 - val_auc: 0.9349 - val_binary_accuracy: 0.8605 - val_loss: 0.3596 - val_precision: 0.8514 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9523 - binary_accuracy: 0.8875 - loss: 0.3143 - precision: 0.8878 - recall: 0.8422 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3604 - val_precision: 0.8483 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9501 - binary_accuracy: 0.8867 - loss: 0.3190 - precision: 0.8745 - recall: 0.8569 - val_auc: 0.9346 - val_binary_accuracy: 0.8628 - val_loss: 0.3604 - val_precision: 0.8563 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9512 - binary_accuracy: 0.8867 - loss: 0.3162 - precision: 0.8807 - recall: 0.8501 - val_auc: 0.9347 - val_binary_accuracy: 0.8628 - val_loss: 0.3600 - val_precision: 0.8483 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9504 - binary_accuracy: 0.8883 - loss: 0.3181 - precision: 0.8828 - recall: 0.8522 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3594 - val_precision: 0.8483 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9503 - binary_accuracy: 0.8859 - loss: 0.3177 - precision: 0.8755 - recall: 0.8529 - val_auc: 0.9352 - val_binary_accuracy: 0.8651 - val_loss: 0.3589 - val_precision: 0.8531 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9509 - binary_accuracy: 0.8914 - loss: 0.3159 - precision: 0.8808 - recall: 0.8631 - val_auc: 0.9350 - val_binary_accuracy: 0.8674 - val_loss: 0.3590 - val_precision: 0.8580 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9509 - binary_accuracy: 0.8898 - loss: 0.3156 - precision: 0.8830 - recall: 0.8556 - val_auc: 0.9349 - val_binary_accuracy: 0.8605 - val_loss: 0.3594 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9510 - binary_accuracy: 0.8883 - loss: 0.3150 - precision: 0.8792 - recall: 0.8550 - val_auc: 0.9352 - val_binary_accuracy: 0.8651 - val_loss: 0.3578 - val_precision: 0.8571 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 86/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9513 - binary_accuracy: 0.8875 - loss: 0.3146 - precision: 0.8807 - recall: 0.8516 - val_auc: 0.9349 - val_binary_accuracy: 0.8605 - val_loss: 0.3590 - val_precision: 0.8514 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 87/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9508 - binary_accuracy: 0.8891 - loss: 0.3159 - precision: 0.8804 - recall: 0.8579 - val_auc: 0.9351 - val_binary_accuracy: 0.8651 - val_loss: 0.3581 - val_precision: 0.8531 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 88/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9505 - binary_accuracy: 0.8875 - loss: 0.3163 - precision: 0.8743 - recall: 0.8616 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3575 - val_precision: 0.8563 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 89/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9506 - binary_accuracy: 0.8844 - loss: 0.3160 - precision: 0.8755 - recall: 0.8498 - val_auc: 0.9352 - val_binary_accuracy: 0.8628 - val_loss: 0.3570 - val_precision: 0.8563 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 90/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9508 - binary_accuracy: 0.8883 - loss: 0.3148 - precision: 0.8809 - recall: 0.8535 - val_auc: 0.9352 - val_binary_accuracy: 0.8674 - val_loss: 0.3571 - val_precision: 0.8580 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 91/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9504 - binary_accuracy: 0.8852 - loss: 0.3158 - precision: 0.8738 - recall: 0.8529 - val_auc: 0.9349 - val_binary_accuracy: 0.8674 - val_loss: 0.3573 - val_precision: 0.8580 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 92/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9521 - binary_accuracy: 0.8914 - loss: 0.3117 - precision: 0.8820 - recall: 0.8611 - val_auc: 0.9349 - val_binary_accuracy: 0.8698 - val_loss: 0.3570 - val_precision: 0.8588 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 93/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9508 - binary_accuracy: 0.8891 - loss: 0.3144 - precision: 0.8795 - recall: 0.8569 - val_auc: 0.9351 - val_binary_accuracy: 0.8674 - val_loss: 0.3578 - val_precision: 0.8539 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 94/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9510 - binary_accuracy: 0.8891 - loss: 0.3138 - precision: 0.8773 - recall: 0.8613 - val_auc: 0.9348 - val_binary_accuracy: 0.8651 - val_loss: 0.3578 - val_precision: 0.8613 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 95/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9512 - binary_accuracy: 0.8891 - loss: 0.3130 - precision: 0.8799 - recall: 0.8574 - val_auc: 0.9347 - val_binary_accuracy: 0.8651 - val_loss: 0.3571 - val_precision: 0.8613 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 96/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9510 - binary_accuracy: 0.8852 - loss: 0.3138 - precision: 0.8783 - recall: 0.8477 - val_auc: 0.9349 - val_binary_accuracy: 0.8674 - val_loss: 0.3571 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 97/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9510 - binary_accuracy: 0.8852 - loss: 0.3141 - precision: 0.8776 - recall: 0.8504 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3570 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 98/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9520 - binary_accuracy: 0.8891 - loss: 0.3113 - precision: 0.8785 - recall: 0.8592 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3561 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 99/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9509 - binary_accuracy: 0.8859 - loss: 0.3140 - precision: 0.8734 - recall: 0.8574 - val_auc: 0.9345 - val_binary_accuracy: 0.8674 - val_loss: 0.3583 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 100/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9510 - binary_accuracy: 0.8875 - loss: 0.3138 - precision: 0.8799 - recall: 0.8543 - val_auc: 0.9350 - val_binary_accuracy: 0.8674 - val_loss: 0.3569 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 101/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9509 - binary_accuracy: 0.8836 - loss: 0.3133 - precision: 0.8781 - recall: 0.8443 - val_auc: 0.9348 - val_binary_accuracy: 0.8674 - val_loss: 0.3575 - val_precision: 0.8539 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 102/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9511 - binary_accuracy: 0.8859 - loss: 0.3130 - precision: 0.8752 - recall: 0.8561 - val_auc: 0.9352 - val_binary_accuracy: 0.8744 - val_loss: 0.3561 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 103/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9521 - binary_accuracy: 0.8852 - loss: 0.3102 - precision: 0.8724 - recall: 0.8548 - val_auc: 0.9350 - val_binary_accuracy: 0.8698 - val_loss: 0.3569 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 104/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9515 - binary_accuracy: 0.8859 - loss: 0.3116 - precision: 0.8762 - recall: 0.8537 - val_auc: 0.9346 - val_binary_accuracy: 0.8674 - val_loss: 0.3580 - val_precision: 0.8539 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 105/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9509 - binary_accuracy: 0.8875 - loss: 0.3127 - precision: 0.8736 - recall: 0.8608 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3565 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 106/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9508 - binary_accuracy: 0.8844 - loss: 0.3127 - precision: 0.8727 - recall: 0.8535 - val_auc: 0.9349 - val_binary_accuracy: 0.8698 - val_loss: 0.3565 - val_precision: 0.8547 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 107/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9513 - binary_accuracy: 0.8844 - loss: 0.3122 - precision: 0.8743 - recall: 0.8519 - val_auc: 0.9351 - val_binary_accuracy: 0.8674 - val_loss: 0.3547 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 108/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9512 - binary_accuracy: 0.8883 - loss: 0.3124 - precision: 0.8769 - recall: 0.8592 - val_auc: 0.9351 - val_binary_accuracy: 0.8698 - val_loss: 0.3560 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 109/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9513 - binary_accuracy: 0.8891 - loss: 0.3112 - precision: 0.8783 - recall: 0.8590 - val_auc: 0.9352 - val_binary_accuracy: 0.8674 - val_loss: 0.3560 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 110/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9512 - binary_accuracy: 0.8875 - loss: 0.3116 - precision: 0.8792 - recall: 0.8535 - val_auc: 0.9351 - val_binary_accuracy: 0.8721 - val_loss: 0.3549 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 111/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9514 - binary_accuracy: 0.8875 - loss: 0.3115 - precision: 0.8734 - recall: 0.8606 - val_auc: 0.9354 - val_binary_accuracy: 0.8674 - val_loss: 0.3552 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 112/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9510 - binary_accuracy: 0.8859 - loss: 0.3118 - precision: 0.8771 - recall: 0.8514 - val_auc: 0.9351 - val_binary_accuracy: 0.8721 - val_loss: 0.3544 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 113/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9522 - binary_accuracy: 0.8844 - loss: 0.3092 - precision: 0.8786 - recall: 0.8464 - val_auc: 0.9349 - val_binary_accuracy: 0.8721 - val_loss: 0.3553 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 114/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9524 - binary_accuracy: 0.8914 - loss: 0.3086 - precision: 0.8792 - recall: 0.8647 - val_auc: 0.9352 - val_binary_accuracy: 0.8674 - val_loss: 0.3546 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 115/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9509 - binary_accuracy: 0.8867 - loss: 0.3122 - precision: 0.8764 - recall: 0.8556 - val_auc: 0.9347 - val_binary_accuracy: 0.8698 - val_loss: 0.3562 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 116/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9518 - binary_accuracy: 0.8898 - loss: 0.3092 - precision: 0.8797 - recall: 0.8587 - val_auc: 0.9353 - val_binary_accuracy: 0.8721 - val_loss: 0.3541 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 117/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9511 - binary_accuracy: 0.8867 - loss: 0.3112 - precision: 0.8720 - recall: 0.8608 - val_auc: 0.9349 - val_binary_accuracy: 0.8698 - val_loss: 0.3552 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 118/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9513 - binary_accuracy: 0.8844 - loss: 0.3110 - precision: 0.8786 - recall: 0.8464 - val_auc: 0.9351 - val_binary_accuracy: 0.8698 - val_loss: 0.3548 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 119/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9509 - binary_accuracy: 0.8852 - loss: 0.3110 - precision: 0.8741 - recall: 0.8532 - val_auc: 0.9351 - val_binary_accuracy: 0.8698 - val_loss: 0.3553 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 120/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9518 - binary_accuracy: 0.8844 - loss: 0.3098 - precision: 0.8769 - recall: 0.8480 - val_auc: 0.9357 - val_binary_accuracy: 0.8744 - val_loss: 0.3533 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 121/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9517 - binary_accuracy: 0.8867 - loss: 0.3088 - precision: 0.8717 - recall: 0.8606 - val_auc: 0.9352 - val_binary_accuracy: 0.8698 - val_loss: 0.3552 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 122/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9514 - binary_accuracy: 0.8852 - loss: 0.3094 - precision: 0.8729 - recall: 0.8553 - val_auc: 0.9351 - val_binary_accuracy: 0.8674 - val_loss: 0.3541 - val_precision: 0.8663 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 123/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9513 - binary_accuracy: 0.8867 - loss: 0.3104 - precision: 0.8748 - recall: 0.8571 - val_auc: 0.9351 - val_binary_accuracy: 0.8721 - val_loss: 0.3538 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 124/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9512 - binary_accuracy: 0.8859 - loss: 0.3102 - precision: 0.8776 - recall: 0.8519 - val_auc: 0.9351 - val_binary_accuracy: 0.8698 - val_loss: 0.3531 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 125/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9514 - binary_accuracy: 0.8875 - loss: 0.3096 - precision: 0.8743 - recall: 0.8616 - val_auc: 0.9349 - val_binary_accuracy: 0.8698 - val_loss: 0.3541 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 126/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9515 - binary_accuracy: 0.8867 - loss: 0.3096 - precision: 0.8819 - recall: 0.8480 - val_auc: 0.9351 - val_binary_accuracy: 0.8721 - val_loss: 0.3532 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 127/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9517 - binary_accuracy: 0.8867 - loss: 0.3093 - precision: 0.8725 - recall: 0.8613 - val_auc: 0.9350 - val_binary_accuracy: 0.8674 - val_loss: 0.3534 - val_precision: 0.8663 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 128/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9515 - binary_accuracy: 0.8852 - loss: 0.3091 - precision: 0.8720 - recall: 0.8577 - val_auc: 0.9353 - val_binary_accuracy: 0.8721 - val_loss: 0.3524 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 129/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9516 - binary_accuracy: 0.8852 - loss: 0.3090 - precision: 0.8781 - recall: 0.8474 - val_auc: 0.9355 - val_binary_accuracy: 0.8698 - val_loss: 0.3519 - val_precision: 0.8588 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 130/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9520 - binary_accuracy: 0.8859 - loss: 0.3072 - precision: 0.8802 - recall: 0.8480 - val_auc: 0.9352 - val_binary_accuracy: 0.8674 - val_loss: 0.3534 - val_precision: 0.8663 - val_recall: 0.8142 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 131/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9516 - binary_accuracy: 0.8867 - loss: 0.3092 - precision: 0.8741 - recall: 0.8597 - val_auc: 0.9349 - val_binary_accuracy: 0.8698 - val_loss: 0.3526 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 132/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9522 - binary_accuracy: 0.8867 - loss: 0.3071 - precision: 0.8776 - recall: 0.8535 - val_auc: 0.9350 - val_binary_accuracy: 0.8698 - val_loss: 0.3529 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 133/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9521 - binary_accuracy: 0.8883 - loss: 0.3071 - precision: 0.8785 - recall: 0.8577 - val_auc: 0.9356 - val_binary_accuracy: 0.8744 - val_loss: 0.3517 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 134/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9526 - binary_accuracy: 0.8922 - loss: 0.3060 - precision: 0.8851 - recall: 0.8592 - val_auc: 0.9351 - val_binary_accuracy: 0.8674 - val_loss: 0.3538 - val_precision: 0.8539 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 135/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9514 - binary_accuracy: 0.8852 - loss: 0.3091 - precision: 0.8683 - recall: 0.8603 - val_auc: 0.9354 - val_binary_accuracy: 0.8744 - val_loss: 0.3520 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 136/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9524 - binary_accuracy: 0.8875 - loss: 0.3058 - precision: 0.8757 - recall: 0.8564 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3518 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 137/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9515 - binary_accuracy: 0.8859 - loss: 0.3081 - precision: 0.8745 - recall: 0.8553 - val_auc: 0.9348 - val_binary_accuracy: 0.8698 - val_loss: 0.3539 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 138/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9518 - binary_accuracy: 0.8875 - loss: 0.3074 - precision: 0.8766 - recall: 0.8574 - val_auc: 0.9352 - val_binary_accuracy: 0.8721 - val_loss: 0.3525 - val_precision: 0.8678 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 139/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9518 - binary_accuracy: 0.8883 - loss: 0.3077 - precision: 0.8780 - recall: 0.8571 - val_auc: 0.9350 - val_binary_accuracy: 0.8698 - val_loss: 0.3524 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 140/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9534 - binary_accuracy: 0.8898 - loss: 0.3027 - precision: 0.8785 - recall: 0.8608 - val_auc: 0.9354 - val_binary_accuracy: 0.8698 - val_loss: 0.3519 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 141/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9514 - binary_accuracy: 0.8875 - loss: 0.3081 - precision: 0.8824 - recall: 0.8501 - val_auc: 0.9355 - val_binary_accuracy: 0.8698 - val_loss: 0.3516 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 142/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9525 - binary_accuracy: 0.8883 - loss: 0.3060 - precision: 0.8830 - recall: 0.8525 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3511 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 143/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9534 - binary_accuracy: 0.8852 - loss: 0.3046 - precision: 0.8653 - recall: 0.8637 - val_auc: 0.9350 - val_binary_accuracy: 0.8674 - val_loss: 0.3543 - val_precision: 0.8706 - val_recall: 0.8087 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 144/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9523 - binary_accuracy: 0.8859 - loss: 0.3064 - precision: 0.8790 - recall: 0.8501 - val_auc: 0.9353 - val_binary_accuracy: 0.8674 - val_loss: 0.3534 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 145/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9525 - binary_accuracy: 0.8875 - loss: 0.3054 - precision: 0.8762 - recall: 0.8569 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3521 - val_precision: 0.8678 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 146/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9526 - binary_accuracy: 0.8891 - loss: 0.3055 - precision: 0.8811 - recall: 0.8553 - val_auc: 0.9350 - val_binary_accuracy: 0.8698 - val_loss: 0.3513 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 147/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9525 - binary_accuracy: 0.8859 - loss: 0.3060 - precision: 0.8706 - recall: 0.8611 - val_auc: 0.9349 - val_binary_accuracy: 0.8721 - val_loss: 0.3524 - val_precision: 0.8678 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 148/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9522 - binary_accuracy: 0.8883 - loss: 0.3066 - precision: 0.8809 - recall: 0.8535 - val_auc: 0.9354 - val_binary_accuracy: 0.8721 - val_loss: 0.3518 - val_precision: 0.8678 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 149/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9523 - binary_accuracy: 0.8891 - loss: 0.3059 - precision: 0.8799 - recall: 0.8574 - val_auc: 0.9353 - val_binary_accuracy: 0.8698 - val_loss: 0.3516 - val_precision: 0.8588 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 150/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9519 - binary_accuracy: 0.8891 - loss: 0.3061 - precision: 0.8750 - recall: 0.8621 - val_auc: 0.9354 - val_binary_accuracy: 0.8698 - val_loss: 0.3520 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 151/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9531 - binary_accuracy: 0.8875 - loss: 0.3045 - precision: 0.8783 - recall: 0.8558 - val_auc: 0.9355 - val_binary_accuracy: 0.8721 - val_loss: 0.3521 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 152/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9520 - binary_accuracy: 0.8867 - loss: 0.3070 - precision: 0.8708 - recall: 0.8629 - val_auc: 0.9355 - val_binary_accuracy: 0.8721 - val_loss: 0.3507 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 153/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9522 - binary_accuracy: 0.8883 - loss: 0.3066 - precision: 0.8799 - recall: 0.8558 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3505 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 154/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9521 - binary_accuracy: 0.8891 - loss: 0.3065 - precision: 0.8766 - recall: 0.8606 - val_auc: 0.9356 - val_binary_accuracy: 0.8698 - val_loss: 0.3517 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 155/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9521 - binary_accuracy: 0.8883 - loss: 0.3058 - precision: 0.8780 - recall: 0.8571 - val_auc: 0.9348 - val_binary_accuracy: 0.8698 - val_loss: 0.3530 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 156/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9521 - binary_accuracy: 0.8852 - loss: 0.3064 - precision: 0.8731 - recall: 0.8556 - val_auc: 0.9348 - val_binary_accuracy: 0.8698 - val_loss: 0.3524 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 157/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9523 - binary_accuracy: 0.8875 - loss: 0.3059 - precision: 0.8811 - recall: 0.8522 - val_auc: 0.9353 - val_binary_accuracy: 0.8698 - val_loss: 0.3522 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 158/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9520 - binary_accuracy: 0.8852 - loss: 0.3067 - precision: 0.8729 - recall: 0.8553 - val_auc: 0.9352 - val_binary_accuracy: 0.8721 - val_loss: 0.3530 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 159/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9519 - binary_accuracy: 0.8867 - loss: 0.3065 - precision: 0.8780 - recall: 0.8540 - val_auc: 0.9359 - val_binary_accuracy: 0.8698 - val_loss: 0.3500 - val_precision: 0.8547 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 160/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9529 - binary_accuracy: 0.8906 - loss: 0.3043 - precision: 0.8902 - recall: 0.8477 - val_auc: 0.9357 - val_binary_accuracy: 0.8698 - val_loss: 0.3521 - val_precision: 0.8470 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 161/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9522 - binary_accuracy: 0.8867 - loss: 0.3057 - precision: 0.8738 - recall: 0.8595 - val_auc: 0.9352 - val_binary_accuracy: 0.8674 - val_loss: 0.3521 - val_precision: 0.8580 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 162/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9525 - binary_accuracy: 0.8867 - loss: 0.3045 - precision: 0.8734 - recall: 0.8590 - val_auc: 0.9352 - val_binary_accuracy: 0.8744 - val_loss: 0.3517 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 163/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9525 - binary_accuracy: 0.8852 - loss: 0.3050 - precision: 0.8731 - recall: 0.8556 - val_auc: 0.9353 - val_binary_accuracy: 0.8744 - val_loss: 0.3514 - val_precision: 0.8686 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 164/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9538 - binary_accuracy: 0.8922 - loss: 0.3009 - precision: 0.8851 - recall: 0.8592 - val_auc: 0.9351 - val_binary_accuracy: 0.8721 - val_loss: 0.3530 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 165/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9524 - binary_accuracy: 0.8875 - loss: 0.3051 - precision: 0.8736 - recall: 0.8608 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3503 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 166/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9523 - binary_accuracy: 0.8867 - loss: 0.3055 - precision: 0.8821 - recall: 0.8483 - val_auc: 0.9352 - val_binary_accuracy: 0.8721 - val_loss: 0.3515 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 167/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9530 - binary_accuracy: 0.8875 - loss: 0.3036 - precision: 0.8711 - recall: 0.8647 - val_auc: 0.9359 - val_binary_accuracy: 0.8767 - val_loss: 0.3510 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 168/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9525 - binary_accuracy: 0.8898 - loss: 0.3048 - precision: 0.8857 - recall: 0.8516 - val_auc: 0.9349 - val_binary_accuracy: 0.8721 - val_loss: 0.3510 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 169/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9535 - binary_accuracy: 0.8844 - loss: 0.3012 - precision: 0.8731 - recall: 0.8540 - val_auc: 0.9361 - val_binary_accuracy: 0.8744 - val_loss: 0.3494 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 170/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9525 - binary_accuracy: 0.8867 - loss: 0.3044 - precision: 0.8776 - recall: 0.8535 - val_auc: 0.9360 - val_binary_accuracy: 0.8744 - val_loss: 0.3496 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 171/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9529 - binary_accuracy: 0.8891 - loss: 0.3043 - precision: 0.8847 - recall: 0.8525 - val_auc: 0.9359 - val_binary_accuracy: 0.8767 - val_loss: 0.3502 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 172/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9525 - binary_accuracy: 0.8867 - loss: 0.3048 - precision: 0.8741 - recall: 0.8597 - val_auc: 0.9353 - val_binary_accuracy: 0.8744 - val_loss: 0.3512 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 173/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9526 - binary_accuracy: 0.8898 - loss: 0.3036 - precision: 0.8797 - recall: 0.8587 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3500 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 174/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9530 - binary_accuracy: 0.8898 - loss: 0.3027 - precision: 0.8785 - recall: 0.8608 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3504 - val_precision: 0.8686 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 175/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9537 - binary_accuracy: 0.8867 - loss: 0.3017 - precision: 0.8755 - recall: 0.8579 - val_auc: 0.9359 - val_binary_accuracy: 0.8744 - val_loss: 0.3501 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 176/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9531 - binary_accuracy: 0.8906 - loss: 0.3022 - precision: 0.8743 - recall: 0.8679 - val_auc: 0.9354 - val_binary_accuracy: 0.8744 - val_loss: 0.3511 - val_precision: 0.8686 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 177/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9527 - binary_accuracy: 0.8906 - loss: 0.3040 - precision: 0.8820 - recall: 0.8595 - val_auc: 0.9352 - val_binary_accuracy: 0.8744 - val_loss: 0.3510 - val_precision: 0.8686 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 178/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9528 - binary_accuracy: 0.8891 - loss: 0.3039 - precision: 0.8838 - recall: 0.8514 - val_auc: 0.9361 - val_binary_accuracy: 0.8767 - val_loss: 0.3496 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 179/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9526 - binary_accuracy: 0.8867 - loss: 0.3037 - precision: 0.8736 - recall: 0.8592 - val_auc: 0.9351 - val_binary_accuracy: 0.8744 - val_loss: 0.3509 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 180/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9525 - binary_accuracy: 0.8867 - loss: 0.3039 - precision: 0.8788 - recall: 0.8514 - val_auc: 0.9355 - val_binary_accuracy: 0.8767 - val_loss: 0.3497 - val_precision: 0.8652 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 181/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9531 - binary_accuracy: 0.8859 - loss: 0.3031 - precision: 0.8704 - recall: 0.8608 - val_auc: 0.9360 - val_binary_accuracy: 0.8767 - val_loss: 0.3492 - val_precision: 0.8693 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 182/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9529 - binary_accuracy: 0.8844 - loss: 0.3037 - precision: 0.8755 - recall: 0.8498 - val_auc: 0.9352 - val_binary_accuracy: 0.8744 - val_loss: 0.3499 - val_precision: 0.8686 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 183/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9530 - binary_accuracy: 0.8891 - loss: 0.3026 - precision: 0.8752 - recall: 0.8624 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3506 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 184/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9533 - binary_accuracy: 0.8875 - loss: 0.3019 - precision: 0.8748 - recall: 0.8587 - val_auc: 0.9355 - val_binary_accuracy: 0.8767 - val_loss: 0.3495 - val_precision: 0.8693 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 185/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9533 - binary_accuracy: 0.8883 - loss: 0.3020 - precision: 0.8795 - recall: 0.8553 - val_auc: 0.9353 - val_binary_accuracy: 0.8767 - val_loss: 0.3514 - val_precision: 0.8652 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 186/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9529 - binary_accuracy: 0.8891 - loss: 0.3025 - precision: 0.8811 - recall: 0.8553 - val_auc: 0.9347 - val_binary_accuracy: 0.8721 - val_loss: 0.3524 - val_precision: 0.8678 - val_recall: 0.8251 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 187/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9532 - binary_accuracy: 0.8883 - loss: 0.3019 - precision: 0.8736 - recall: 0.8624 - val_auc: 0.9354 - val_binary_accuracy: 0.8791 - val_loss: 0.3504 - val_precision: 0.8701 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 188/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9536 - binary_accuracy: 0.8898 - loss: 0.3011 - precision: 0.8845 - recall: 0.8537 - val_auc: 0.9360 - val_binary_accuracy: 0.8744 - val_loss: 0.3495 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 189/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9530 - binary_accuracy: 0.8891 - loss: 0.3028 - precision: 0.8764 - recall: 0.8603 - val_auc: 0.9357 - val_binary_accuracy: 0.8744 - val_loss: 0.3498 - val_precision: 0.8686 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 190/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9531 - binary_accuracy: 0.8883 - loss: 0.3027 - precision: 0.8811 - recall: 0.8537 - val_auc: 0.9360 - val_binary_accuracy: 0.8698 - val_loss: 0.3503 - val_precision: 0.8470 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 191/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9537 - binary_accuracy: 0.8859 - loss: 0.3008 - precision: 0.8745 - recall: 0.8553 - val_auc: 0.9356 - val_binary_accuracy: 0.8744 - val_loss: 0.3504 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 192/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9536 - binary_accuracy: 0.8906 - loss: 0.3012 - precision: 0.8832 - recall: 0.8574 - val_auc: 0.9356 - val_binary_accuracy: 0.8791 - val_loss: 0.3503 - val_precision: 0.8701 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 193/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9531 - binary_accuracy: 0.8875 - loss: 0.3027 - precision: 0.8727 - recall: 0.8631 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3507 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 194/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9533 - binary_accuracy: 0.8875 - loss: 0.3013 - precision: 0.8752 - recall: 0.8592 - val_auc: 0.9357 - val_binary_accuracy: 0.8814 - val_loss: 0.3496 - val_precision: 0.8750 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 195/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9529 - binary_accuracy: 0.8891 - loss: 0.3021 - precision: 0.8809 - recall: 0.8550 - val_auc: 0.9357 - val_binary_accuracy: 0.8814 - val_loss: 0.3496 - val_precision: 0.8750 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 196/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9532 - binary_accuracy: 0.8883 - loss: 0.3022 - precision: 0.8787 - recall: 0.8579 - val_auc: 0.9355 - val_binary_accuracy: 0.8767 - val_loss: 0.3501 - val_precision: 0.8652 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 197/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9534 - binary_accuracy: 0.8883 - loss: 0.3010 - precision: 0.8785 - recall: 0.8577 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3504 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 198/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9541 - binary_accuracy: 0.8883 - loss: 0.2992 - precision: 0.8795 - recall: 0.8553 - val_auc: 0.9357 - val_binary_accuracy: 0.8698 - val_loss: 0.3498 - val_precision: 0.8470 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 199/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9535 - binary_accuracy: 0.8875 - loss: 0.3010 - precision: 0.8764 - recall: 0.8571 - val_auc: 0.9359 - val_binary_accuracy: 0.8814 - val_loss: 0.3490 - val_precision: 0.8708 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 200/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9533 - binary_accuracy: 0.8891 - loss: 0.3013 - precision: 0.8795 - recall: 0.8569 - val_auc: 0.9353 - val_binary_accuracy: 0.8744 - val_loss: 0.3497 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 201/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9544 - binary_accuracy: 0.8922 - loss: 0.2988 - precision: 0.8849 - recall: 0.8590 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3503 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 202/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9537 - binary_accuracy: 0.8883 - loss: 0.3002 - precision: 0.8814 - recall: 0.8540 - val_auc: 0.9361 - val_binary_accuracy: 0.8721 - val_loss: 0.3490 - val_precision: 0.8516 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 203/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9530 - binary_accuracy: 0.8898 - loss: 0.3016 - precision: 0.8811 - recall: 0.8569 - val_auc: 0.9357 - val_binary_accuracy: 0.8698 - val_loss: 0.3508 - val_precision: 0.8470 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 204/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9535 - binary_accuracy: 0.8914 - loss: 0.3005 - precision: 0.8816 - recall: 0.8606 - val_auc: 0.9346 - val_binary_accuracy: 0.8744 - val_loss: 0.3512 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 205/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9533 - binary_accuracy: 0.8898 - loss: 0.3013 - precision: 0.8799 - recall: 0.8590 - val_auc: 0.9353 - val_binary_accuracy: 0.8791 - val_loss: 0.3497 - val_precision: 0.8701 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 206/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9535 - binary_accuracy: 0.8852 - loss: 0.3011 - precision: 0.8788 - recall: 0.8483 - val_auc: 0.9360 - val_binary_accuracy: 0.8698 - val_loss: 0.3499 - val_precision: 0.8470 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 207/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9546 - binary_accuracy: 0.8930 - loss: 0.2977 - precision: 0.8780 - recall: 0.8700 - val_auc: 0.9353 - val_binary_accuracy: 0.8767 - val_loss: 0.3498 - val_precision: 0.8652 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 208/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9535 - binary_accuracy: 0.8883 - loss: 0.3017 - precision: 0.8828 - recall: 0.8522 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3509 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 209/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9537 - binary_accuracy: 0.8898 - loss: 0.2997 - precision: 0.8769 - recall: 0.8624 - val_auc: 0.9354 - val_binary_accuracy: 0.8767 - val_loss: 0.3503 - val_precision: 0.8652 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 210/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9540 - binary_accuracy: 0.8883 - loss: 0.2989 - precision: 0.8776 - recall: 0.8566 - val_auc: 0.9348 - val_binary_accuracy: 0.8767 - val_loss: 0.3506 - val_precision: 0.8693 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 211/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9532 - binary_accuracy: 0.8883 - loss: 0.3005 - precision: 0.8834 - recall: 0.8493 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3496 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 212/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9540 - binary_accuracy: 0.8891 - loss: 0.2996 - precision: 0.8785 - recall: 0.8592 - val_auc: 0.9362 - val_binary_accuracy: 0.8767 - val_loss: 0.3482 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 213/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9537 - binary_accuracy: 0.8891 - loss: 0.2999 - precision: 0.8797 - recall: 0.8571 - val_auc: 0.9361 - val_binary_accuracy: 0.8744 - val_loss: 0.3486 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 214/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9534 - binary_accuracy: 0.8914 - loss: 0.3011 - precision: 0.8801 - recall: 0.8624 - val_auc: 0.9363 - val_binary_accuracy: 0.8721 - val_loss: 0.3499 - val_precision: 0.8516 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 215/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9532 - binary_accuracy: 0.8875 - loss: 0.3005 - precision: 0.8778 - recall: 0.8553 - val_auc: 0.9357 - val_binary_accuracy: 0.8767 - val_loss: 0.3491 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 216/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9544 - binary_accuracy: 0.8906 - loss: 0.2982 - precision: 0.8790 - recall: 0.8629 - val_auc: 0.9359 - val_binary_accuracy: 0.8721 - val_loss: 0.3495 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 217/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9539 - binary_accuracy: 0.8867 - loss: 0.2994 - precision: 0.8762 - recall: 0.8553 - val_auc: 0.9358 - val_binary_accuracy: 0.8674 - val_loss: 0.3491 - val_precision: 0.8462 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 218/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9537 - binary_accuracy: 0.8906 - loss: 0.2999 - precision: 0.8799 - recall: 0.8606 - val_auc: 0.9359 - val_binary_accuracy: 0.8721 - val_loss: 0.3490 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 219/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9540 - binary_accuracy: 0.8898 - loss: 0.2985 - precision: 0.8773 - recall: 0.8629 - val_auc: 0.9357 - val_binary_accuracy: 0.8721 - val_loss: 0.3492 - val_precision: 0.8516 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 220/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9536 - binary_accuracy: 0.8922 - loss: 0.2996 - precision: 0.8820 - recall: 0.8626 - val_auc: 0.9359 - val_binary_accuracy: 0.8698 - val_loss: 0.3487 - val_precision: 0.8470 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 221/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9538 - binary_accuracy: 0.8914 - loss: 0.2995 - precision: 0.8820 - recall: 0.8611 - val_auc: 0.9355 - val_binary_accuracy: 0.8767 - val_loss: 0.3483 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 222/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9542 - binary_accuracy: 0.8891 - loss: 0.2983 - precision: 0.8809 - recall: 0.8550 - val_auc: 0.9351 - val_binary_accuracy: 0.8721 - val_loss: 0.3502 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 223/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9541 - binary_accuracy: 0.8883 - loss: 0.2990 - precision: 0.8787 - recall: 0.8579 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3482 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 224/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9538 - binary_accuracy: 0.8898 - loss: 0.2993 - precision: 0.8904 - recall: 0.8464 - val_auc: 0.9363 - val_binary_accuracy: 0.8698 - val_loss: 0.3490 - val_precision: 0.8432 - val_recall: 0.8525 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 225/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9536 - binary_accuracy: 0.8883 - loss: 0.3004 - precision: 0.8811 - recall: 0.8537 - val_auc: 0.9358 - val_binary_accuracy: 0.8698 - val_loss: 0.3501 - val_precision: 0.8432 - val_recall: 0.8525 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 226/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9539 - binary_accuracy: 0.8852 - loss: 0.2997 - precision: 0.8731 - recall: 0.8556 - val_auc: 0.9354 - val_binary_accuracy: 0.8721 - val_loss: 0.3486 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 227/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9536 - binary_accuracy: 0.8906 - loss: 0.3003 - precision: 0.8799 - recall: 0.8606 - val_auc: 0.9354 - val_binary_accuracy: 0.8721 - val_loss: 0.3491 - val_precision: 0.8516 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 228/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9546 - binary_accuracy: 0.8898 - loss: 0.2971 - precision: 0.8797 - recall: 0.8587 - val_auc: 0.9356 - val_binary_accuracy: 0.8767 - val_loss: 0.3481 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 229/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9547 - binary_accuracy: 0.8891 - loss: 0.2969 - precision: 0.8797 - recall: 0.8571 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3484 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 230/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9546 - binary_accuracy: 0.8922 - loss: 0.2973 - precision: 0.8818 - recall: 0.8624 - val_auc: 0.9354 - val_binary_accuracy: 0.8744 - val_loss: 0.3489 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 231/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9553 - binary_accuracy: 0.8891 - loss: 0.2946 - precision: 0.8799 - recall: 0.8574 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3488 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 232/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9538 - binary_accuracy: 0.8875 - loss: 0.2995 - precision: 0.8851 - recall: 0.8462 - val_auc: 0.9361 - val_binary_accuracy: 0.8767 - val_loss: 0.3477 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 233/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9543 - binary_accuracy: 0.8906 - loss: 0.2978 - precision: 0.8778 - recall: 0.8650 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3494 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 234/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9540 - binary_accuracy: 0.8898 - loss: 0.2994 - precision: 0.8816 - recall: 0.8574 - val_auc: 0.9356 - val_binary_accuracy: 0.8721 - val_loss: 0.3483 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 235/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9554 - binary_accuracy: 0.8891 - loss: 0.2947 - precision: 0.8797 - recall: 0.8571 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3485 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 236/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9541 - binary_accuracy: 0.8867 - loss: 0.2979 - precision: 0.8797 - recall: 0.8525 - val_auc: 0.9361 - val_binary_accuracy: 0.8767 - val_loss: 0.3476 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 237/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9541 - binary_accuracy: 0.8906 - loss: 0.2979 - precision: 0.8785 - recall: 0.8624 - val_auc: 0.9352 - val_binary_accuracy: 0.8721 - val_loss: 0.3487 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 238/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9539 - binary_accuracy: 0.8875 - loss: 0.2983 - precision: 0.8776 - recall: 0.8550 - val_auc: 0.9354 - val_binary_accuracy: 0.8721 - val_loss: 0.3487 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 239/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9551 - binary_accuracy: 0.8914 - loss: 0.2957 - precision: 0.8799 - recall: 0.8621 - val_auc: 0.9356 - val_binary_accuracy: 0.8767 - val_loss: 0.3482 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 240/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9544 - binary_accuracy: 0.8898 - loss: 0.2970 - precision: 0.8818 - recall: 0.8577 - val_auc: 0.9357 - val_binary_accuracy: 0.8767 - val_loss: 0.3485 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 241/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9544 - binary_accuracy: 0.8875 - loss: 0.2974 - precision: 0.8783 - recall: 0.8558 - val_auc: 0.9357 - val_binary_accuracy: 0.8744 - val_loss: 0.3485 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 242/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9546 - binary_accuracy: 0.8891 - loss: 0.2965 - precision: 0.8811 - recall: 0.8553 - val_auc: 0.9363 - val_binary_accuracy: 0.8721 - val_loss: 0.3472 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 243/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9541 - binary_accuracy: 0.8914 - loss: 0.2975 - precision: 0.8835 - recall: 0.8592 - val_auc: 0.9357 - val_binary_accuracy: 0.8767 - val_loss: 0.3479 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 244/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9538 - binary_accuracy: 0.8875 - loss: 0.2987 - precision: 0.8790 - recall: 0.8532 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3486 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 245/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9545 - binary_accuracy: 0.8883 - loss: 0.2972 - precision: 0.8801 - recall: 0.8561 - val_auc: 0.9360 - val_binary_accuracy: 0.8744 - val_loss: 0.3471 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 246/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9546 - binary_accuracy: 0.8906 - loss: 0.2967 - precision: 0.8818 - recall: 0.8592 - val_auc: 0.9354 - val_binary_accuracy: 0.8744 - val_loss: 0.3486 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 247/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9545 - binary_accuracy: 0.8898 - loss: 0.2970 - precision: 0.8816 - recall: 0.8574 - val_auc: 0.9354 - val_binary_accuracy: 0.8744 - val_loss: 0.3492 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 248/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9544 - binary_accuracy: 0.8906 - loss: 0.2971 - precision: 0.8764 - recall: 0.8668 - val_auc: 0.9349 - val_binary_accuracy: 0.8744 - val_loss: 0.3490 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 249/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9548 - binary_accuracy: 0.8906 - loss: 0.2958 - precision: 0.8835 - recall: 0.8577 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3496 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 250/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9549 - binary_accuracy: 0.8906 - loss: 0.2959 - precision: 0.8840 - recall: 0.8548 - val_auc: 0.9350 - val_binary_accuracy: 0.8721 - val_loss: 0.3498 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 251/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9548 - binary_accuracy: 0.8922 - loss: 0.2962 - precision: 0.8825 - recall: 0.8631 - val_auc: 0.9350 - val_binary_accuracy: 0.8744 - val_loss: 0.3492 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 252/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9543 - binary_accuracy: 0.8883 - loss: 0.2978 - precision: 0.8764 - recall: 0.8587 - val_auc: 0.9357 - val_binary_accuracy: 0.8744 - val_loss: 0.3494 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 253/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9554 - binary_accuracy: 0.8930 - loss: 0.2943 - precision: 0.8866 - recall: 0.8590 - val_auc: 0.9360 - val_binary_accuracy: 0.8721 - val_loss: 0.3493 - val_precision: 0.8516 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 254/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9553 - binary_accuracy: 0.8906 - loss: 0.2945 - precision: 0.8849 - recall: 0.8558 - val_auc: 0.9355 - val_binary_accuracy: 0.8721 - val_loss: 0.3491 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 255/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9544 - binary_accuracy: 0.8906 - loss: 0.2973 - precision: 0.8816 - recall: 0.8590 - val_auc: 0.9357 - val_binary_accuracy: 0.8698 - val_loss: 0.3516 - val_precision: 0.8396 - val_recall: 0.8579 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 256/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9543 - binary_accuracy: 0.8906 - loss: 0.2969 - precision: 0.8830 - recall: 0.8571 - val_auc: 0.9361 - val_binary_accuracy: 0.8721 - val_loss: 0.3489 - val_precision: 0.8478 - val_recall: 0.8525 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 257/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9542 - binary_accuracy: 0.8914 - loss: 0.2981 - precision: 0.8825 - recall: 0.8616 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3488 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 258/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9553 - binary_accuracy: 0.8938 - loss: 0.2946 - precision: 0.8810 - recall: 0.8681 - val_auc: 0.9334 - val_binary_accuracy: 0.8721 - val_loss: 0.3519 - val_precision: 0.8636 - val_recall: 0.8306 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 259/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9567 - binary_accuracy: 0.8883 - loss: 0.2905 - precision: 0.8851 - recall: 0.8477 - val_auc: 0.9350 - val_binary_accuracy: 0.8698 - val_loss: 0.3500 - val_precision: 0.8508 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 260/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9549 - binary_accuracy: 0.8891 - loss: 0.2960 - precision: 0.8816 - recall: 0.8558 - val_auc: 0.9336 - val_binary_accuracy: 0.8744 - val_loss: 0.3523 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 261/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9550 - binary_accuracy: 0.8906 - loss: 0.2956 - precision: 0.8818 - recall: 0.8592 - val_auc: 0.9354 - val_binary_accuracy: 0.8721 - val_loss: 0.3496 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 262/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9554 - binary_accuracy: 0.8914 - loss: 0.2940 - precision: 0.8832 - recall: 0.8590 - val_auc: 0.9346 - val_binary_accuracy: 0.8721 - val_loss: 0.3512 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 7.3786e-04\n",
      "\n",
      "Epoch 263/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9553 - binary_accuracy: 0.8914 - loss: 0.2948 - precision: 0.8832 - recall: 0.8590 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3493 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 264/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9556 - binary_accuracy: 0.8922 - loss: 0.2939 - precision: 0.8820 - recall: 0.8626 - val_auc: 0.9352 - val_binary_accuracy: 0.8698 - val_loss: 0.3499 - val_precision: 0.8547 - val_recall: 0.8361 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 265/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9553 - binary_accuracy: 0.8930 - loss: 0.2951 - precision: 0.8829 - recall: 0.8652 - val_auc: 0.9351 - val_binary_accuracy: 0.8698 - val_loss: 0.3494 - val_precision: 0.8547 - val_recall: 0.8361 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 266/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9553 - binary_accuracy: 0.8906 - loss: 0.2950 - precision: 0.8830 - recall: 0.8571 - val_auc: 0.9362 - val_binary_accuracy: 0.8767 - val_loss: 0.3496 - val_precision: 0.8533 - val_recall: 0.8579 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 267/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9557 - binary_accuracy: 0.8930 - loss: 0.2925 - precision: 0.8853 - recall: 0.8611 - val_auc: 0.9358 - val_binary_accuracy: 0.8744 - val_loss: 0.3493 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 268/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9549 - binary_accuracy: 0.8930 - loss: 0.2951 - precision: 0.8849 - recall: 0.8606 - val_auc: 0.9352 - val_binary_accuracy: 0.8744 - val_loss: 0.3499 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 269/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9553 - binary_accuracy: 0.8938 - loss: 0.2949 - precision: 0.8853 - recall: 0.8626 - val_auc: 0.9352 - val_binary_accuracy: 0.8721 - val_loss: 0.3501 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 270/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9550 - binary_accuracy: 0.8914 - loss: 0.2955 - precision: 0.8832 - recall: 0.8590 - val_auc: 0.9358 - val_binary_accuracy: 0.8767 - val_loss: 0.3496 - val_precision: 0.8571 - val_recall: 0.8525 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 271/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9552 - binary_accuracy: 0.8914 - loss: 0.2948 - precision: 0.8832 - recall: 0.8590 - val_auc: 0.9356 - val_binary_accuracy: 0.8721 - val_loss: 0.3491 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 272/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9555 - binary_accuracy: 0.8922 - loss: 0.2939 - precision: 0.8820 - recall: 0.8626 - val_auc: 0.9355 - val_binary_accuracy: 0.8698 - val_loss: 0.3496 - val_precision: 0.8547 - val_recall: 0.8361 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 273/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9552 - binary_accuracy: 0.8930 - loss: 0.2951 - precision: 0.8841 - recall: 0.8631 - val_auc: 0.9354 - val_binary_accuracy: 0.8767 - val_loss: 0.3505 - val_precision: 0.8571 - val_recall: 0.8525 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 274/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9554 - binary_accuracy: 0.8914 - loss: 0.2945 - precision: 0.8851 - recall: 0.8577 - val_auc: 0.9359 - val_binary_accuracy: 0.8791 - val_loss: 0.3498 - val_precision: 0.8619 - val_recall: 0.8525 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 275/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9556 - binary_accuracy: 0.8922 - loss: 0.2934 - precision: 0.8866 - recall: 0.8574 - val_auc: 0.9355 - val_binary_accuracy: 0.8744 - val_loss: 0.3499 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 276/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9559 - binary_accuracy: 0.8914 - loss: 0.2932 - precision: 0.8851 - recall: 0.8577 - val_auc: 0.9359 - val_binary_accuracy: 0.8791 - val_loss: 0.3498 - val_precision: 0.8579 - val_recall: 0.8579 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 277/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9564 - binary_accuracy: 0.8953 - loss: 0.2918 - precision: 0.8872 - recall: 0.8645 - val_auc: 0.9351 - val_binary_accuracy: 0.8744 - val_loss: 0.3509 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 278/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9552 - binary_accuracy: 0.8930 - loss: 0.2949 - precision: 0.8851 - recall: 0.8608 - val_auc: 0.9360 - val_binary_accuracy: 0.8698 - val_loss: 0.3502 - val_precision: 0.8432 - val_recall: 0.8525 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 279/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9555 - binary_accuracy: 0.8969 - loss: 0.2936 - precision: 0.8848 - recall: 0.8718 - val_auc: 0.9355 - val_binary_accuracy: 0.8721 - val_loss: 0.3501 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 280/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9557 - binary_accuracy: 0.8945 - loss: 0.2928 - precision: 0.8856 - recall: 0.8645 - val_auc: 0.9352 - val_binary_accuracy: 0.8721 - val_loss: 0.3505 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 281/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9555 - binary_accuracy: 0.8938 - loss: 0.2940 - precision: 0.8870 - recall: 0.8611 - val_auc: 0.9346 - val_binary_accuracy: 0.8721 - val_loss: 0.3517 - val_precision: 0.8516 - val_recall: 0.8470 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 282/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9556 - binary_accuracy: 0.8938 - loss: 0.2925 - precision: 0.8849 - recall: 0.8621 - val_auc: 0.9352 - val_binary_accuracy: 0.8744 - val_loss: 0.3498 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 6.0896e-04\n",
      "\n",
      "Epoch 283/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9564 - binary_accuracy: 0.8930 - loss: 0.2916 - precision: 0.8839 - recall: 0.8629 - val_auc: 0.9360 - val_binary_accuracy: 0.8767 - val_loss: 0.3501 - val_precision: 0.8571 - val_recall: 0.8525 - learning_rate: 5.0258e-04\n",
      "\n",
      "Epoch 284/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9558 - binary_accuracy: 0.8930 - loss: 0.2938 - precision: 0.8804 - recall: 0.8658 - val_auc: 0.9359 - val_binary_accuracy: 0.8767 - val_loss: 0.3495 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 5.0258e-04\n",
      "\n",
      "Epoch 285/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9564 - binary_accuracy: 0.8930 - loss: 0.2922 - precision: 0.8870 - recall: 0.8595 - val_auc: 0.9358 - val_binary_accuracy: 0.8767 - val_loss: 0.3492 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 5.0258e-04\n",
      "\n",
      "./plots/calm-hare-496/learning_rate_vs_epoch.png                                  \n",
      "./plots/calm-hare-496/auc_vs_epoch.png                                            \n",
      "./plots/calm-hare-496/loss_vs_epoch.png                                           \n",
      "./plots/calm-hare-496/binary_accuracy_vs_epoch.png                                \n",
      "./plots/calm-hare-496/recall_vs_epoch.png                                         \n",
      "./plots/calm-hare-496/precision_vs_epoch.png                                      \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 513ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step         \n",
      "\n",
      " 80%|████████  | 12/15 [05:24<06:20, 126.86s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step         \n",
      "\n",
      " 80%|████████  | 12/15 [05:24<06:20, 126.86s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62504201977e484cae2c4cced9825fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m225/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m194/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m292/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run calm-hare-496 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/c36b0c5784bf477ea617cd7898ec61cb\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 87%|████████▋ | 13/15 [06:10<04:04, 122.48s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 03:33:27.475416: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.521067: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.565530: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.607936: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.653819: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.696599: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.742007: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.784195: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.827016: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.869949: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.910077: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.952190: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:27.993823: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:28.034960: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:28.075036: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:33:28.116022: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 4s - 53ms/step - auc: 0.9019 - binary_accuracy: 0.8414 - loss: 0.4062 - precision: 0.8200 - recall: 0.8066 - val_auc: 0.9186 - val_binary_accuracy: 0.8302 - val_loss: 0.3700 - val_precision: 0.7989 - val_recall: 0.8033 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9349 - binary_accuracy: 0.8617 - loss: 0.3240 - precision: 0.8361 - recall: 0.8407 - val_auc: 0.9285 - val_binary_accuracy: 0.8512 - val_loss: 0.3488 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8719 - loss: 0.3147 - precision: 0.8519 - recall: 0.8488 - val_auc: 0.9310 - val_binary_accuracy: 0.8558 - val_loss: 0.3422 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8734 - loss: 0.3093 - precision: 0.8569 - recall: 0.8443 - val_auc: 0.9316 - val_binary_accuracy: 0.8558 - val_loss: 0.3372 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9444 - binary_accuracy: 0.8781 - loss: 0.3022 - precision: 0.8641 - recall: 0.8483 - val_auc: 0.9308 - val_binary_accuracy: 0.8535 - val_loss: 0.3430 - val_precision: 0.8529 - val_recall: 0.7923 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9435 - binary_accuracy: 0.8781 - loss: 0.3027 - precision: 0.8721 - recall: 0.8370 - val_auc: 0.9334 - val_binary_accuracy: 0.8674 - val_loss: 0.3348 - val_precision: 0.8424 - val_recall: 0.8470 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8719 - loss: 0.3016 - precision: 0.8648 - recall: 0.8300 - val_auc: 0.9324 - val_binary_accuracy: 0.8512 - val_loss: 0.3351 - val_precision: 0.8439 - val_recall: 0.7978 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9457 - binary_accuracy: 0.8813 - loss: 0.2976 - precision: 0.8675 - recall: 0.8516 - val_auc: 0.9336 - val_binary_accuracy: 0.8605 - val_loss: 0.3359 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9463 - binary_accuracy: 0.8789 - loss: 0.2965 - precision: 0.8767 - recall: 0.8333 - val_auc: 0.9344 - val_binary_accuracy: 0.8651 - val_loss: 0.3307 - val_precision: 0.8531 - val_recall: 0.8251 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9458 - binary_accuracy: 0.8828 - loss: 0.2976 - precision: 0.8752 - recall: 0.8464 - val_auc: 0.9329 - val_binary_accuracy: 0.8628 - val_loss: 0.3327 - val_precision: 0.8523 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9466 - binary_accuracy: 0.8758 - loss: 0.2957 - precision: 0.8705 - recall: 0.8339 - val_auc: 0.9340 - val_binary_accuracy: 0.8744 - val_loss: 0.3322 - val_precision: 0.8486 - val_recall: 0.8579 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9480 - binary_accuracy: 0.8789 - loss: 0.2928 - precision: 0.8564 - recall: 0.8611 - val_auc: 0.9332 - val_binary_accuracy: 0.8581 - val_loss: 0.3440 - val_precision: 0.8631 - val_recall: 0.7923 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8836 - loss: 0.2938 - precision: 0.8738 - recall: 0.8498 - val_auc: 0.9334 - val_binary_accuracy: 0.8581 - val_loss: 0.3359 - val_precision: 0.8588 - val_recall: 0.7978 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9481 - binary_accuracy: 0.8805 - loss: 0.2910 - precision: 0.8729 - recall: 0.8425 - val_auc: 0.9345 - val_binary_accuracy: 0.8651 - val_loss: 0.3312 - val_precision: 0.8453 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9490 - binary_accuracy: 0.8836 - loss: 0.2902 - precision: 0.8701 - recall: 0.8558 - val_auc: 0.9343 - val_binary_accuracy: 0.8651 - val_loss: 0.3393 - val_precision: 0.8655 - val_recall: 0.8087 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9490 - binary_accuracy: 0.8836 - loss: 0.2889 - precision: 0.8755 - recall: 0.8483 - val_auc: 0.9341 - val_binary_accuracy: 0.8674 - val_loss: 0.3316 - val_precision: 0.8580 - val_recall: 0.8251 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9496 - binary_accuracy: 0.8859 - loss: 0.2875 - precision: 0.8748 - recall: 0.8556 - val_auc: 0.9359 - val_binary_accuracy: 0.8581 - val_loss: 0.3320 - val_precision: 0.8352 - val_recall: 0.8306 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9499 - binary_accuracy: 0.8852 - loss: 0.2864 - precision: 0.8715 - recall: 0.8571 - val_auc: 0.9359 - val_binary_accuracy: 0.8674 - val_loss: 0.3253 - val_precision: 0.8580 - val_recall: 0.8251 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9491 - binary_accuracy: 0.8867 - loss: 0.2882 - precision: 0.8738 - recall: 0.8595 - val_auc: 0.9356 - val_binary_accuracy: 0.8674 - val_loss: 0.3263 - val_precision: 0.8621 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9502 - binary_accuracy: 0.8844 - loss: 0.2864 - precision: 0.8774 - recall: 0.8485 - val_auc: 0.9344 - val_binary_accuracy: 0.8628 - val_loss: 0.3318 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9501 - binary_accuracy: 0.8820 - loss: 0.2858 - precision: 0.8669 - recall: 0.8558 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3279 - val_precision: 0.8523 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9498 - binary_accuracy: 0.8914 - loss: 0.2857 - precision: 0.8864 - recall: 0.8556 - val_auc: 0.9363 - val_binary_accuracy: 0.8651 - val_loss: 0.3230 - val_precision: 0.8492 - val_recall: 0.8306 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9506 - binary_accuracy: 0.8852 - loss: 0.2852 - precision: 0.8731 - recall: 0.8556 - val_auc: 0.9358 - val_binary_accuracy: 0.8698 - val_loss: 0.3288 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9512 - binary_accuracy: 0.8844 - loss: 0.2823 - precision: 0.8771 - recall: 0.8483 - val_auc: 0.9365 - val_binary_accuracy: 0.8605 - val_loss: 0.3265 - val_precision: 0.8398 - val_recall: 0.8306 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9506 - binary_accuracy: 0.8820 - loss: 0.2845 - precision: 0.8724 - recall: 0.8485 - val_auc: 0.9363 - val_binary_accuracy: 0.8674 - val_loss: 0.3233 - val_precision: 0.8500 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9514 - binary_accuracy: 0.8844 - loss: 0.2829 - precision: 0.8802 - recall: 0.8449 - val_auc: 0.9369 - val_binary_accuracy: 0.8674 - val_loss: 0.3217 - val_precision: 0.8351 - val_recall: 0.8579 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9512 - binary_accuracy: 0.8859 - loss: 0.2829 - precision: 0.8695 - recall: 0.8631 - val_auc: 0.9363 - val_binary_accuracy: 0.8628 - val_loss: 0.3267 - val_precision: 0.8444 - val_recall: 0.8306 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9526 - binary_accuracy: 0.8867 - loss: 0.2793 - precision: 0.8725 - recall: 0.8613 - val_auc: 0.9353 - val_binary_accuracy: 0.8651 - val_loss: 0.3282 - val_precision: 0.8453 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9507 - binary_accuracy: 0.8805 - loss: 0.2829 - precision: 0.8712 - recall: 0.8440 - val_auc: 0.9370 - val_binary_accuracy: 0.8698 - val_loss: 0.3197 - val_precision: 0.8508 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9523 - binary_accuracy: 0.8867 - loss: 0.2797 - precision: 0.8734 - recall: 0.8590 - val_auc: 0.9359 - val_binary_accuracy: 0.8605 - val_loss: 0.3309 - val_precision: 0.8596 - val_recall: 0.8033 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9517 - binary_accuracy: 0.8867 - loss: 0.2802 - precision: 0.8771 - recall: 0.8529 - val_auc: 0.9367 - val_binary_accuracy: 0.8581 - val_loss: 0.3238 - val_precision: 0.8506 - val_recall: 0.8087 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9517 - binary_accuracy: 0.8844 - loss: 0.2800 - precision: 0.8738 - recall: 0.8514 - val_auc: 0.9348 - val_binary_accuracy: 0.8721 - val_loss: 0.3329 - val_precision: 0.8902 - val_recall: 0.7978 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9508 - binary_accuracy: 0.8789 - loss: 0.2834 - precision: 0.8701 - recall: 0.8431 - val_auc: 0.9374 - val_binary_accuracy: 0.8674 - val_loss: 0.3192 - val_precision: 0.8424 - val_recall: 0.8470 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9533 - binary_accuracy: 0.8820 - loss: 0.2774 - precision: 0.8736 - recall: 0.8464 - val_auc: 0.9364 - val_binary_accuracy: 0.8628 - val_loss: 0.3288 - val_precision: 0.8370 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9525 - binary_accuracy: 0.8844 - loss: 0.2793 - precision: 0.8724 - recall: 0.8532 - val_auc: 0.9365 - val_binary_accuracy: 0.8698 - val_loss: 0.3182 - val_precision: 0.8547 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9518 - binary_accuracy: 0.8813 - loss: 0.2811 - precision: 0.8705 - recall: 0.8483 - val_auc: 0.9360 - val_binary_accuracy: 0.8721 - val_loss: 0.3217 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9522 - binary_accuracy: 0.8805 - loss: 0.2803 - precision: 0.8684 - recall: 0.8477 - val_auc: 0.9361 - val_binary_accuracy: 0.8721 - val_loss: 0.3215 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9529 - binary_accuracy: 0.8859 - loss: 0.2780 - precision: 0.8769 - recall: 0.8511 - val_auc: 0.9376 - val_binary_accuracy: 0.8698 - val_loss: 0.3251 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9526 - binary_accuracy: 0.8836 - loss: 0.2786 - precision: 0.8767 - recall: 0.8462 - val_auc: 0.9383 - val_binary_accuracy: 0.8744 - val_loss: 0.3179 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9532 - binary_accuracy: 0.8859 - loss: 0.2764 - precision: 0.8745 - recall: 0.8553 - val_auc: 0.9371 - val_binary_accuracy: 0.8674 - val_loss: 0.3182 - val_precision: 0.8539 - val_recall: 0.8306 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9536 - binary_accuracy: 0.8898 - loss: 0.2756 - precision: 0.8814 - recall: 0.8571 - val_auc: 0.9352 - val_binary_accuracy: 0.8674 - val_loss: 0.3343 - val_precision: 0.8580 - val_recall: 0.8251 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9524 - binary_accuracy: 0.8875 - loss: 0.2795 - precision: 0.8795 - recall: 0.8537 - val_auc: 0.9369 - val_binary_accuracy: 0.8721 - val_loss: 0.3238 - val_precision: 0.8721 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9541 - binary_accuracy: 0.8875 - loss: 0.2746 - precision: 0.8807 - recall: 0.8516 - val_auc: 0.9366 - val_binary_accuracy: 0.8698 - val_loss: 0.3291 - val_precision: 0.8588 - val_recall: 0.8306 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9525 - binary_accuracy: 0.8852 - loss: 0.2787 - precision: 0.8757 - recall: 0.8516 - val_auc: 0.9359 - val_binary_accuracy: 0.8791 - val_loss: 0.3234 - val_precision: 0.8743 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9542 - binary_accuracy: 0.8883 - loss: 0.2749 - precision: 0.8797 - recall: 0.8556 - val_auc: 0.9377 - val_binary_accuracy: 0.8721 - val_loss: 0.3154 - val_precision: 0.8556 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9539 - binary_accuracy: 0.8859 - loss: 0.2751 - precision: 0.8759 - recall: 0.8535 - val_auc: 0.9373 - val_binary_accuracy: 0.8791 - val_loss: 0.3197 - val_precision: 0.8701 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9541 - binary_accuracy: 0.8852 - loss: 0.2752 - precision: 0.8750 - recall: 0.8543 - val_auc: 0.9369 - val_binary_accuracy: 0.8767 - val_loss: 0.3199 - val_precision: 0.8533 - val_recall: 0.8579 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9537 - binary_accuracy: 0.8859 - loss: 0.2766 - precision: 0.8734 - recall: 0.8574 - val_auc: 0.9372 - val_binary_accuracy: 0.8674 - val_loss: 0.3224 - val_precision: 0.8462 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9539 - binary_accuracy: 0.8836 - loss: 0.2754 - precision: 0.8722 - recall: 0.8514 - val_auc: 0.9362 - val_binary_accuracy: 0.8744 - val_loss: 0.3185 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9546 - binary_accuracy: 0.8883 - loss: 0.2750 - precision: 0.8785 - recall: 0.8577 - val_auc: 0.9366 - val_binary_accuracy: 0.8674 - val_loss: 0.3229 - val_precision: 0.8462 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9561 - binary_accuracy: 0.8891 - loss: 0.2698 - precision: 0.8847 - recall: 0.8525 - val_auc: 0.9368 - val_binary_accuracy: 0.8744 - val_loss: 0.3225 - val_precision: 0.8525 - val_recall: 0.8525 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9550 - binary_accuracy: 0.8844 - loss: 0.2715 - precision: 0.8713 - recall: 0.8553 - val_auc: 0.9378 - val_binary_accuracy: 0.8744 - val_loss: 0.3189 - val_precision: 0.8486 - val_recall: 0.8579 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9551 - binary_accuracy: 0.8867 - loss: 0.2723 - precision: 0.8736 - recall: 0.8592 - val_auc: 0.9378 - val_binary_accuracy: 0.8814 - val_loss: 0.3188 - val_precision: 0.8626 - val_recall: 0.8579 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9545 - binary_accuracy: 0.8891 - loss: 0.2734 - precision: 0.8828 - recall: 0.8537 - val_auc: 0.9344 - val_binary_accuracy: 0.8674 - val_loss: 0.3248 - val_precision: 0.8462 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9568 - binary_accuracy: 0.8891 - loss: 0.2677 - precision: 0.8702 - recall: 0.8702 - val_auc: 0.9337 - val_binary_accuracy: 0.8721 - val_loss: 0.3353 - val_precision: 0.8721 - val_recall: 0.8197 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9558 - binary_accuracy: 0.8852 - loss: 0.2699 - precision: 0.8757 - recall: 0.8516 - val_auc: 0.9366 - val_binary_accuracy: 0.8744 - val_loss: 0.3220 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9567 - binary_accuracy: 0.8883 - loss: 0.2674 - precision: 0.8769 - recall: 0.8592 - val_auc: 0.9367 - val_binary_accuracy: 0.8698 - val_loss: 0.3261 - val_precision: 0.8629 - val_recall: 0.8251 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9570 - binary_accuracy: 0.8859 - loss: 0.2675 - precision: 0.8652 - recall: 0.8684 - val_auc: 0.9341 - val_binary_accuracy: 0.8698 - val_loss: 0.3294 - val_precision: 0.8547 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9560 - binary_accuracy: 0.8844 - loss: 0.2695 - precision: 0.8729 - recall: 0.8537 - val_auc: 0.9373 - val_binary_accuracy: 0.8767 - val_loss: 0.3196 - val_precision: 0.8652 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9568 - binary_accuracy: 0.8844 - loss: 0.2681 - precision: 0.8650 - recall: 0.8650 - val_auc: 0.9362 - val_binary_accuracy: 0.8767 - val_loss: 0.3216 - val_precision: 0.8693 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9577 - binary_accuracy: 0.8891 - loss: 0.2637 - precision: 0.8755 - recall: 0.8626 - val_auc: 0.9363 - val_binary_accuracy: 0.8721 - val_loss: 0.3284 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9567 - binary_accuracy: 0.8852 - loss: 0.2683 - precision: 0.8674 - recall: 0.8626 - val_auc: 0.9366 - val_binary_accuracy: 0.8837 - val_loss: 0.3198 - val_precision: 0.8674 - val_recall: 0.8579 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9570 - binary_accuracy: 0.8898 - loss: 0.2669 - precision: 0.8741 - recall: 0.8661 - val_auc: 0.9368 - val_binary_accuracy: 0.8744 - val_loss: 0.3234 - val_precision: 0.8413 - val_recall: 0.8689 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9573 - binary_accuracy: 0.8914 - loss: 0.2663 - precision: 0.8790 - recall: 0.8645 - val_auc: 0.9353 - val_binary_accuracy: 0.8698 - val_loss: 0.3230 - val_precision: 0.8470 - val_recall: 0.8470 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9580 - binary_accuracy: 0.8852 - loss: 0.2646 - precision: 0.8663 - recall: 0.8647 - val_auc: 0.9329 - val_binary_accuracy: 0.8698 - val_loss: 0.3316 - val_precision: 0.8508 - val_recall: 0.8415 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9576 - binary_accuracy: 0.8914 - loss: 0.2646 - precision: 0.8704 - recall: 0.8752 - val_auc: 0.9368 - val_binary_accuracy: 0.8814 - val_loss: 0.3196 - val_precision: 0.8626 - val_recall: 0.8579 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9581 - binary_accuracy: 0.8867 - loss: 0.2636 - precision: 0.8706 - recall: 0.8626 - val_auc: 0.9375 - val_binary_accuracy: 0.8814 - val_loss: 0.3235 - val_precision: 0.8626 - val_recall: 0.8579 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9578 - binary_accuracy: 0.8898 - loss: 0.2637 - precision: 0.8732 - recall: 0.8684 - val_auc: 0.9361 - val_binary_accuracy: 0.8791 - val_loss: 0.3264 - val_precision: 0.8619 - val_recall: 0.8525 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9584 - binary_accuracy: 0.8891 - loss: 0.2628 - precision: 0.8636 - recall: 0.8793 - val_auc: 0.9341 - val_binary_accuracy: 0.8698 - val_loss: 0.3351 - val_precision: 0.8671 - val_recall: 0.8197 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9600 - binary_accuracy: 0.8945 - loss: 0.2573 - precision: 0.8803 - recall: 0.8723 - val_auc: 0.9383 - val_binary_accuracy: 0.8744 - val_loss: 0.3165 - val_precision: 0.8486 - val_recall: 0.8579 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9586 - binary_accuracy: 0.8914 - loss: 0.2622 - precision: 0.8675 - recall: 0.8787 - val_auc: 0.9379 - val_binary_accuracy: 0.8791 - val_loss: 0.3199 - val_precision: 0.8394 - val_recall: 0.8852 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9580 - binary_accuracy: 0.8922 - loss: 0.2642 - precision: 0.8704 - recall: 0.8768 - val_auc: 0.9361 - val_binary_accuracy: 0.8744 - val_loss: 0.3259 - val_precision: 0.8603 - val_recall: 0.8415 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9586 - binary_accuracy: 0.8898 - loss: 0.2628 - precision: 0.8729 - recall: 0.8681 - val_auc: 0.9358 - val_binary_accuracy: 0.8767 - val_loss: 0.3204 - val_precision: 0.8652 - val_recall: 0.8415 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9586 - binary_accuracy: 0.8969 - loss: 0.2626 - precision: 0.8821 - recall: 0.8757 - val_auc: 0.9365 - val_binary_accuracy: 0.8791 - val_loss: 0.3225 - val_precision: 0.8503 - val_recall: 0.8689 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9594 - binary_accuracy: 0.8930 - loss: 0.2595 - precision: 0.8799 - recall: 0.8686 - val_auc: 0.9370 - val_binary_accuracy: 0.8767 - val_loss: 0.3225 - val_precision: 0.8495 - val_recall: 0.8634 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9603 - binary_accuracy: 0.8906 - loss: 0.2577 - precision: 0.8709 - recall: 0.8741 - val_auc: 0.9340 - val_binary_accuracy: 0.8767 - val_loss: 0.3317 - val_precision: 0.8693 - val_recall: 0.8361 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9589 - binary_accuracy: 0.8914 - loss: 0.2627 - precision: 0.8764 - recall: 0.8684 - val_auc: 0.9376 - val_binary_accuracy: 0.8767 - val_loss: 0.3248 - val_precision: 0.8495 - val_recall: 0.8634 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9616 - binary_accuracy: 0.9000 - loss: 0.2533 - precision: 0.8788 - recall: 0.8885 - val_auc: 0.9367 - val_binary_accuracy: 0.8744 - val_loss: 0.3199 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9588 - binary_accuracy: 0.8906 - loss: 0.2618 - precision: 0.8734 - recall: 0.8702 - val_auc: 0.9356 - val_binary_accuracy: 0.8767 - val_loss: 0.3251 - val_precision: 0.8421 - val_recall: 0.8743 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9603 - binary_accuracy: 0.8938 - loss: 0.2572 - precision: 0.8799 - recall: 0.8702 - val_auc: 0.9336 - val_binary_accuracy: 0.8767 - val_loss: 0.3277 - val_precision: 0.8611 - val_recall: 0.8470 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9607 - binary_accuracy: 0.8977 - loss: 0.2568 - precision: 0.8793 - recall: 0.8810 - val_auc: 0.9360 - val_binary_accuracy: 0.8767 - val_loss: 0.3225 - val_precision: 0.8571 - val_recall: 0.8525 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9600 - binary_accuracy: 0.8930 - loss: 0.2585 - precision: 0.8780 - recall: 0.8700 - val_auc: 0.9368 - val_binary_accuracy: 0.8744 - val_loss: 0.3186 - val_precision: 0.8564 - val_recall: 0.8470 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9616 - binary_accuracy: 0.8961 - loss: 0.2531 - precision: 0.8799 - recall: 0.8750 - val_auc: 0.9344 - val_binary_accuracy: 0.8744 - val_loss: 0.3358 - val_precision: 0.8644 - val_recall: 0.8361 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9600 - binary_accuracy: 0.8930 - loss: 0.2581 - precision: 0.8750 - recall: 0.8734 - val_auc: 0.9371 - val_binary_accuracy: 0.8721 - val_loss: 0.3223 - val_precision: 0.8299 - val_recall: 0.8798 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9598 - binary_accuracy: 0.8906 - loss: 0.2593 - precision: 0.8693 - recall: 0.8757 - val_auc: 0.9335 - val_binary_accuracy: 0.8721 - val_loss: 0.3373 - val_precision: 0.8596 - val_recall: 0.8361 - learning_rate: 0.0031\n",
      "\n",
      "./plots/clean-rat-663/learning_rate_vs_epoch.png                                  \n",
      "./plots/clean-rat-663/auc_vs_epoch.png                                            \n",
      "./plots/clean-rat-663/loss_vs_epoch.png                                           \n",
      "./plots/clean-rat-663/binary_accuracy_vs_epoch.png                                \n",
      "./plots/clean-rat-663/recall_vs_epoch.png                                         \n",
      "./plots/clean-rat-663/precision_vs_epoch.png                                      \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 430ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step         \n",
      "\n",
      " 87%|████████▋ | 13/15 [06:35<04:04, 122.48s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step         \n",
      "\n",
      " 87%|████████▋ | 13/15 [06:35<04:04, 122.48s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599efabefcdd4f259315b9727411a881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 66/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 98/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 66/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run clean-rat-663 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/33360b0b06e74507a84a3e1a47646f81\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 93%|█████████▎| 14/15 [07:21<01:42, 102.26s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 03:34:38.723883: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:38.769923: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:38.814248: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:38.859091: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:38.901781: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:38.947566: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:38.987761: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.032652: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.073908: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.116997: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.158273: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.201330: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.241585: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.283572: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.324565: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-07 03:34:39.367297: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 4s - 55ms/step - auc: 0.6151 - binary_accuracy: 0.6180 - loss: 0.6919 - precision: 0.6239 - recall: 0.2669 - val_auc: 0.6643 - val_binary_accuracy: 0.6558 - val_loss: 0.6757 - val_precision: 0.6733 - val_recall: 0.3716 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7270 - binary_accuracy: 0.6664 - loss: 0.6509 - precision: 0.7010 - recall: 0.3850 - val_auc: 0.7519 - val_binary_accuracy: 0.6977 - val_loss: 0.6393 - val_precision: 0.7265 - val_recall: 0.4645 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8111 - binary_accuracy: 0.7141 - loss: 0.6130 - precision: 0.7405 - recall: 0.5037 - val_auc: 0.8147 - val_binary_accuracy: 0.7349 - val_loss: 0.6070 - val_precision: 0.7556 - val_recall: 0.5574 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8658 - binary_accuracy: 0.7672 - loss: 0.5797 - precision: 0.7763 - recall: 0.6367 - val_auc: 0.8576 - val_binary_accuracy: 0.7814 - val_loss: 0.5786 - val_precision: 0.7871 - val_recall: 0.6667 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8953 - binary_accuracy: 0.8055 - loss: 0.5514 - precision: 0.7906 - recall: 0.7399 - val_auc: 0.8828 - val_binary_accuracy: 0.8163 - val_loss: 0.5538 - val_precision: 0.7955 - val_recall: 0.7650 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9112 - binary_accuracy: 0.8297 - loss: 0.5253 - precision: 0.8060 - recall: 0.7912 - val_auc: 0.8932 - val_binary_accuracy: 0.8233 - val_loss: 0.5321 - val_precision: 0.7923 - val_recall: 0.7923 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9185 - binary_accuracy: 0.8398 - loss: 0.5033 - precision: 0.8109 - recall: 0.8154 - val_auc: 0.8998 - val_binary_accuracy: 0.8186 - val_loss: 0.5133 - val_precision: 0.7838 - val_recall: 0.7923 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9228 - binary_accuracy: 0.8469 - loss: 0.4838 - precision: 0.8169 - recall: 0.8288 - val_auc: 0.9036 - val_binary_accuracy: 0.8186 - val_loss: 0.4967 - val_precision: 0.7838 - val_recall: 0.7923 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9257 - binary_accuracy: 0.8484 - loss: 0.4668 - precision: 0.8154 - recall: 0.8333 - val_auc: 0.9069 - val_binary_accuracy: 0.8233 - val_loss: 0.4816 - val_precision: 0.7831 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9278 - binary_accuracy: 0.8461 - loss: 0.4510 - precision: 0.8107 - recall: 0.8330 - val_auc: 0.9084 - val_binary_accuracy: 0.8233 - val_loss: 0.4688 - val_precision: 0.7831 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9307 - binary_accuracy: 0.8492 - loss: 0.4361 - precision: 0.8131 - recall: 0.8412 - val_auc: 0.9105 - val_binary_accuracy: 0.8233 - val_loss: 0.4572 - val_precision: 0.7801 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9317 - binary_accuracy: 0.8500 - loss: 0.4240 - precision: 0.8105 - recall: 0.8462 - val_auc: 0.9117 - val_binary_accuracy: 0.8209 - val_loss: 0.4470 - val_precision: 0.7819 - val_recall: 0.8033 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9334 - binary_accuracy: 0.8531 - loss: 0.4127 - precision: 0.8129 - recall: 0.8516 - val_auc: 0.9129 - val_binary_accuracy: 0.8209 - val_loss: 0.4382 - val_precision: 0.7819 - val_recall: 0.8033 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9326 - binary_accuracy: 0.8500 - loss: 0.4051 - precision: 0.8080 - recall: 0.8495 - val_auc: 0.9140 - val_binary_accuracy: 0.8233 - val_loss: 0.4302 - val_precision: 0.7831 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9337 - binary_accuracy: 0.8516 - loss: 0.3965 - precision: 0.8105 - recall: 0.8493 - val_auc: 0.9146 - val_binary_accuracy: 0.8233 - val_loss: 0.4235 - val_precision: 0.7801 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9345 - binary_accuracy: 0.8547 - loss: 0.3891 - precision: 0.8153 - recall: 0.8540 - val_auc: 0.9158 - val_binary_accuracy: 0.8233 - val_loss: 0.4174 - val_precision: 0.7801 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9345 - binary_accuracy: 0.8555 - loss: 0.3841 - precision: 0.8175 - recall: 0.8519 - val_auc: 0.9165 - val_binary_accuracy: 0.8233 - val_loss: 0.4124 - val_precision: 0.7801 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9374 - binary_accuracy: 0.8570 - loss: 0.3742 - precision: 0.8201 - recall: 0.8516 - val_auc: 0.9171 - val_binary_accuracy: 0.8256 - val_loss: 0.4083 - val_precision: 0.7812 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9353 - binary_accuracy: 0.8539 - loss: 0.3737 - precision: 0.8164 - recall: 0.8506 - val_auc: 0.9175 - val_binary_accuracy: 0.8302 - val_loss: 0.4043 - val_precision: 0.7835 - val_recall: 0.8306 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9362 - binary_accuracy: 0.8578 - loss: 0.3688 - precision: 0.8199 - recall: 0.8558 - val_auc: 0.9182 - val_binary_accuracy: 0.8349 - val_loss: 0.4010 - val_precision: 0.7887 - val_recall: 0.8361 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8602 - loss: 0.3652 - precision: 0.8228 - recall: 0.8574 - val_auc: 0.9186 - val_binary_accuracy: 0.8372 - val_loss: 0.3982 - val_precision: 0.7927 - val_recall: 0.8361 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9369 - binary_accuracy: 0.8602 - loss: 0.3615 - precision: 0.8231 - recall: 0.8577 - val_auc: 0.9191 - val_binary_accuracy: 0.8349 - val_loss: 0.3956 - val_precision: 0.7887 - val_recall: 0.8361 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9371 - binary_accuracy: 0.8609 - loss: 0.3582 - precision: 0.8243 - recall: 0.8574 - val_auc: 0.9199 - val_binary_accuracy: 0.8302 - val_loss: 0.3936 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8594 - loss: 0.3553 - precision: 0.8228 - recall: 0.8558 - val_auc: 0.9204 - val_binary_accuracy: 0.8302 - val_loss: 0.3916 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9371 - binary_accuracy: 0.8602 - loss: 0.3545 - precision: 0.8207 - recall: 0.8585 - val_auc: 0.9209 - val_binary_accuracy: 0.8302 - val_loss: 0.3898 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8625 - loss: 0.3517 - precision: 0.8254 - recall: 0.8587 - val_auc: 0.9212 - val_binary_accuracy: 0.8302 - val_loss: 0.3886 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9383 - binary_accuracy: 0.8633 - loss: 0.3494 - precision: 0.8278 - recall: 0.8595 - val_auc: 0.9216 - val_binary_accuracy: 0.8302 - val_loss: 0.3873 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9401 - binary_accuracy: 0.8641 - loss: 0.3449 - precision: 0.8263 - recall: 0.8626 - val_auc: 0.9219 - val_binary_accuracy: 0.8326 - val_loss: 0.3861 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9394 - binary_accuracy: 0.8641 - loss: 0.3451 - precision: 0.8278 - recall: 0.8611 - val_auc: 0.9220 - val_binary_accuracy: 0.8326 - val_loss: 0.3852 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8617 - loss: 0.3455 - precision: 0.8254 - recall: 0.8571 - val_auc: 0.9224 - val_binary_accuracy: 0.8326 - val_loss: 0.3842 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8633 - loss: 0.3444 - precision: 0.8280 - recall: 0.8569 - val_auc: 0.9225 - val_binary_accuracy: 0.8326 - val_loss: 0.3834 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9390 - binary_accuracy: 0.8625 - loss: 0.3435 - precision: 0.8274 - recall: 0.8548 - val_auc: 0.9230 - val_binary_accuracy: 0.8326 - val_loss: 0.3827 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8641 - loss: 0.3414 - precision: 0.8298 - recall: 0.8571 - val_auc: 0.9231 - val_binary_accuracy: 0.8326 - val_loss: 0.3824 - val_precision: 0.7876 - val_recall: 0.8306 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9398 - binary_accuracy: 0.8641 - loss: 0.3404 - precision: 0.8298 - recall: 0.8571 - val_auc: 0.9233 - val_binary_accuracy: 0.8302 - val_loss: 0.3818 - val_precision: 0.7865 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9395 - binary_accuracy: 0.8633 - loss: 0.3407 - precision: 0.8298 - recall: 0.8556 - val_auc: 0.9234 - val_binary_accuracy: 0.8349 - val_loss: 0.3815 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8672 - loss: 0.3373 - precision: 0.8360 - recall: 0.8574 - val_auc: 0.9239 - val_binary_accuracy: 0.8349 - val_loss: 0.3808 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8672 - loss: 0.3354 - precision: 0.8375 - recall: 0.8558 - val_auc: 0.9238 - val_binary_accuracy: 0.8372 - val_loss: 0.3805 - val_precision: 0.7989 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9405 - binary_accuracy: 0.8648 - loss: 0.3370 - precision: 0.8336 - recall: 0.8535 - val_auc: 0.9238 - val_binary_accuracy: 0.8372 - val_loss: 0.3802 - val_precision: 0.7989 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8672 - loss: 0.3354 - precision: 0.8366 - recall: 0.8550 - val_auc: 0.9241 - val_binary_accuracy: 0.8372 - val_loss: 0.3797 - val_precision: 0.7989 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8695 - loss: 0.3355 - precision: 0.8417 - recall: 0.8556 - val_auc: 0.9242 - val_binary_accuracy: 0.8395 - val_loss: 0.3794 - val_precision: 0.8032 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9409 - binary_accuracy: 0.8680 - loss: 0.3355 - precision: 0.8381 - recall: 0.8550 - val_auc: 0.9245 - val_binary_accuracy: 0.8395 - val_loss: 0.3792 - val_precision: 0.8032 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8687 - loss: 0.3355 - precision: 0.8390 - recall: 0.8574 - val_auc: 0.9246 - val_binary_accuracy: 0.8372 - val_loss: 0.3789 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8687 - loss: 0.3347 - precision: 0.8399 - recall: 0.8553 - val_auc: 0.9246 - val_binary_accuracy: 0.8395 - val_loss: 0.3788 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8680 - loss: 0.3338 - precision: 0.8387 - recall: 0.8556 - val_auc: 0.9248 - val_binary_accuracy: 0.8395 - val_loss: 0.3784 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8703 - loss: 0.3327 - precision: 0.8448 - recall: 0.8540 - val_auc: 0.9250 - val_binary_accuracy: 0.8395 - val_loss: 0.3781 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8711 - loss: 0.3319 - precision: 0.8460 - recall: 0.8537 - val_auc: 0.9250 - val_binary_accuracy: 0.8395 - val_loss: 0.3778 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8711 - loss: 0.3326 - precision: 0.8466 - recall: 0.8543 - val_auc: 0.9252 - val_binary_accuracy: 0.8395 - val_loss: 0.3776 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8703 - loss: 0.3332 - precision: 0.8457 - recall: 0.8519 - val_auc: 0.9252 - val_binary_accuracy: 0.8395 - val_loss: 0.3774 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8703 - loss: 0.3321 - precision: 0.8460 - recall: 0.8522 - val_auc: 0.9251 - val_binary_accuracy: 0.8395 - val_loss: 0.3773 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8695 - loss: 0.3325 - precision: 0.8457 - recall: 0.8504 - val_auc: 0.9252 - val_binary_accuracy: 0.8395 - val_loss: 0.3770 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8727 - loss: 0.3273 - precision: 0.8504 - recall: 0.8519 - val_auc: 0.9254 - val_binary_accuracy: 0.8395 - val_loss: 0.3767 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8703 - loss: 0.3313 - precision: 0.8455 - recall: 0.8516 - val_auc: 0.9256 - val_binary_accuracy: 0.8395 - val_loss: 0.3765 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9427 - binary_accuracy: 0.8711 - loss: 0.3287 - precision: 0.8488 - recall: 0.8504 - val_auc: 0.9254 - val_binary_accuracy: 0.8395 - val_loss: 0.3763 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8711 - loss: 0.3292 - precision: 0.8475 - recall: 0.8522 - val_auc: 0.9255 - val_binary_accuracy: 0.8395 - val_loss: 0.3762 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8727 - loss: 0.3290 - precision: 0.8501 - recall: 0.8516 - val_auc: 0.9257 - val_binary_accuracy: 0.8395 - val_loss: 0.3759 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8719 - loss: 0.3287 - precision: 0.8493 - recall: 0.8493 - val_auc: 0.9257 - val_binary_accuracy: 0.8419 - val_loss: 0.3759 - val_precision: 0.8108 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8719 - loss: 0.3298 - precision: 0.8495 - recall: 0.8495 - val_auc: 0.9257 - val_binary_accuracy: 0.8419 - val_loss: 0.3757 - val_precision: 0.8108 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8734 - loss: 0.3274 - precision: 0.8545 - recall: 0.8483 - val_auc: 0.9258 - val_binary_accuracy: 0.8442 - val_loss: 0.3754 - val_precision: 0.8118 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8750 - loss: 0.3247 - precision: 0.8519 - recall: 0.8550 - val_auc: 0.9258 - val_binary_accuracy: 0.8442 - val_loss: 0.3753 - val_precision: 0.8118 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8719 - loss: 0.3289 - precision: 0.8521 - recall: 0.8459 - val_auc: 0.9259 - val_binary_accuracy: 0.8465 - val_loss: 0.3750 - val_precision: 0.8162 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8742 - loss: 0.3280 - precision: 0.8535 - recall: 0.8519 - val_auc: 0.9259 - val_binary_accuracy: 0.8465 - val_loss: 0.3748 - val_precision: 0.8162 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8734 - loss: 0.3270 - precision: 0.8532 - recall: 0.8501 - val_auc: 0.9260 - val_binary_accuracy: 0.8465 - val_loss: 0.3749 - val_precision: 0.8162 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8734 - loss: 0.3263 - precision: 0.8532 - recall: 0.8501 - val_auc: 0.9261 - val_binary_accuracy: 0.8465 - val_loss: 0.3747 - val_precision: 0.8162 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9429 - binary_accuracy: 0.8734 - loss: 0.3274 - precision: 0.8532 - recall: 0.8501 - val_auc: 0.9261 - val_binary_accuracy: 0.8488 - val_loss: 0.3745 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9429 - binary_accuracy: 0.8719 - loss: 0.3276 - precision: 0.8532 - recall: 0.8470 - val_auc: 0.9261 - val_binary_accuracy: 0.8465 - val_loss: 0.3741 - val_precision: 0.8162 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9439 - binary_accuracy: 0.8719 - loss: 0.3250 - precision: 0.8524 - recall: 0.8462 - val_auc: 0.9261 - val_binary_accuracy: 0.8465 - val_loss: 0.3739 - val_precision: 0.8162 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9438 - binary_accuracy: 0.8727 - loss: 0.3251 - precision: 0.8529 - recall: 0.8483 - val_auc: 0.9262 - val_binary_accuracy: 0.8488 - val_loss: 0.3738 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9433 - binary_accuracy: 0.8734 - loss: 0.3265 - precision: 0.8558 - recall: 0.8464 - val_auc: 0.9263 - val_binary_accuracy: 0.8488 - val_loss: 0.3736 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9437 - binary_accuracy: 0.8727 - loss: 0.3253 - precision: 0.8514 - recall: 0.8498 - val_auc: 0.9262 - val_binary_accuracy: 0.8512 - val_loss: 0.3734 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8734 - loss: 0.3254 - precision: 0.8556 - recall: 0.8462 - val_auc: 0.9264 - val_binary_accuracy: 0.8512 - val_loss: 0.3733 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9438 - binary_accuracy: 0.8742 - loss: 0.3246 - precision: 0.8540 - recall: 0.8493 - val_auc: 0.9265 - val_binary_accuracy: 0.8512 - val_loss: 0.3732 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9435 - binary_accuracy: 0.8742 - loss: 0.3249 - precision: 0.8574 - recall: 0.8464 - val_auc: 0.9265 - val_binary_accuracy: 0.8512 - val_loss: 0.3730 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8727 - loss: 0.3259 - precision: 0.8537 - recall: 0.8459 - val_auc: 0.9266 - val_binary_accuracy: 0.8512 - val_loss: 0.3727 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8742 - loss: 0.3248 - precision: 0.8532 - recall: 0.8516 - val_auc: 0.9268 - val_binary_accuracy: 0.8535 - val_loss: 0.3726 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9439 - binary_accuracy: 0.8742 - loss: 0.3243 - precision: 0.8529 - recall: 0.8514 - val_auc: 0.9267 - val_binary_accuracy: 0.8535 - val_loss: 0.3725 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8750 - loss: 0.3222 - precision: 0.8545 - recall: 0.8514 - val_auc: 0.9267 - val_binary_accuracy: 0.8535 - val_loss: 0.3724 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9444 - binary_accuracy: 0.8758 - loss: 0.3228 - precision: 0.8545 - recall: 0.8529 - val_auc: 0.9269 - val_binary_accuracy: 0.8535 - val_loss: 0.3724 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9444 - binary_accuracy: 0.8742 - loss: 0.3227 - precision: 0.8529 - recall: 0.8514 - val_auc: 0.9269 - val_binary_accuracy: 0.8535 - val_loss: 0.3720 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9447 - binary_accuracy: 0.8750 - loss: 0.3222 - precision: 0.8550 - recall: 0.8519 - val_auc: 0.9269 - val_binary_accuracy: 0.8535 - val_loss: 0.3721 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8742 - loss: 0.3220 - precision: 0.8529 - recall: 0.8514 - val_auc: 0.9269 - val_binary_accuracy: 0.8535 - val_loss: 0.3718 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9440 - binary_accuracy: 0.8742 - loss: 0.3238 - precision: 0.8548 - recall: 0.8501 - val_auc: 0.9268 - val_binary_accuracy: 0.8535 - val_loss: 0.3718 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8766 - loss: 0.3230 - precision: 0.8593 - recall: 0.8498 - val_auc: 0.9269 - val_binary_accuracy: 0.8535 - val_loss: 0.3716 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9447 - binary_accuracy: 0.8734 - loss: 0.3217 - precision: 0.8511 - recall: 0.8511 - val_auc: 0.9270 - val_binary_accuracy: 0.8535 - val_loss: 0.3713 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8750 - loss: 0.3202 - precision: 0.8529 - recall: 0.8529 - val_auc: 0.9270 - val_binary_accuracy: 0.8535 - val_loss: 0.3713 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8773 - loss: 0.3228 - precision: 0.8606 - recall: 0.8495 - val_auc: 0.9269 - val_binary_accuracy: 0.8535 - val_loss: 0.3713 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 86/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8750 - loss: 0.3227 - precision: 0.8566 - recall: 0.8504 - val_auc: 0.9270 - val_binary_accuracy: 0.8535 - val_loss: 0.3711 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 87/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8742 - loss: 0.3221 - precision: 0.8548 - recall: 0.8501 - val_auc: 0.9270 - val_binary_accuracy: 0.8535 - val_loss: 0.3709 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 88/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8758 - loss: 0.3219 - precision: 0.8566 - recall: 0.8519 - val_auc: 0.9271 - val_binary_accuracy: 0.8535 - val_loss: 0.3709 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 89/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8750 - loss: 0.3222 - precision: 0.8564 - recall: 0.8501 - val_auc: 0.9271 - val_binary_accuracy: 0.8535 - val_loss: 0.3707 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 90/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8766 - loss: 0.3205 - precision: 0.8598 - recall: 0.8504 - val_auc: 0.9270 - val_binary_accuracy: 0.8535 - val_loss: 0.3707 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 91/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9443 - binary_accuracy: 0.8750 - loss: 0.3224 - precision: 0.8558 - recall: 0.8495 - val_auc: 0.9270 - val_binary_accuracy: 0.8535 - val_loss: 0.3706 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 92/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8758 - loss: 0.3222 - precision: 0.8582 - recall: 0.8504 - val_auc: 0.9268 - val_binary_accuracy: 0.8535 - val_loss: 0.3705 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 93/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8766 - loss: 0.3205 - precision: 0.8593 - recall: 0.8498 - val_auc: 0.9270 - val_binary_accuracy: 0.8488 - val_loss: 0.3702 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 94/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9452 - binary_accuracy: 0.8773 - loss: 0.3205 - precision: 0.8614 - recall: 0.8504 - val_auc: 0.9271 - val_binary_accuracy: 0.8488 - val_loss: 0.3703 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 95/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9449 - binary_accuracy: 0.8773 - loss: 0.3210 - precision: 0.8609 - recall: 0.8498 - val_auc: 0.9271 - val_binary_accuracy: 0.8488 - val_loss: 0.3701 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 96/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9462 - binary_accuracy: 0.8781 - loss: 0.3176 - precision: 0.8590 - recall: 0.8558 - val_auc: 0.9272 - val_binary_accuracy: 0.8488 - val_loss: 0.3699 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 97/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9465 - binary_accuracy: 0.8789 - loss: 0.3169 - precision: 0.8582 - recall: 0.8566 - val_auc: 0.9272 - val_binary_accuracy: 0.8488 - val_loss: 0.3699 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 98/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8781 - loss: 0.3207 - precision: 0.8587 - recall: 0.8556 - val_auc: 0.9274 - val_binary_accuracy: 0.8488 - val_loss: 0.3698 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 99/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8781 - loss: 0.3204 - precision: 0.8603 - recall: 0.8540 - val_auc: 0.9273 - val_binary_accuracy: 0.8488 - val_loss: 0.3697 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 100/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8781 - loss: 0.3200 - precision: 0.8600 - recall: 0.8537 - val_auc: 0.9273 - val_binary_accuracy: 0.8488 - val_loss: 0.3697 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 101/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8781 - loss: 0.3191 - precision: 0.8600 - recall: 0.8537 - val_auc: 0.9273 - val_binary_accuracy: 0.8488 - val_loss: 0.3695 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 102/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8773 - loss: 0.3209 - precision: 0.8569 - recall: 0.8553 - val_auc: 0.9273 - val_binary_accuracy: 0.8488 - val_loss: 0.3694 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 103/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9451 - binary_accuracy: 0.8781 - loss: 0.3198 - precision: 0.8582 - recall: 0.8550 - val_auc: 0.9274 - val_binary_accuracy: 0.8488 - val_loss: 0.3694 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 104/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8789 - loss: 0.3200 - precision: 0.8600 - recall: 0.8553 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3694 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 105/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9452 - binary_accuracy: 0.8781 - loss: 0.3194 - precision: 0.8587 - recall: 0.8556 - val_auc: 0.9274 - val_binary_accuracy: 0.8512 - val_loss: 0.3691 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 106/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8781 - loss: 0.3199 - precision: 0.8590 - recall: 0.8558 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3690 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 107/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8797 - loss: 0.3184 - precision: 0.8619 - recall: 0.8556 - val_auc: 0.9275 - val_binary_accuracy: 0.8488 - val_loss: 0.3690 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 108/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8797 - loss: 0.3187 - precision: 0.8603 - recall: 0.8571 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3688 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 109/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8797 - loss: 0.3187 - precision: 0.8624 - recall: 0.8561 - val_auc: 0.9275 - val_binary_accuracy: 0.8488 - val_loss: 0.3687 - val_precision: 0.8207 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 110/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8797 - loss: 0.3179 - precision: 0.8608 - recall: 0.8577 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3687 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 111/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8828 - loss: 0.3143 - precision: 0.8624 - recall: 0.8624 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3684 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 112/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9452 - binary_accuracy: 0.8789 - loss: 0.3191 - precision: 0.8603 - recall: 0.8556 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3683 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 113/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8813 - loss: 0.3162 - precision: 0.8621 - recall: 0.8590 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3681 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 114/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9459 - binary_accuracy: 0.8805 - loss: 0.3171 - precision: 0.8621 - recall: 0.8574 - val_auc: 0.9277 - val_binary_accuracy: 0.8512 - val_loss: 0.3681 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 115/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8797 - loss: 0.3187 - precision: 0.8621 - recall: 0.8558 - val_auc: 0.9277 - val_binary_accuracy: 0.8512 - val_loss: 0.3680 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 116/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8813 - loss: 0.3184 - precision: 0.8626 - recall: 0.8595 - val_auc: 0.9277 - val_binary_accuracy: 0.8512 - val_loss: 0.3679 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 117/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8820 - loss: 0.3170 - precision: 0.8629 - recall: 0.8613 - val_auc: 0.9278 - val_binary_accuracy: 0.8512 - val_loss: 0.3676 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 118/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8820 - loss: 0.3172 - precision: 0.8626 - recall: 0.8611 - val_auc: 0.9277 - val_binary_accuracy: 0.8535 - val_loss: 0.3676 - val_precision: 0.8297 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 119/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9462 - binary_accuracy: 0.8820 - loss: 0.3163 - precision: 0.8624 - recall: 0.8608 - val_auc: 0.9277 - val_binary_accuracy: 0.8512 - val_loss: 0.3674 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 120/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8813 - loss: 0.3173 - precision: 0.8626 - recall: 0.8595 - val_auc: 0.9277 - val_binary_accuracy: 0.8512 - val_loss: 0.3673 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 121/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9470 - binary_accuracy: 0.8820 - loss: 0.3144 - precision: 0.8637 - recall: 0.8590 - val_auc: 0.9278 - val_binary_accuracy: 0.8512 - val_loss: 0.3673 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 122/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8828 - loss: 0.3154 - precision: 0.8658 - recall: 0.8595 - val_auc: 0.9279 - val_binary_accuracy: 0.8512 - val_loss: 0.3671 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 123/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8820 - loss: 0.3163 - precision: 0.8637 - recall: 0.8590 - val_auc: 0.9279 - val_binary_accuracy: 0.8512 - val_loss: 0.3671 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 124/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8828 - loss: 0.3156 - precision: 0.8645 - recall: 0.8613 - val_auc: 0.9279 - val_binary_accuracy: 0.8512 - val_loss: 0.3671 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 125/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8820 - loss: 0.3167 - precision: 0.8632 - recall: 0.8585 - val_auc: 0.9281 - val_binary_accuracy: 0.8512 - val_loss: 0.3667 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 126/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8836 - loss: 0.3169 - precision: 0.8640 - recall: 0.8624 - val_auc: 0.9281 - val_binary_accuracy: 0.8512 - val_loss: 0.3666 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 127/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8828 - loss: 0.3152 - precision: 0.8630 - recall: 0.8598 - val_auc: 0.9279 - val_binary_accuracy: 0.8512 - val_loss: 0.3667 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 128/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9469 - binary_accuracy: 0.8844 - loss: 0.3138 - precision: 0.8674 - recall: 0.8611 - val_auc: 0.9281 - val_binary_accuracy: 0.8512 - val_loss: 0.3666 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 129/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8836 - loss: 0.3169 - precision: 0.8642 - recall: 0.8626 - val_auc: 0.9281 - val_binary_accuracy: 0.8512 - val_loss: 0.3664 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 130/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8828 - loss: 0.3161 - precision: 0.8629 - recall: 0.8629 - val_auc: 0.9281 - val_binary_accuracy: 0.8512 - val_loss: 0.3661 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 131/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9469 - binary_accuracy: 0.8844 - loss: 0.3134 - precision: 0.8661 - recall: 0.8629 - val_auc: 0.9282 - val_binary_accuracy: 0.8512 - val_loss: 0.3660 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 132/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9467 - binary_accuracy: 0.8852 - loss: 0.3140 - precision: 0.8645 - recall: 0.8661 - val_auc: 0.9283 - val_binary_accuracy: 0.8535 - val_loss: 0.3659 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 133/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9465 - binary_accuracy: 0.8836 - loss: 0.3142 - precision: 0.8653 - recall: 0.8606 - val_auc: 0.9283 - val_binary_accuracy: 0.8535 - val_loss: 0.3659 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 134/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9467 - binary_accuracy: 0.8828 - loss: 0.3142 - precision: 0.8640 - recall: 0.8608 - val_auc: 0.9283 - val_binary_accuracy: 0.8535 - val_loss: 0.3657 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 135/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8820 - loss: 0.3160 - precision: 0.8621 - recall: 0.8606 - val_auc: 0.9283 - val_binary_accuracy: 0.8535 - val_loss: 0.3655 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 136/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8820 - loss: 0.3154 - precision: 0.8629 - recall: 0.8613 - val_auc: 0.9284 - val_binary_accuracy: 0.8535 - val_loss: 0.3654 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 137/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9466 - binary_accuracy: 0.8820 - loss: 0.3143 - precision: 0.8626 - recall: 0.8611 - val_auc: 0.9285 - val_binary_accuracy: 0.8535 - val_loss: 0.3652 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 138/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8820 - loss: 0.3155 - precision: 0.8626 - recall: 0.8611 - val_auc: 0.9285 - val_binary_accuracy: 0.8535 - val_loss: 0.3650 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 139/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9475 - binary_accuracy: 0.8820 - loss: 0.3124 - precision: 0.8629 - recall: 0.8613 - val_auc: 0.9285 - val_binary_accuracy: 0.8535 - val_loss: 0.3648 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 140/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9469 - binary_accuracy: 0.8844 - loss: 0.3131 - precision: 0.8665 - recall: 0.8634 - val_auc: 0.9286 - val_binary_accuracy: 0.8535 - val_loss: 0.3647 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 141/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8828 - loss: 0.3152 - precision: 0.8629 - recall: 0.8629 - val_auc: 0.9286 - val_binary_accuracy: 0.8535 - val_loss: 0.3647 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 142/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9468 - binary_accuracy: 0.8836 - loss: 0.3134 - precision: 0.8645 - recall: 0.8629 - val_auc: 0.9285 - val_binary_accuracy: 0.8535 - val_loss: 0.3644 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 143/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8844 - loss: 0.3128 - precision: 0.8663 - recall: 0.8631 - val_auc: 0.9286 - val_binary_accuracy: 0.8512 - val_loss: 0.3643 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 144/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9468 - binary_accuracy: 0.8828 - loss: 0.3135 - precision: 0.8645 - recall: 0.8613 - val_auc: 0.9286 - val_binary_accuracy: 0.8512 - val_loss: 0.3642 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 145/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9469 - binary_accuracy: 0.8836 - loss: 0.3132 - precision: 0.8647 - recall: 0.8631 - val_auc: 0.9287 - val_binary_accuracy: 0.8512 - val_loss: 0.3641 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 146/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8852 - loss: 0.3130 - precision: 0.8663 - recall: 0.8647 - val_auc: 0.9286 - val_binary_accuracy: 0.8512 - val_loss: 0.3639 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 147/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9467 - binary_accuracy: 0.8836 - loss: 0.3136 - precision: 0.8645 - recall: 0.8629 - val_auc: 0.9288 - val_binary_accuracy: 0.8512 - val_loss: 0.3638 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 148/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9476 - binary_accuracy: 0.8852 - loss: 0.3111 - precision: 0.8663 - recall: 0.8647 - val_auc: 0.9288 - val_binary_accuracy: 0.8512 - val_loss: 0.3638 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 149/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9465 - binary_accuracy: 0.8836 - loss: 0.3137 - precision: 0.8645 - recall: 0.8629 - val_auc: 0.9288 - val_binary_accuracy: 0.8512 - val_loss: 0.3635 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 150/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9473 - binary_accuracy: 0.8844 - loss: 0.3120 - precision: 0.8676 - recall: 0.8613 - val_auc: 0.9290 - val_binary_accuracy: 0.8512 - val_loss: 0.3636 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 151/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9468 - binary_accuracy: 0.8844 - loss: 0.3131 - precision: 0.8674 - recall: 0.8611 - val_auc: 0.9289 - val_binary_accuracy: 0.8512 - val_loss: 0.3634 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 152/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9475 - binary_accuracy: 0.8852 - loss: 0.3113 - precision: 0.8692 - recall: 0.8613 - val_auc: 0.9290 - val_binary_accuracy: 0.8512 - val_loss: 0.3632 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 153/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8836 - loss: 0.3123 - precision: 0.8663 - recall: 0.8616 - val_auc: 0.9290 - val_binary_accuracy: 0.8512 - val_loss: 0.3631 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 154/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9478 - binary_accuracy: 0.8859 - loss: 0.3103 - precision: 0.8674 - recall: 0.8642 - val_auc: 0.9290 - val_binary_accuracy: 0.8512 - val_loss: 0.3630 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 155/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9479 - binary_accuracy: 0.8852 - loss: 0.3102 - precision: 0.8676 - recall: 0.8629 - val_auc: 0.9291 - val_binary_accuracy: 0.8512 - val_loss: 0.3630 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 156/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9466 - binary_accuracy: 0.8836 - loss: 0.3133 - precision: 0.8656 - recall: 0.8608 - val_auc: 0.9291 - val_binary_accuracy: 0.8512 - val_loss: 0.3630 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 157/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8836 - loss: 0.3125 - precision: 0.8658 - recall: 0.8611 - val_auc: 0.9290 - val_binary_accuracy: 0.8512 - val_loss: 0.3628 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 158/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9472 - binary_accuracy: 0.8844 - loss: 0.3120 - precision: 0.8679 - recall: 0.8616 - val_auc: 0.9291 - val_binary_accuracy: 0.8512 - val_loss: 0.3628 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 159/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8836 - loss: 0.3127 - precision: 0.8676 - recall: 0.8597 - val_auc: 0.9291 - val_binary_accuracy: 0.8512 - val_loss: 0.3627 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 160/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9472 - binary_accuracy: 0.8844 - loss: 0.3117 - precision: 0.8674 - recall: 0.8611 - val_auc: 0.9292 - val_binary_accuracy: 0.8512 - val_loss: 0.3625 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 161/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8828 - loss: 0.3122 - precision: 0.8637 - recall: 0.8606 - val_auc: 0.9292 - val_binary_accuracy: 0.8512 - val_loss: 0.3625 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 162/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9474 - binary_accuracy: 0.8844 - loss: 0.3112 - precision: 0.8658 - recall: 0.8626 - val_auc: 0.9292 - val_binary_accuracy: 0.8512 - val_loss: 0.3623 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 163/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9478 - binary_accuracy: 0.8844 - loss: 0.3102 - precision: 0.8642 - recall: 0.8642 - val_auc: 0.9292 - val_binary_accuracy: 0.8512 - val_loss: 0.3623 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 164/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9484 - binary_accuracy: 0.8852 - loss: 0.3087 - precision: 0.8672 - recall: 0.8624 - val_auc: 0.9293 - val_binary_accuracy: 0.8512 - val_loss: 0.3624 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 165/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9474 - binary_accuracy: 0.8836 - loss: 0.3113 - precision: 0.8685 - recall: 0.8574 - val_auc: 0.9293 - val_binary_accuracy: 0.8512 - val_loss: 0.3621 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 166/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8828 - loss: 0.3119 - precision: 0.8667 - recall: 0.8571 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3620 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 167/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9474 - binary_accuracy: 0.8836 - loss: 0.3109 - precision: 0.8678 - recall: 0.8566 - val_auc: 0.9294 - val_binary_accuracy: 0.8512 - val_loss: 0.3619 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 168/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9475 - binary_accuracy: 0.8836 - loss: 0.3111 - precision: 0.8672 - recall: 0.8592 - val_auc: 0.9293 - val_binary_accuracy: 0.8535 - val_loss: 0.3619 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 169/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8820 - loss: 0.3119 - precision: 0.8651 - recall: 0.8571 - val_auc: 0.9293 - val_binary_accuracy: 0.8535 - val_loss: 0.3617 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 170/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9473 - binary_accuracy: 0.8820 - loss: 0.3113 - precision: 0.8662 - recall: 0.8550 - val_auc: 0.9294 - val_binary_accuracy: 0.8535 - val_loss: 0.3616 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 171/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9480 - binary_accuracy: 0.8844 - loss: 0.3090 - precision: 0.8688 - recall: 0.8592 - val_auc: 0.9294 - val_binary_accuracy: 0.8512 - val_loss: 0.3616 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 172/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9479 - binary_accuracy: 0.8836 - loss: 0.3095 - precision: 0.8683 - recall: 0.8571 - val_auc: 0.9293 - val_binary_accuracy: 0.8512 - val_loss: 0.3616 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 173/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8813 - loss: 0.3116 - precision: 0.8648 - recall: 0.8553 - val_auc: 0.9293 - val_binary_accuracy: 0.8512 - val_loss: 0.3615 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 174/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9473 - binary_accuracy: 0.8820 - loss: 0.3112 - precision: 0.8648 - recall: 0.8569 - val_auc: 0.9294 - val_binary_accuracy: 0.8512 - val_loss: 0.3614 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 175/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9483 - binary_accuracy: 0.8836 - loss: 0.3085 - precision: 0.8667 - recall: 0.8587 - val_auc: 0.9294 - val_binary_accuracy: 0.8512 - val_loss: 0.3614 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 176/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8813 - loss: 0.3103 - precision: 0.8664 - recall: 0.8537 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3613 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 177/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8813 - loss: 0.3082 - precision: 0.8635 - recall: 0.8571 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3611 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 178/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8813 - loss: 0.3099 - precision: 0.8632 - recall: 0.8569 - val_auc: 0.9294 - val_binary_accuracy: 0.8512 - val_loss: 0.3610 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 179/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9493 - binary_accuracy: 0.8820 - loss: 0.3057 - precision: 0.8667 - recall: 0.8556 - val_auc: 0.9294 - val_binary_accuracy: 0.8488 - val_loss: 0.3610 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 180/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9476 - binary_accuracy: 0.8805 - loss: 0.3101 - precision: 0.8648 - recall: 0.8537 - val_auc: 0.9295 - val_binary_accuracy: 0.8488 - val_loss: 0.3610 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 181/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9486 - binary_accuracy: 0.8836 - loss: 0.3072 - precision: 0.8648 - recall: 0.8600 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3610 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 182/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9482 - binary_accuracy: 0.8820 - loss: 0.3082 - precision: 0.8646 - recall: 0.8566 - val_auc: 0.9294 - val_binary_accuracy: 0.8488 - val_loss: 0.3609 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 183/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8813 - loss: 0.3096 - precision: 0.8653 - recall: 0.8558 - val_auc: 0.9294 - val_binary_accuracy: 0.8488 - val_loss: 0.3608 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 184/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8813 - loss: 0.3096 - precision: 0.8632 - recall: 0.8569 - val_auc: 0.9293 - val_binary_accuracy: 0.8512 - val_loss: 0.3607 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 185/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9474 - binary_accuracy: 0.8805 - loss: 0.3105 - precision: 0.8646 - recall: 0.8535 - val_auc: 0.9294 - val_binary_accuracy: 0.8488 - val_loss: 0.3606 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 186/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8820 - loss: 0.3097 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9295 - val_binary_accuracy: 0.8488 - val_loss: 0.3605 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 187/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8813 - loss: 0.3075 - precision: 0.8646 - recall: 0.8550 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3604 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 188/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9487 - binary_accuracy: 0.8820 - loss: 0.3067 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3602 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 189/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8805 - loss: 0.3096 - precision: 0.8637 - recall: 0.8558 - val_auc: 0.9296 - val_binary_accuracy: 0.8488 - val_loss: 0.3603 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 190/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9478 - binary_accuracy: 0.8805 - loss: 0.3094 - precision: 0.8635 - recall: 0.8556 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3601 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 191/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9479 - binary_accuracy: 0.8813 - loss: 0.3090 - precision: 0.8640 - recall: 0.8577 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3602 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 192/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9480 - binary_accuracy: 0.8820 - loss: 0.3086 - precision: 0.8653 - recall: 0.8574 - val_auc: 0.9296 - val_binary_accuracy: 0.8488 - val_loss: 0.3602 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 193/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9476 - binary_accuracy: 0.8797 - loss: 0.3097 - precision: 0.8632 - recall: 0.8537 - val_auc: 0.9294 - val_binary_accuracy: 0.8488 - val_loss: 0.3600 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 194/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8828 - loss: 0.3049 - precision: 0.8669 - recall: 0.8574 - val_auc: 0.9294 - val_binary_accuracy: 0.8535 - val_loss: 0.3600 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 195/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8828 - loss: 0.3071 - precision: 0.8648 - recall: 0.8585 - val_auc: 0.9295 - val_binary_accuracy: 0.8535 - val_loss: 0.3599 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 196/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8820 - loss: 0.3058 - precision: 0.8683 - recall: 0.8540 - val_auc: 0.9296 - val_binary_accuracy: 0.8512 - val_loss: 0.3601 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 197/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8797 - loss: 0.3055 - precision: 0.8643 - recall: 0.8516 - val_auc: 0.9296 - val_binary_accuracy: 0.8512 - val_loss: 0.3599 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 198/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9479 - binary_accuracy: 0.8797 - loss: 0.3089 - precision: 0.8648 - recall: 0.8522 - val_auc: 0.9297 - val_binary_accuracy: 0.8535 - val_loss: 0.3598 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 199/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8805 - loss: 0.3078 - precision: 0.8651 - recall: 0.8540 - val_auc: 0.9296 - val_binary_accuracy: 0.8535 - val_loss: 0.3597 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 200/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9481 - binary_accuracy: 0.8797 - loss: 0.3081 - precision: 0.8659 - recall: 0.8501 - val_auc: 0.9298 - val_binary_accuracy: 0.8512 - val_loss: 0.3597 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 201/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8820 - loss: 0.3074 - precision: 0.8658 - recall: 0.8579 - val_auc: 0.9297 - val_binary_accuracy: 0.8535 - val_loss: 0.3596 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 202/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9479 - binary_accuracy: 0.8789 - loss: 0.3089 - precision: 0.8643 - recall: 0.8501 - val_auc: 0.9298 - val_binary_accuracy: 0.8535 - val_loss: 0.3595 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 203/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8828 - loss: 0.3058 - precision: 0.8674 - recall: 0.8579 - val_auc: 0.9297 - val_binary_accuracy: 0.8535 - val_loss: 0.3594 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 204/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9480 - binary_accuracy: 0.8797 - loss: 0.3079 - precision: 0.8641 - recall: 0.8514 - val_auc: 0.9297 - val_binary_accuracy: 0.8535 - val_loss: 0.3595 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 205/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9484 - binary_accuracy: 0.8813 - loss: 0.3073 - precision: 0.8646 - recall: 0.8550 - val_auc: 0.9298 - val_binary_accuracy: 0.8535 - val_loss: 0.3594 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 206/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9480 - binary_accuracy: 0.8797 - loss: 0.3081 - precision: 0.8643 - recall: 0.8516 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3593 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 207/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9481 - binary_accuracy: 0.8797 - loss: 0.3082 - precision: 0.8635 - recall: 0.8540 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3592 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 208/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8797 - loss: 0.3055 - precision: 0.8622 - recall: 0.8527 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3593 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 209/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9484 - binary_accuracy: 0.8813 - loss: 0.3071 - precision: 0.8667 - recall: 0.8540 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3592 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 210/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8797 - loss: 0.3076 - precision: 0.8659 - recall: 0.8501 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3592 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 211/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9478 - binary_accuracy: 0.8797 - loss: 0.3084 - precision: 0.8643 - recall: 0.8516 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3591 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 212/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9482 - binary_accuracy: 0.8813 - loss: 0.3074 - precision: 0.8675 - recall: 0.8516 - val_auc: 0.9298 - val_binary_accuracy: 0.8535 - val_loss: 0.3593 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 213/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9482 - binary_accuracy: 0.8805 - loss: 0.3074 - precision: 0.8643 - recall: 0.8532 - val_auc: 0.9300 - val_binary_accuracy: 0.8558 - val_loss: 0.3590 - val_precision: 0.8380 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 214/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9480 - binary_accuracy: 0.8805 - loss: 0.3079 - precision: 0.8668 - recall: 0.8493 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3591 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 215/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9488 - binary_accuracy: 0.8813 - loss: 0.3058 - precision: 0.8670 - recall: 0.8511 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3591 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 216/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8805 - loss: 0.3070 - precision: 0.8659 - recall: 0.8516 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3590 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 217/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8813 - loss: 0.3066 - precision: 0.8708 - recall: 0.8485 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3591 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 218/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9481 - binary_accuracy: 0.8781 - loss: 0.3075 - precision: 0.8641 - recall: 0.8483 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3590 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 219/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8805 - loss: 0.3064 - precision: 0.8665 - recall: 0.8490 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3589 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 220/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9479 - binary_accuracy: 0.8781 - loss: 0.3082 - precision: 0.8643 - recall: 0.8485 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3589 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 221/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9482 - binary_accuracy: 0.8797 - loss: 0.3071 - precision: 0.8654 - recall: 0.8495 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3588 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 222/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9482 - binary_accuracy: 0.8797 - loss: 0.3071 - precision: 0.8670 - recall: 0.8480 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3589 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 223/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9483 - binary_accuracy: 0.8781 - loss: 0.3071 - precision: 0.8641 - recall: 0.8483 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3588 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 224/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8789 - loss: 0.3069 - precision: 0.8638 - recall: 0.8495 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3588 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 225/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9486 - binary_accuracy: 0.8797 - loss: 0.3057 - precision: 0.8668 - recall: 0.8477 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3588 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 226/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8797 - loss: 0.3051 - precision: 0.8646 - recall: 0.8519 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3587 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 227/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9481 - binary_accuracy: 0.8797 - loss: 0.3072 - precision: 0.8665 - recall: 0.8474 - val_auc: 0.9298 - val_binary_accuracy: 0.8535 - val_loss: 0.3587 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 228/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8805 - loss: 0.3061 - precision: 0.8632 - recall: 0.8553 - val_auc: 0.9300 - val_binary_accuracy: 0.8558 - val_loss: 0.3586 - val_precision: 0.8380 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 229/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9482 - binary_accuracy: 0.8797 - loss: 0.3070 - precision: 0.8670 - recall: 0.8480 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3586 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 230/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9491 - binary_accuracy: 0.8805 - loss: 0.3048 - precision: 0.8637 - recall: 0.8558 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3586 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 231/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9490 - binary_accuracy: 0.8813 - loss: 0.3047 - precision: 0.8643 - recall: 0.8548 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3587 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 232/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9484 - binary_accuracy: 0.8797 - loss: 0.3065 - precision: 0.8657 - recall: 0.8498 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3586 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 233/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8813 - loss: 0.3047 - precision: 0.8662 - recall: 0.8535 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3586 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 234/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9483 - binary_accuracy: 0.8789 - loss: 0.3066 - precision: 0.8657 - recall: 0.8483 - val_auc: 0.9299 - val_binary_accuracy: 0.8535 - val_loss: 0.3586 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 235/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9486 - binary_accuracy: 0.8789 - loss: 0.3057 - precision: 0.8657 - recall: 0.8483 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3585 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 236/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9487 - binary_accuracy: 0.8813 - loss: 0.3055 - precision: 0.8662 - recall: 0.8535 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3585 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 237/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8797 - loss: 0.3062 - precision: 0.8643 - recall: 0.8516 - val_auc: 0.9301 - val_binary_accuracy: 0.8558 - val_loss: 0.3583 - val_precision: 0.8380 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 238/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8813 - loss: 0.3061 - precision: 0.8664 - recall: 0.8537 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3584 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 239/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9481 - binary_accuracy: 0.8805 - loss: 0.3068 - precision: 0.8632 - recall: 0.8553 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3584 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 240/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9483 - binary_accuracy: 0.8797 - loss: 0.3062 - precision: 0.8630 - recall: 0.8535 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3584 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 241/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8820 - loss: 0.3045 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9302 - val_binary_accuracy: 0.8535 - val_loss: 0.3584 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 242/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9494 - binary_accuracy: 0.8820 - loss: 0.3032 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3585 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 243/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8813 - loss: 0.3037 - precision: 0.8689 - recall: 0.8498 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3583 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 244/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9483 - binary_accuracy: 0.8813 - loss: 0.3065 - precision: 0.8678 - recall: 0.8519 - val_auc: 0.9300 - val_binary_accuracy: 0.8535 - val_loss: 0.3583 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 245/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9484 - binary_accuracy: 0.8805 - loss: 0.3062 - precision: 0.8659 - recall: 0.8516 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3583 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 246/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9507 - binary_accuracy: 0.8836 - loss: 0.2999 - precision: 0.8696 - recall: 0.8553 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3584 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 247/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8828 - loss: 0.3031 - precision: 0.8696 - recall: 0.8537 - val_auc: 0.9302 - val_binary_accuracy: 0.8535 - val_loss: 0.3583 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 248/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9485 - binary_accuracy: 0.8805 - loss: 0.3060 - precision: 0.8664 - recall: 0.8522 - val_auc: 0.9302 - val_binary_accuracy: 0.8558 - val_loss: 0.3582 - val_precision: 0.8380 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 249/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9483 - binary_accuracy: 0.8820 - loss: 0.3062 - precision: 0.8675 - recall: 0.8532 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3583 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 250/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9487 - binary_accuracy: 0.8797 - loss: 0.3056 - precision: 0.8643 - recall: 0.8516 - val_auc: 0.9302 - val_binary_accuracy: 0.8558 - val_loss: 0.3581 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 251/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9487 - binary_accuracy: 0.8813 - loss: 0.3050 - precision: 0.8662 - recall: 0.8535 - val_auc: 0.9301 - val_binary_accuracy: 0.8535 - val_loss: 0.3581 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 252/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9488 - binary_accuracy: 0.8828 - loss: 0.3051 - precision: 0.8694 - recall: 0.8535 - val_auc: 0.9301 - val_binary_accuracy: 0.8558 - val_loss: 0.3582 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 253/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9484 - binary_accuracy: 0.8813 - loss: 0.3058 - precision: 0.8678 - recall: 0.8519 - val_auc: 0.9302 - val_binary_accuracy: 0.8558 - val_loss: 0.3581 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 254/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8828 - loss: 0.3039 - precision: 0.8696 - recall: 0.8537 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3579 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 255/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9488 - binary_accuracy: 0.8844 - loss: 0.3045 - precision: 0.8710 - recall: 0.8550 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3579 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 256/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9486 - binary_accuracy: 0.8820 - loss: 0.3057 - precision: 0.8694 - recall: 0.8519 - val_auc: 0.9302 - val_binary_accuracy: 0.8558 - val_loss: 0.3579 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 257/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8820 - loss: 0.3037 - precision: 0.8692 - recall: 0.8516 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3578 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 258/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9497 - binary_accuracy: 0.8844 - loss: 0.3026 - precision: 0.8717 - recall: 0.8558 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3578 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 259/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9492 - binary_accuracy: 0.8836 - loss: 0.3039 - precision: 0.8699 - recall: 0.8556 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3577 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 260/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9492 - binary_accuracy: 0.8828 - loss: 0.3043 - precision: 0.8685 - recall: 0.8558 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3578 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 261/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9486 - binary_accuracy: 0.8836 - loss: 0.3054 - precision: 0.8696 - recall: 0.8553 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3577 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 262/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8836 - loss: 0.3045 - precision: 0.8696 - recall: 0.8553 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3577 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 263/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9487 - binary_accuracy: 0.8820 - loss: 0.3053 - precision: 0.8675 - recall: 0.8532 - val_auc: 0.9303 - val_binary_accuracy: 0.8558 - val_loss: 0.3577 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 264/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9489 - binary_accuracy: 0.8813 - loss: 0.3047 - precision: 0.8662 - recall: 0.8535 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3577 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 265/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8828 - loss: 0.3044 - precision: 0.8701 - recall: 0.8543 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3576 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 266/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9488 - binary_accuracy: 0.8820 - loss: 0.3049 - precision: 0.8678 - recall: 0.8535 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3576 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 267/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8828 - loss: 0.3042 - precision: 0.8694 - recall: 0.8535 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3575 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 268/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8820 - loss: 0.3042 - precision: 0.8670 - recall: 0.8527 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3575 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 269/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9490 - binary_accuracy: 0.8828 - loss: 0.3044 - precision: 0.8683 - recall: 0.8556 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3575 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 270/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9490 - binary_accuracy: 0.8820 - loss: 0.3048 - precision: 0.8669 - recall: 0.8558 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3574 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 271/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9492 - binary_accuracy: 0.8813 - loss: 0.3040 - precision: 0.8667 - recall: 0.8540 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3574 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 272/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9498 - binary_accuracy: 0.8828 - loss: 0.3023 - precision: 0.8683 - recall: 0.8556 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3574 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 273/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8828 - loss: 0.3041 - precision: 0.8699 - recall: 0.8540 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3573 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 274/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8813 - loss: 0.3041 - precision: 0.8667 - recall: 0.8540 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3572 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 275/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8820 - loss: 0.3032 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3571 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 276/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9494 - binary_accuracy: 0.8820 - loss: 0.3034 - precision: 0.8685 - recall: 0.8543 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3573 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 277/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9497 - binary_accuracy: 0.8820 - loss: 0.3025 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9306 - val_binary_accuracy: 0.8581 - val_loss: 0.3572 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 278/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9489 - binary_accuracy: 0.8820 - loss: 0.3045 - precision: 0.8662 - recall: 0.8550 - val_auc: 0.9306 - val_binary_accuracy: 0.8581 - val_loss: 0.3571 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 279/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9499 - binary_accuracy: 0.8828 - loss: 0.3020 - precision: 0.8683 - recall: 0.8556 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3571 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 280/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8820 - loss: 0.3032 - precision: 0.8667 - recall: 0.8556 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3570 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 281/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9494 - binary_accuracy: 0.8820 - loss: 0.3032 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9303 - val_binary_accuracy: 0.8558 - val_loss: 0.3572 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 282/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9502 - binary_accuracy: 0.8836 - loss: 0.3010 - precision: 0.8699 - recall: 0.8556 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3570 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 283/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8820 - loss: 0.3032 - precision: 0.8662 - recall: 0.8550 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3570 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 284/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9500 - binary_accuracy: 0.8828 - loss: 0.3015 - precision: 0.8669 - recall: 0.8574 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3570 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 285/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9495 - binary_accuracy: 0.8820 - loss: 0.3025 - precision: 0.8678 - recall: 0.8535 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3570 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 286/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9492 - binary_accuracy: 0.8813 - loss: 0.3035 - precision: 0.8664 - recall: 0.8537 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3569 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 287/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9492 - binary_accuracy: 0.8820 - loss: 0.3038 - precision: 0.8672 - recall: 0.8561 - val_auc: 0.9306 - val_binary_accuracy: 0.8581 - val_loss: 0.3568 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 288/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9504 - binary_accuracy: 0.8844 - loss: 0.2999 - precision: 0.8685 - recall: 0.8590 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3567 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 289/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9492 - binary_accuracy: 0.8820 - loss: 0.3033 - precision: 0.8680 - recall: 0.8537 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3567 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 290/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9499 - binary_accuracy: 0.8828 - loss: 0.3015 - precision: 0.8664 - recall: 0.8569 - val_auc: 0.9306 - val_binary_accuracy: 0.8581 - val_loss: 0.3567 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 291/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9505 - binary_accuracy: 0.8836 - loss: 0.2994 - precision: 0.8713 - recall: 0.8537 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3567 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 292/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9497 - binary_accuracy: 0.8813 - loss: 0.3020 - precision: 0.8659 - recall: 0.8532 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3566 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 293/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9491 - binary_accuracy: 0.8820 - loss: 0.3035 - precision: 0.8667 - recall: 0.8556 - val_auc: 0.9306 - val_binary_accuracy: 0.8581 - val_loss: 0.3565 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 294/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9492 - binary_accuracy: 0.8828 - loss: 0.3030 - precision: 0.8683 - recall: 0.8556 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3566 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 295/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9506 - binary_accuracy: 0.8828 - loss: 0.2995 - precision: 0.8667 - recall: 0.8571 - val_auc: 0.9303 - val_binary_accuracy: 0.8581 - val_loss: 0.3565 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 296/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9500 - binary_accuracy: 0.8813 - loss: 0.3014 - precision: 0.8669 - recall: 0.8543 - val_auc: 0.9305 - val_binary_accuracy: 0.8581 - val_loss: 0.3565 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 297/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9492 - binary_accuracy: 0.8805 - loss: 0.3035 - precision: 0.8648 - recall: 0.8537 - val_auc: 0.9304 - val_binary_accuracy: 0.8581 - val_loss: 0.3564 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 298/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9496 - binary_accuracy: 0.8813 - loss: 0.3029 - precision: 0.8653 - recall: 0.8558 - val_auc: 0.9307 - val_binary_accuracy: 0.8581 - val_loss: 0.3564 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 299/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9493 - binary_accuracy: 0.8789 - loss: 0.3029 - precision: 0.8611 - recall: 0.8532 - val_auc: 0.9305 - val_binary_accuracy: 0.8605 - val_loss: 0.3563 - val_precision: 0.8436 - val_recall: 0.8251 - learning_rate: 9.0903e-05\n",
      "\n",
      "Epoch 300/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9492 - binary_accuracy: 0.8805 - loss: 0.3034 - precision: 0.8651 - recall: 0.8540 - val_auc: 0.9306 - val_binary_accuracy: 0.8581 - val_loss: 0.3564 - val_precision: 0.8427 - val_recall: 0.8197 - learning_rate: 9.0903e-05\n",
      "\n",
      "./plots/learned-auk-714/learning_rate_vs_epoch.png                                \n",
      "./plots/learned-auk-714/auc_vs_epoch.png                                          \n",
      "./plots/learned-auk-714/loss_vs_epoch.png                                         \n",
      "./plots/learned-auk-714/binary_accuracy_vs_epoch.png                              \n",
      "./plots/learned-auk-714/recall_vs_epoch.png                                       \n",
      "./plots/learned-auk-714/precision_vs_epoch.png                                    \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 404ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step         \n",
      "\n",
      " 93%|█████████▎| 14/15 [08:41<01:42, 102.26s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step         \n",
      "\n",
      " 93%|█████████▎| 14/15 [08:42<01:42, 102.26s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f73aec08d4543eebcdc8e6bc9d849ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m225/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m225/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run learned-auk-714 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/06637237171541dabacf1f348f614575\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "100%|██████████| 15/15 [09:29<00:00, 113.90s/trial, best loss: 0.2997603714466095]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from hyperopt import Trials, fmin, tpe\n",
    "if os.path.exists(TRIALS_FILE_LOCATION):\n",
    "    trials = pickle.load(open(TRIALS_FILE_LOCATION,'rb'))\n",
    "else:\n",
    "    trials = Trials()\n",
    "\n",
    "\n",
    "evals_done = len(trials.trials)\n",
    "max_evals = evals_done + TRIALS_PER_RUN\n",
    "best = fmin(pistachio_objective,\n",
    "    space=hp_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials)\n",
    "\n",
    "with open(TRIALS_FILE_LOCATION,'wb') as outfile:\n",
    "    pickle.dump(trials,outfile)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6381b4eb-f602-4192-95b0-70e34140def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "trials = pickle.load(open(TRIALS_FILE_LOCATION,'rb'))\n",
    "print(len(trials.trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca134d-81a2-4925-a913-1e58b51ec189",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57cbcf8d-65a8-4865-9e1e-a06a7f773e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "def shap_wrapper(X):\n",
    "    feature_dict = {k:X[:,i] for i,k in enumerate(feature_columns)}\n",
    "    return model.predict(feature_dict).flatten()\n",
    "\n",
    "# shap_n_samples = 50\n",
    "# shap_explainer_samples = 50\n",
    "\n",
    "# data_shap = train_df.loc[:,feature_columns]\n",
    "# explainer = shap.KernelExplainer(shap_wrapper, data_shap.iloc[:shap_explainer_samples,:])\n",
    "# shap_values = explainer.shap_values(data_shap.iloc[shap_explainer_samples:shap_explainer_samples+shap_n_samples, :], nsamples=200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "162d3525-16e1-4b47-b261-1f78ed9f2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81858e7-edfd-4c76-a001-0fac60046b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.scatter(explainer)\n",
    "# shap.plots.bar(shap_values[0])\n",
    "# shap_violin_path = os.path.join(plot_dir,'shap_violin.png')\n",
    "# shap_bar_path = os.path.join(plot_dir,'shap_bar.png')\n",
    "\n",
    "# shap.summary_plot(\n",
    "#     shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"violin\", max_display=30, show=False)\n",
    "# plt.savefig(shap_violin_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8022bc9-7de6-427a-ae34-f1277c45d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(\n",
    "#     shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"bar\", max_display=30, show=False)\n",
    "# plt.savefig(shap_bar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "527e5c7e-ad4c-44dc-9f74-e27635afcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run(run_id=run_id) as mlflow_run:\n",
    "# #     for mm in metrics_to_plot:\n",
    "# #         # fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "    \n",
    "\n",
    "#     mlflow.log_artifact(validation_metrics_path)\n",
    "#     mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "#     mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # mlflow.log_metrics(best_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad6598-ee20-4e4a-bd25-78936e8d5d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
