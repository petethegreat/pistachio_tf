{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67e146c-7741-4e5d-b3e5-152d1fcce01c",
   "metadata": {},
   "source": [
    "# tensorflow pistachio\n",
    "Tuning with hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d7921-a931-4947-85fa-036f43cf4653",
   "metadata": {},
   "source": [
    "## Links\n",
    "  - [notes on training/validation loss](https://siddiqueabusaleh.medium.com/why-my-training-loss-is-higher-than-validation-loss-is-the-reported-loss-even-accurate-8843e14a0756)\n",
    "  - [initialisation values](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines)\n",
    "  - [shap feature importance](https://shap.readthedocs.io/en/latest/tabular_examples.html#neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9645c12f-836e-43ef-a516-dd6134687a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:35:50.743458: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c077c-56e8-4081-b5dc-34945bd1fa61",
   "metadata": {},
   "source": [
    "## arff to csv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98bbd97-83f9-40e2-a125-e20d695ac0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19e49d4-8185-4a92-b60f-7e94609fccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/pistachio_16.csv exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from scipy.io import arff\n",
    "import os \n",
    "\n",
    "from pistachio.data import load_arff_file\n",
    "\n",
    "label_mapping = {'Kirmizi_Pistachio': 0, 'Siit_Pistachio': 1}\n",
    "\n",
    "\n",
    "arff_filename = './data/Pistachio_16_Features_Dataset.arff'\n",
    "csv_filename = './data/pistachio_16.csv'\n",
    "\n",
    "if not os.path.exists(csv_filename):\n",
    "    df = load_arff_file(arff_filename, label_mapping)\n",
    "    df.head()\n",
    "    df.to_csv(csv_filename, index=False, header=True)\n",
    "    print(f'wrote file to {csv_filename}')\n",
    "else:\n",
    "    print(f'{csv_filename} exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1321b8-3de5-4129-862a-7b503427c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7728108f-df68-4e88-bfd0-a9298262c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset\n",
    "# BATCH_SIZE = 16 \n",
    "# PREFETCH = tf.data.AUTOTUNE\n",
    "SEED=37\n",
    "\n",
    "# model parameters\n",
    "# UNITS = 12\n",
    "# LAYER_1_L1 = 2e-4\n",
    "# LAYER_1_L2 = 5e-3\n",
    "# LAYER_2_L1 = 2e-4\n",
    "# LAYER_2_L2 = 5e-3\n",
    "\n",
    "\n",
    "\n",
    "#model fitting\n",
    "# EPOCHS = 500\n",
    "# LEARNING_RATE = 0.001 # initial learning rate\n",
    "# LR_PLATEAU_FACTOR = 0.5\n",
    "# LR_PLATEAU_PATIENCE = 5\n",
    "# LR_DECAY_RATE = 0.8\n",
    "# MIN_LEARNING_RATE = 1e-6\n",
    "# EARLY_STOPPING_PATIENCE = 40\n",
    "\n",
    "\n",
    "# mlflow\n",
    "MLFLOW_URI = uri=\"http://pistachio_mlflow:5000\"\n",
    "MLFLOW_EXPERIMENT = \"pistachio_tf_tuning\"\n",
    "MLFLOW_RUN_DESCRIPTION = 'initial tuning of two layer model'\n",
    "MLFLOW_TAGS = {'architecture': f'two layers'}\n",
    "\n",
    "# hyperopt\n",
    "TRIALS_FILE_LOCATION = f'./trials/trials_{MLFLOW_EXPERIMENT}.pkl'\n",
    "if not os.path.exists(os.path.dirname(TRIALS_FILE_LOCATION)):\n",
    "    os.makedirs(os.path.dirname(TRIALS_FILE_LOCATION))\n",
    "    \n",
    "# will save trials object at this location\n",
    "TRIALS_PER_RUN = 5\n",
    "# run this many trials per notebook execution.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e66103-32dc-4820-8089-71b0f3b4b789",
   "metadata": {},
   "source": [
    "## dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7845cd-40fe-4406-9874-ca68bc501561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "df shape = (1288, 17)\n",
      "   Class  AREA\n",
      "0      0   738\n",
      "1      1   550\n",
      "validation\n",
      "df shape = (430, 17)\n",
      "   Class  AREA\n",
      "0      0   247\n",
      "1      1   183\n",
      "test\n",
      "df shape = (430, 17)\n",
      "   Class  AREA\n",
      "0      0   247\n",
      "1      1   183\n"
     ]
    }
   ],
   "source": [
    "from pistachio.data import read_or_generate_splits\n",
    "\n",
    "# define where train/test csvs will live\n",
    "split_data_path = f\"./data/seed_{SEED}/\"\n",
    "if not os.path.exists(split_data_path):\n",
    "    os.makedirs(split_data_path)\n",
    "\n",
    "train_df, valid_df, test_df = read_or_generate_splits(split_data_path, csv_filename, seed=SEED)\n",
    "\n",
    "for setname, df in zip(['train','validation','test'],[train_df, valid_df, test_df]):\n",
    "    print(setname)\n",
    "    print(f'df shape = {df.shape}')\n",
    "    agged = df.groupby('Class').agg({'AREA':'count'}).reset_index()\n",
    "    print(agged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f2aaff-b76c-4041-b30b-09399a3ec519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AREA',\n",
       " 'PERIMETER',\n",
       " 'MAJOR_AXIS',\n",
       " 'MINOR_AXIS',\n",
       " 'ECCENTRICITY',\n",
       " 'EQDIASQ',\n",
       " 'SOLIDITY',\n",
       " 'CONVEX_AREA',\n",
       " 'EXTENT',\n",
       " 'ASPECT_RATIO',\n",
       " 'ROUNDNESS',\n",
       " 'COMPACTNESS',\n",
       " 'SHAPEFACTOR_1',\n",
       " 'SHAPEFACTOR_2',\n",
       " 'SHAPEFACTOR_3',\n",
       " 'SHAPEFACTOR_4']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = list(train_df.columns)\n",
    "feature_columns.remove('Class')\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778ff87f-3a47-493f-8bdc-54309fc32215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pistachio.data import df_to_dataset\n",
    "# # create datasets\n",
    "# train_ds = df_to_dataset(train_df,'Class', shuffle=True, drop=True)\n",
    "# valid_ds = df_to_dataset(valid_df,'Class', shuffle=False, drop=False)\n",
    "# test_ds = df_to_dataset(test_df,'Class', shuffle=False, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf349e02-402e-49c1-8656-24e3a197e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.298317366548036"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.log(5e-3)\n",
    "# np.exp(-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0033c4dd-2a95-4b3c-b256-cdbb478cf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "# hyperopt search space/parameters\n",
    "hp_space = {\n",
    "    # model\n",
    "    'units': hp.randint('units', 5,12),\n",
    "    'layer_l1_reg': hp.loguniform('layer_l1_reg', -13.1,-6.214),\n",
    "    'layer_l2_reg':hp.loguniform('layer_l2_reg',-13.1,-6.214),\n",
    "    'feature_columns':feature_columns,\n",
    "    # fitting\n",
    "    'learning_rate': hp.loguniform('learning_rate', -11.5,-5.3),\n",
    "    'lr_plateau_factor': hp.uniform('lr_plateau_factor', 0.5, 0.95),\n",
    "    'lr_plateau_patience': 20,\n",
    "    'lr_decay_rate': 0.9,\n",
    "    'min_learning_rate': 5e-8,\n",
    "    'early_stopping_patience': 40,\n",
    "\n",
    "    # data/batch/epochs\n",
    "    'batch_size': 16,\n",
    "    'prefetch':  tf.data.AUTOTUNE,\n",
    "    'epochs': 300,\n",
    "    'seed':SEED\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0274feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pistachio.data import df_to_dataset\n",
    "from pistachio.model import get_pistachio_model\n",
    "from typing import Dict \n",
    "import mlflow\n",
    "# create datasets\n",
    "import mlflow\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, roc_curve\n",
    "\n",
    "from pistachio.evaluation import plot_metric, get_roc_results, plot_roc_curve, get_confusion_matrix\n",
    "from pistachio.evaluation import make_precision_recall_plot, make_prob_calibration_plot, make_confusion_matrix_plot\n",
    "sns.set()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI)\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "\n",
    "# define our hyperopt objective\n",
    "def pistachio_objective(params: Dict) -> Dict:\n",
    "    '''take model parameters, build, train and evaluate model, return loss value and other stats'''\n",
    "    #     units: int,\n",
    "    # layer_l1_reg: float,\n",
    "    # layer_l2_reg: float,\n",
    "    # feature_columns:feature_columns,\n",
    "    # learning_rate: float,\n",
    "    # lr_plateau_factor: float,\n",
    "    # lr_plateau_patience: int,\n",
    "    # lr_decay_rate: float,\n",
    "    # min_learning_rate: float,\n",
    "    # early_stopping_patience: int,\n",
    "    # batch_size: int,\n",
    "    # prefetch:  int,\n",
    "    # epochs: int,\n",
    "    # seed:int \n",
    "    \n",
    "    # reset tf state\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # start mlflow run\n",
    "    with  mlflow.start_run(tags=MLFLOW_TAGS, description=MLFLOW_RUN_DESCRIPTION) as mlflow_run:\n",
    "\n",
    "        run_name = mlflow_run.info.run_name\n",
    "        run_id = mlflow_run.info.run_id\n",
    "        # mlflow.log_params(kwargs)\n",
    "\n",
    "\n",
    "        # define datasets \n",
    "        # think these need to go in here, given that we're clearing the tf state\n",
    "        train_ds = df_to_dataset(\n",
    "            train_df,\n",
    "            'Class',\n",
    "            shuffle=True,\n",
    "            drop=True,\n",
    "            batch_size=params.get('batch_size'),\n",
    "            prefetch=params.get('prefetch'))\n",
    "\n",
    "        valid_ds = df_to_dataset(\n",
    "            valid_df,\n",
    "            'Class', \n",
    "            shuffle=False,\n",
    "            drop=False,\n",
    "            batch_size=params.get('batch_size'),\n",
    "            prefetch=params.get('prefetch'))\n",
    "        \n",
    "        # get the model we'll train, adapting it on train data\n",
    "        model = get_pistachio_model(\n",
    "            feature_columns=params.get('feature_columns'),\n",
    "            train_dataset=train_ds,\n",
    "            units=params.get('units',10),\n",
    "            layer_l1_reg=params.get('layer_l1_reg'),\n",
    "            layer_l2_reg=params.get('layer_l2_reg'))\n",
    "    \n",
    "        checkpoint_dir = './pistachio_model_checkpoints/'\n",
    "        checkpoint_path = os.path.join(checkpoint_dir,f'model_{mlflow_run.info.run_name}.model.keras')\n",
    "\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "        metrics = {\n",
    "        'predicted_probability': [\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.BinaryAccuracy()]}\n",
    "\n",
    "        callbacks = [\n",
    "            # tf.keras.callbacks.TensorBoard(logdir, update_freq='batch'),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', \n",
    "                factor=params.get('lr_plateau_factor'), \n",
    "                patience=params.get('lr_plateau_patience'), \n",
    "                min_lr=params.get('min_learning_rate')),\n",
    "            tf.keras.callbacks.EarlyStopping(patience=params.get('early_stopping_patience')),\n",
    "            # checkpoint\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                initial_value_threshold=9000,\n",
    "                save_best_only=True),\n",
    "            # mlflow\n",
    "            mlflow.keras.MlflowCallback(mlflow_run)]\n",
    "    \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=params.get('learning_rate'))\n",
    "\n",
    "        # compile model\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss={'predicted_probability': tf.keras.losses.BinaryCrossentropy(from_logits=False)},\n",
    "            metrics=metrics)\n",
    "        \n",
    "        # train model\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=params.get('epochs'),\n",
    "            callbacks=callbacks,\n",
    "            validation_data=valid_ds,\n",
    "            verbose=2)\n",
    "        \n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df['epoch'] = history_df.index\n",
    "        # history_df.columns\n",
    "\n",
    "        # plot training stuff\n",
    "        plot_dir = f'./plots/{run_name}/'\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        metrics_to_plot = [\n",
    "            'learning_rate',\n",
    "            'auc',\n",
    "            'loss',\n",
    "            'binary_accuracy',\n",
    "            'recall',\n",
    "            'precision']\n",
    "\n",
    "        metric_plots = {}\n",
    "        for mm in metrics_to_plot:\n",
    "            metric_plots[mm] = plot_metric(history_df, mm);\n",
    "            \n",
    "            fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "            print(fig_path)\n",
    "            metric_plots[mm][0].savefig(fig_path);\n",
    "            plt.close() \n",
    "        \n",
    "        # look at the best training epoch, get some metrics\n",
    "\n",
    "        val_metrics = [k for k in history_df.columns if k.startswith('val')]\n",
    "        best_epoch = history_df.loc[history_df.val_loss == np.min(history_df.val_loss)][['epoch'] + val_metrics].copy()\n",
    "\n",
    "        # best_epoch\n",
    "        rename = {k:f'best_epoch_{k}' for k in val_metrics}\n",
    "        rename['epoch'] = 'best_epoch'\n",
    "\n",
    "        best_stats = best_epoch\\\n",
    "            .rename(columns=rename)\\\n",
    "            .to_dict(orient='records')[0]\n",
    "        \n",
    "        # log these things\n",
    "        mlflow.log_artifacts(plot_dir, artifact_path='training_plots')\n",
    "        mlflow.log_metrics(best_stats)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # load the best version of the model\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "        # get predictions on validation set\n",
    "        valid_features = {k: valid_df[k].values for k in feature_columns}\n",
    "        valid_predictions = model.predict(valid_features)\n",
    "        valid_df['predicted_prob'] = valid_predictions\n",
    "        threshold = 0.5\n",
    "        valid_df['predicted_class'] = valid_df.predicted_prob.map(lambda x: 0 if x < threshold else 1)\n",
    "\n",
    "        try:           \n",
    "            validation_metrics_path = './saved_model_validation_metrics.txt'\n",
    "            valid_auc_score = roc_auc_score(valid_df.Class, valid_df.predicted_prob)\n",
    "            \n",
    "            with open(validation_metrics_path,'w') as outfile:\n",
    "                outfile.write(f'accuracy: {accuracy_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'precision: {precision_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'recall: {recall_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'f1_score: {f1_score(valid_df.Class,valid_df.predicted_class)}\\n')\n",
    "                outfile.write(f'roc_auc_score: {valid_auc_score}\\n')\n",
    "            mlflow.log_artifact(validation_metrics_path)\n",
    "\n",
    "            # roc curve\n",
    "            roc_results = get_roc_results(valid_df.predicted_prob, valid_df.Class)\n",
    "            fig, ax = plot_roc_curve(*roc_results, title=f'validation data, auc_score = {valid_auc_score}');\n",
    "            roc_plot_path = os.path.join(plot_dir, 'roc_curve.png')\n",
    "            fig.savefig(roc_plot_path)\n",
    "            mlflow.log_artifact(roc_plot_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "    \n",
    "            # precision recall\n",
    "            fig, ax = make_precision_recall_plot(valid_df.predicted_prob, valid_df.Class, title='precision-recall')\n",
    "            prec_rec_path = os.path.join(plot_dir,'precision_recall_curve.png')\n",
    "            fig.savefig(prec_rec_path)\n",
    "            mlflow.log_artifact(prec_rec_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "    \n",
    "            # confusion matrix\n",
    "            fig, ax = make_confusion_matrix_plot(valid_df.predicted_class, valid_df.Class)\n",
    "            confusion_plot_path = os.path.join(plot_dir, 'confusion_matrix.png')\n",
    "            fig.savefig(confusion_plot_path)\n",
    "            mlflow.log_artifact(confusion_plot_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "    \n",
    "            # prob calibration\n",
    "            fig, ax = make_prob_calibration_plot(valid_df.predicted_prob, valid_df.Class, title='pistachio classifier probability calibration')\n",
    "            prob_cal_path = os.path.join(plot_dir,'probability_calibration.png')\n",
    "            fig.savefig(prob_cal_path)\n",
    "            mlflow.log_artifact(prob_cal_path, artifact_path='evaluation_plots')\n",
    "            plt.close()\n",
    "\n",
    "            # shap\n",
    "            def shap_wrapper(X):\n",
    "                feature_dict = {k:X[:,i] for i,k in enumerate(feature_columns)}\n",
    "                return model.predict(feature_dict, verbose=0).flatten()\n",
    "            shap_n_samples = 50\n",
    "            shap_explainer_samples = 50\n",
    "            shap_values_path = './shap_values.txt'\n",
    "\n",
    "            shap_violin_path = os.path.join(plot_dir,'shap_violin.png')\n",
    "            shap_bar_path = os.path.join(plot_dir,'shap_bar.png')\n",
    "            data_shap = train_df.loc[:,feature_columns]\n",
    "            explainer = shap.KernelExplainer(shap_wrapper, data_shap.iloc[:shap_explainer_samples,:])\n",
    "            shap_values = explainer.shap_values(data_shap.iloc[shap_explainer_samples:shap_explainer_samples+shap_n_samples, :], nsamples=200)\n",
    "            mlflow.log_artifact(prob_cal_path, artifact_path='evaluation_plots')\n",
    "\n",
    "            with open(shap_values_path,'w') as outfile:\n",
    "                outfile.write('SHAP values:\\n')\n",
    "                for k,v in zip(feature_columns, shap_values):\n",
    "                    outfile.write(f'{k}: {v}\\n')\n",
    "            mlflow.log_artifact(shap_values_path)\n",
    "\n",
    "            \n",
    "            shap.summary_plot(\n",
    "                shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"violin\", max_display=30, show=False)\n",
    "            plt.savefig(shap_violin_path)\n",
    "            plt.close()\n",
    "\n",
    "            shap.summary_plot(\n",
    "                shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"bar\", max_display=30, show=False)\n",
    "            plt.savefig(shap_bar_path)\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "            mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('exception during evaluation - may not have all plots available')\n",
    "    \n",
    "\n",
    "            # mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "            # mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "\n",
    "        # print(open(validation_metrics_path,'r').read())\n",
    "        # return. Can put more info in here, but it should be in mlflow regardless\n",
    "        return {'status': STATUS_OK, 'loss': best_stats['best_epoch_val_loss'], 'true_loss':best_stats['best_epoch_val_loss'] }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a8ac90-eceb-44cb-a73f-8d55a76c66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing - initialising normalisers               \n",
      " 75%|███████▌  | 15/20 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:36:01.965949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.559500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.560367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.562251: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.562609: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.562899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.665063: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.665288: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.665434: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-08 22:36:02.691811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5041 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2024-12-08 22:36:05.975389: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.019504: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.060660: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.104330: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.145947: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.188663: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.230841: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.273475: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.313832: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.356110: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.395704: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.436735: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.474961: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.517612: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.556472: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:36:06.594546: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                            \n",
      "\n",
      " 75%|███████▌  | 15/20 [00:05<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733697368.329977     161 service.cc:145] XLA service 0x78cdec010ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733697368.330005     161 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "2024-12-08 22:36:08.527666: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-08 22:36:09.145817: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n",
      "I0000 00:00:1733697370.253735     161 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 6s - 71ms/step - auc: 0.2331 - binary_accuracy: 0.3977 - loss: 0.7768 - precision: 0.1368 - recall: 0.0766 - val_auc: 0.2683 - val_binary_accuracy: 0.4442 - val_loss: 0.7598 - val_precision: 0.1667 - val_recall: 0.0765 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 2/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2447 - binary_accuracy: 0.4039 - loss: 0.7696 - precision: 0.1471 - recall: 0.0823 - val_auc: 0.2771 - val_binary_accuracy: 0.4512 - val_loss: 0.7538 - val_precision: 0.1728 - val_recall: 0.0765 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 3/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2582 - binary_accuracy: 0.4117 - loss: 0.7629 - precision: 0.1612 - recall: 0.0896 - val_auc: 0.2919 - val_binary_accuracy: 0.4651 - val_loss: 0.7480 - val_precision: 0.1948 - val_recall: 0.0820 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 4/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2753 - binary_accuracy: 0.4180 - loss: 0.7564 - precision: 0.1786 - recall: 0.1005 - val_auc: 0.3067 - val_binary_accuracy: 0.4651 - val_loss: 0.7424 - val_precision: 0.2025 - val_recall: 0.0874 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 5/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2902 - binary_accuracy: 0.4273 - loss: 0.7498 - precision: 0.1914 - recall: 0.1062 - val_auc: 0.3197 - val_binary_accuracy: 0.4767 - val_loss: 0.7368 - val_precision: 0.2308 - val_recall: 0.0984 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 6/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3047 - binary_accuracy: 0.4336 - loss: 0.7442 - precision: 0.2033 - recall: 0.1115 - val_auc: 0.3358 - val_binary_accuracy: 0.4884 - val_loss: 0.7316 - val_precision: 0.2597 - val_recall: 0.1093 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 7/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3225 - binary_accuracy: 0.4453 - loss: 0.7384 - precision: 0.2264 - recall: 0.1223 - val_auc: 0.3575 - val_binary_accuracy: 0.4953 - val_loss: 0.7264 - val_precision: 0.2875 - val_recall: 0.1257 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 8/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3391 - binary_accuracy: 0.4594 - loss: 0.7326 - precision: 0.2509 - recall: 0.1335 - val_auc: 0.3745 - val_binary_accuracy: 0.5047 - val_loss: 0.7213 - val_precision: 0.3125 - val_recall: 0.1366 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 9/300                                            \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3584 - binary_accuracy: 0.4711 - loss: 0.7265 - precision: 0.2708 - recall: 0.1431 - val_auc: 0.3916 - val_binary_accuracy: 0.5140 - val_loss: 0.7162 - val_precision: 0.3375 - val_recall: 0.1475 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 10/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3767 - binary_accuracy: 0.4805 - loss: 0.7206 - precision: 0.2847 - recall: 0.1471 - val_auc: 0.4115 - val_binary_accuracy: 0.5302 - val_loss: 0.7113 - val_precision: 0.3699 - val_recall: 0.1475 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 11/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3967 - binary_accuracy: 0.4922 - loss: 0.7149 - precision: 0.3114 - recall: 0.1554 - val_auc: 0.4324 - val_binary_accuracy: 0.5349 - val_loss: 0.7063 - val_precision: 0.3836 - val_recall: 0.1530 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 12/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4191 - binary_accuracy: 0.5070 - loss: 0.7093 - precision: 0.3433 - recall: 0.1682 - val_auc: 0.4516 - val_binary_accuracy: 0.5465 - val_loss: 0.7015 - val_precision: 0.4167 - val_recall: 0.1639 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 13/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4378 - binary_accuracy: 0.5156 - loss: 0.7049 - precision: 0.3636 - recall: 0.1752 - val_auc: 0.4748 - val_binary_accuracy: 0.5535 - val_loss: 0.6969 - val_precision: 0.4384 - val_recall: 0.1749 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 14/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4615 - binary_accuracy: 0.5289 - loss: 0.6988 - precision: 0.3908 - recall: 0.1868 - val_auc: 0.4965 - val_binary_accuracy: 0.5628 - val_loss: 0.6922 - val_precision: 0.4684 - val_recall: 0.2022 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 15/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.4844 - binary_accuracy: 0.5453 - loss: 0.6938 - precision: 0.4315 - recall: 0.1953 - val_auc: 0.5117 - val_binary_accuracy: 0.5744 - val_loss: 0.6877 - val_precision: 0.5000 - val_recall: 0.2131 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 16/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5060 - binary_accuracy: 0.5594 - loss: 0.6890 - precision: 0.4677 - recall: 0.2117 - val_auc: 0.5306 - val_binary_accuracy: 0.5814 - val_loss: 0.6832 - val_precision: 0.5190 - val_recall: 0.2240 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 17/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5295 - binary_accuracy: 0.5727 - loss: 0.6826 - precision: 0.4958 - recall: 0.2147 - val_auc: 0.5484 - val_binary_accuracy: 0.5977 - val_loss: 0.6789 - val_precision: 0.5694 - val_recall: 0.2240 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 18/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5458 - binary_accuracy: 0.5828 - loss: 0.6788 - precision: 0.5274 - recall: 0.2285 - val_auc: 0.5695 - val_binary_accuracy: 0.6140 - val_loss: 0.6746 - val_precision: 0.6269 - val_recall: 0.2295 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 19/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5690 - binary_accuracy: 0.5930 - loss: 0.6734 - precision: 0.5546 - recall: 0.2326 - val_auc: 0.5880 - val_binary_accuracy: 0.6163 - val_loss: 0.6705 - val_precision: 0.6324 - val_recall: 0.2350 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 20/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5872 - binary_accuracy: 0.6031 - loss: 0.6684 - precision: 0.5801 - recall: 0.2459 - val_auc: 0.6040 - val_binary_accuracy: 0.6233 - val_loss: 0.6662 - val_precision: 0.6522 - val_recall: 0.2459 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 21/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6041 - binary_accuracy: 0.6062 - loss: 0.6634 - precision: 0.5837 - recall: 0.2505 - val_auc: 0.6184 - val_binary_accuracy: 0.6279 - val_loss: 0.6621 - val_precision: 0.6667 - val_recall: 0.2514 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 22/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6226 - binary_accuracy: 0.6109 - loss: 0.6593 - precision: 0.6034 - recall: 0.2564 - val_auc: 0.6365 - val_binary_accuracy: 0.6372 - val_loss: 0.6578 - val_precision: 0.6957 - val_recall: 0.2623 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 23/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6425 - binary_accuracy: 0.6141 - loss: 0.6544 - precision: 0.6134 - recall: 0.2664 - val_auc: 0.6497 - val_binary_accuracy: 0.6372 - val_loss: 0.6537 - val_precision: 0.6901 - val_recall: 0.2678 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 24/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6588 - binary_accuracy: 0.6187 - loss: 0.6499 - precision: 0.6214 - recall: 0.2761 - val_auc: 0.6625 - val_binary_accuracy: 0.6349 - val_loss: 0.6496 - val_precision: 0.6806 - val_recall: 0.2678 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 25/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6736 - binary_accuracy: 0.6211 - loss: 0.6453 - precision: 0.6255 - recall: 0.2784 - val_auc: 0.6748 - val_binary_accuracy: 0.6372 - val_loss: 0.6456 - val_precision: 0.6800 - val_recall: 0.2787 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 26/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6905 - binary_accuracy: 0.6281 - loss: 0.6402 - precision: 0.6386 - recall: 0.2917 - val_auc: 0.6878 - val_binary_accuracy: 0.6419 - val_loss: 0.6416 - val_precision: 0.6933 - val_recall: 0.2842 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 27/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7057 - binary_accuracy: 0.6320 - loss: 0.6355 - precision: 0.6409 - recall: 0.3051 - val_auc: 0.6990 - val_binary_accuracy: 0.6512 - val_loss: 0.6375 - val_precision: 0.7089 - val_recall: 0.3060 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 28/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7205 - binary_accuracy: 0.6328 - loss: 0.6313 - precision: 0.6455 - recall: 0.3157 - val_auc: 0.7068 - val_binary_accuracy: 0.6535 - val_loss: 0.6336 - val_precision: 0.7125 - val_recall: 0.3115 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 29/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7342 - binary_accuracy: 0.6406 - loss: 0.6271 - precision: 0.6595 - recall: 0.3352 - val_auc: 0.7205 - val_binary_accuracy: 0.6558 - val_loss: 0.6297 - val_precision: 0.7160 - val_recall: 0.3169 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 30/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7448 - binary_accuracy: 0.6492 - loss: 0.6221 - precision: 0.6667 - recall: 0.3493 - val_auc: 0.7332 - val_binary_accuracy: 0.6535 - val_loss: 0.6258 - val_precision: 0.7024 - val_recall: 0.3224 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 31/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7539 - binary_accuracy: 0.6578 - loss: 0.6186 - precision: 0.6826 - recall: 0.3670 - val_auc: 0.7415 - val_binary_accuracy: 0.6605 - val_loss: 0.6220 - val_precision: 0.7126 - val_recall: 0.3388 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 32/300                                           \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.7659 - binary_accuracy: 0.6617 - loss: 0.6137 - precision: 0.6890 - recall: 0.3773 - val_auc: 0.7514 - val_binary_accuracy: 0.6628 - val_loss: 0.6183 - val_precision: 0.7159 - val_recall: 0.3443 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 33/300                                           \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.7758 - binary_accuracy: 0.6656 - loss: 0.6092 - precision: 0.6990 - recall: 0.3821 - val_auc: 0.7602 - val_binary_accuracy: 0.6605 - val_loss: 0.6147 - val_precision: 0.7033 - val_recall: 0.3497 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 34/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7807 - binary_accuracy: 0.6672 - loss: 0.6054 - precision: 0.6961 - recall: 0.3901 - val_auc: 0.7685 - val_binary_accuracy: 0.6605 - val_loss: 0.6110 - val_precision: 0.7033 - val_recall: 0.3497 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 35/300                                           \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.7900 - binary_accuracy: 0.6711 - loss: 0.6010 - precision: 0.7019 - recall: 0.4004 - val_auc: 0.7754 - val_binary_accuracy: 0.6767 - val_loss: 0.6075 - val_precision: 0.7391 - val_recall: 0.3716 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 36/300                                           \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.7928 - binary_accuracy: 0.6727 - loss: 0.5986 - precision: 0.7029 - recall: 0.4029 - val_auc: 0.7823 - val_binary_accuracy: 0.6814 - val_loss: 0.6041 - val_precision: 0.7447 - val_recall: 0.3825 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 37/300                                           \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.7992 - binary_accuracy: 0.6828 - loss: 0.5947 - precision: 0.7156 - recall: 0.4278 - val_auc: 0.7884 - val_binary_accuracy: 0.6930 - val_loss: 0.6008 - val_precision: 0.7684 - val_recall: 0.3989 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 38/300                                           \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8044 - binary_accuracy: 0.6922 - loss: 0.5908 - precision: 0.7284 - recall: 0.4461 - val_auc: 0.7967 - val_binary_accuracy: 0.6953 - val_loss: 0.5974 - val_precision: 0.7708 - val_recall: 0.4044 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 39/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8106 - binary_accuracy: 0.6945 - loss: 0.5867 - precision: 0.7331 - recall: 0.4545 - val_auc: 0.8021 - val_binary_accuracy: 0.7000 - val_loss: 0.5943 - val_precision: 0.7755 - val_recall: 0.4153 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 40/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8149 - binary_accuracy: 0.6961 - loss: 0.5833 - precision: 0.7278 - recall: 0.4635 - val_auc: 0.8069 - val_binary_accuracy: 0.7070 - val_loss: 0.5911 - val_precision: 0.7822 - val_recall: 0.4317 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 41/300                                           \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8199 - binary_accuracy: 0.7000 - loss: 0.5794 - precision: 0.7328 - recall: 0.4670 - val_auc: 0.8116 - val_binary_accuracy: 0.7140 - val_loss: 0.5879 - val_precision: 0.7941 - val_recall: 0.4426 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 42/300                                           \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8233 - binary_accuracy: 0.7102 - loss: 0.5762 - precision: 0.7410 - recall: 0.4927 - val_auc: 0.8182 - val_binary_accuracy: 0.7186 - val_loss: 0.5848 - val_precision: 0.7981 - val_recall: 0.4536 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 43/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8296 - binary_accuracy: 0.7148 - loss: 0.5723 - precision: 0.7473 - recall: 0.5064 - val_auc: 0.8223 - val_binary_accuracy: 0.7233 - val_loss: 0.5818 - val_precision: 0.8019 - val_recall: 0.4645 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 44/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8323 - binary_accuracy: 0.7188 - loss: 0.5695 - precision: 0.7467 - recall: 0.5209 - val_auc: 0.8275 - val_binary_accuracy: 0.7279 - val_loss: 0.5787 - val_precision: 0.8056 - val_recall: 0.4754 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 45/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8360 - binary_accuracy: 0.7211 - loss: 0.5663 - precision: 0.7448 - recall: 0.5283 - val_auc: 0.8329 - val_binary_accuracy: 0.7372 - val_loss: 0.5758 - val_precision: 0.8070 - val_recall: 0.5027 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 46/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8399 - binary_accuracy: 0.7266 - loss: 0.5627 - precision: 0.7500 - recall: 0.5420 - val_auc: 0.8350 - val_binary_accuracy: 0.7442 - val_loss: 0.5729 - val_precision: 0.8174 - val_recall: 0.5137 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 47/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8432 - binary_accuracy: 0.7320 - loss: 0.5591 - precision: 0.7538 - recall: 0.5505 - val_auc: 0.8379 - val_binary_accuracy: 0.7512 - val_loss: 0.5701 - val_precision: 0.8220 - val_recall: 0.5301 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 48/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8477 - binary_accuracy: 0.7422 - loss: 0.5557 - precision: 0.7659 - recall: 0.5730 - val_auc: 0.8412 - val_binary_accuracy: 0.7535 - val_loss: 0.5673 - val_precision: 0.8235 - val_recall: 0.5355 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 49/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8494 - binary_accuracy: 0.7477 - loss: 0.5528 - precision: 0.7679 - recall: 0.5868 - val_auc: 0.8439 - val_binary_accuracy: 0.7581 - val_loss: 0.5645 - val_precision: 0.8264 - val_recall: 0.5464 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 50/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8531 - binary_accuracy: 0.7484 - loss: 0.5494 - precision: 0.7698 - recall: 0.5868 - val_auc: 0.8483 - val_binary_accuracy: 0.7674 - val_loss: 0.5618 - val_precision: 0.8320 - val_recall: 0.5683 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 51/300                                           \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8547 - binary_accuracy: 0.7547 - loss: 0.5467 - precision: 0.7741 - recall: 0.6015 - val_auc: 0.8509 - val_binary_accuracy: 0.7674 - val_loss: 0.5592 - val_precision: 0.8268 - val_recall: 0.5738 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 52/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8572 - binary_accuracy: 0.7617 - loss: 0.5434 - precision: 0.7778 - recall: 0.6165 - val_auc: 0.8518 - val_binary_accuracy: 0.7721 - val_loss: 0.5565 - val_precision: 0.8295 - val_recall: 0.5847 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 53/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8602 - binary_accuracy: 0.7641 - loss: 0.5402 - precision: 0.7816 - recall: 0.6216 - val_auc: 0.8539 - val_binary_accuracy: 0.7721 - val_loss: 0.5539 - val_precision: 0.8244 - val_recall: 0.5902 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 54/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8606 - binary_accuracy: 0.7672 - loss: 0.5388 - precision: 0.7828 - recall: 0.6314 - val_auc: 0.8554 - val_binary_accuracy: 0.7698 - val_loss: 0.5514 - val_precision: 0.8182 - val_recall: 0.5902 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 55/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8638 - binary_accuracy: 0.7727 - loss: 0.5352 - precision: 0.7888 - recall: 0.6405 - val_auc: 0.8571 - val_binary_accuracy: 0.7698 - val_loss: 0.5489 - val_precision: 0.8182 - val_recall: 0.5902 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 56/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8655 - binary_accuracy: 0.7781 - loss: 0.5320 - precision: 0.7924 - recall: 0.6502 - val_auc: 0.8590 - val_binary_accuracy: 0.7721 - val_loss: 0.5465 - val_precision: 0.8195 - val_recall: 0.5956 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 57/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8665 - binary_accuracy: 0.7812 - loss: 0.5299 - precision: 0.7947 - recall: 0.6581 - val_auc: 0.8600 - val_binary_accuracy: 0.7721 - val_loss: 0.5441 - val_precision: 0.8148 - val_recall: 0.6011 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 58/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8680 - binary_accuracy: 0.7812 - loss: 0.5268 - precision: 0.7947 - recall: 0.6581 - val_auc: 0.8605 - val_binary_accuracy: 0.7744 - val_loss: 0.5417 - val_precision: 0.8162 - val_recall: 0.6066 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 59/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8695 - binary_accuracy: 0.7820 - loss: 0.5240 - precision: 0.7960 - recall: 0.6575 - val_auc: 0.8615 - val_binary_accuracy: 0.7791 - val_loss: 0.5394 - val_precision: 0.8188 - val_recall: 0.6175 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 60/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8725 - binary_accuracy: 0.7867 - loss: 0.5204 - precision: 0.7996 - recall: 0.6661 - val_auc: 0.8630 - val_binary_accuracy: 0.7767 - val_loss: 0.5371 - val_precision: 0.8085 - val_recall: 0.6230 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 61/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8726 - binary_accuracy: 0.7875 - loss: 0.5188 - precision: 0.8004 - recall: 0.6685 - val_auc: 0.8638 - val_binary_accuracy: 0.7791 - val_loss: 0.5348 - val_precision: 0.8099 - val_recall: 0.6284 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 62/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8735 - binary_accuracy: 0.7867 - loss: 0.5159 - precision: 0.8004 - recall: 0.6673 - val_auc: 0.8648 - val_binary_accuracy: 0.7837 - val_loss: 0.5325 - val_precision: 0.8125 - val_recall: 0.6393 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 63/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8772 - binary_accuracy: 0.7883 - loss: 0.5124 - precision: 0.8026 - recall: 0.6691 - val_auc: 0.8652 - val_binary_accuracy: 0.7860 - val_loss: 0.5303 - val_precision: 0.8138 - val_recall: 0.6448 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 64/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8764 - binary_accuracy: 0.7883 - loss: 0.5104 - precision: 0.7996 - recall: 0.6758 - val_auc: 0.8662 - val_binary_accuracy: 0.7860 - val_loss: 0.5280 - val_precision: 0.8138 - val_recall: 0.6448 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 65/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8789 - binary_accuracy: 0.7914 - loss: 0.5076 - precision: 0.8017 - recall: 0.6801 - val_auc: 0.8673 - val_binary_accuracy: 0.7860 - val_loss: 0.5259 - val_precision: 0.8138 - val_recall: 0.6448 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 66/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8795 - binary_accuracy: 0.7922 - loss: 0.5049 - precision: 0.8013 - recall: 0.6843 - val_auc: 0.8661 - val_binary_accuracy: 0.7884 - val_loss: 0.5236 - val_precision: 0.8151 - val_recall: 0.6503 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 67/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8797 - binary_accuracy: 0.7945 - loss: 0.5030 - precision: 0.8021 - recall: 0.6892 - val_auc: 0.8674 - val_binary_accuracy: 0.7884 - val_loss: 0.5214 - val_precision: 0.8151 - val_recall: 0.6503 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 68/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8804 - binary_accuracy: 0.7961 - loss: 0.5003 - precision: 0.8021 - recall: 0.6917 - val_auc: 0.8699 - val_binary_accuracy: 0.7884 - val_loss: 0.5193 - val_precision: 0.8108 - val_recall: 0.6557 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 69/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8823 - binary_accuracy: 0.8000 - loss: 0.4978 - precision: 0.8089 - recall: 0.6965 - val_auc: 0.8705 - val_binary_accuracy: 0.7860 - val_loss: 0.5172 - val_precision: 0.8054 - val_recall: 0.6557 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 70/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8825 - binary_accuracy: 0.8008 - loss: 0.4955 - precision: 0.8042 - recall: 0.7057 - val_auc: 0.8717 - val_binary_accuracy: 0.7837 - val_loss: 0.5150 - val_precision: 0.7961 - val_recall: 0.6612 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 71/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8847 - binary_accuracy: 0.8078 - loss: 0.4925 - precision: 0.8099 - recall: 0.7179 - val_auc: 0.8714 - val_binary_accuracy: 0.7837 - val_loss: 0.5130 - val_precision: 0.7961 - val_recall: 0.6612 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 72/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8845 - binary_accuracy: 0.8086 - loss: 0.4908 - precision: 0.8082 - recall: 0.7239 - val_auc: 0.8722 - val_binary_accuracy: 0.7837 - val_loss: 0.5109 - val_precision: 0.7961 - val_recall: 0.6612 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 73/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8852 - binary_accuracy: 0.8086 - loss: 0.4875 - precision: 0.8078 - recall: 0.7234 - val_auc: 0.8732 - val_binary_accuracy: 0.7837 - val_loss: 0.5088 - val_precision: 0.7961 - val_recall: 0.6612 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 74/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8873 - binary_accuracy: 0.8102 - loss: 0.4852 - precision: 0.8119 - recall: 0.7245 - val_auc: 0.8742 - val_binary_accuracy: 0.7860 - val_loss: 0.5067 - val_precision: 0.7974 - val_recall: 0.6667 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 75/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8857 - binary_accuracy: 0.8078 - loss: 0.4844 - precision: 0.8049 - recall: 0.7253 - val_auc: 0.8744 - val_binary_accuracy: 0.7907 - val_loss: 0.5046 - val_precision: 0.8000 - val_recall: 0.6776 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 76/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8892 - binary_accuracy: 0.8094 - loss: 0.4800 - precision: 0.8044 - recall: 0.7308 - val_auc: 0.8750 - val_binary_accuracy: 0.7930 - val_loss: 0.5025 - val_precision: 0.8013 - val_recall: 0.6831 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 77/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8877 - binary_accuracy: 0.8094 - loss: 0.4788 - precision: 0.8044 - recall: 0.7308 - val_auc: 0.8760 - val_binary_accuracy: 0.7930 - val_loss: 0.5004 - val_precision: 0.8013 - val_recall: 0.6831 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 78/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8899 - binary_accuracy: 0.8117 - loss: 0.4751 - precision: 0.8081 - recall: 0.7326 - val_auc: 0.8762 - val_binary_accuracy: 0.7930 - val_loss: 0.4984 - val_precision: 0.8013 - val_recall: 0.6831 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 79/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8900 - binary_accuracy: 0.8117 - loss: 0.4732 - precision: 0.8068 - recall: 0.7344 - val_auc: 0.8771 - val_binary_accuracy: 0.7907 - val_loss: 0.4963 - val_precision: 0.7962 - val_recall: 0.6831 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 80/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8893 - binary_accuracy: 0.8102 - loss: 0.4729 - precision: 0.8060 - recall: 0.7341 - val_auc: 0.8778 - val_binary_accuracy: 0.7953 - val_loss: 0.4943 - val_precision: 0.7987 - val_recall: 0.6940 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 81/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8913 - binary_accuracy: 0.8125 - loss: 0.4689 - precision: 0.8060 - recall: 0.7381 - val_auc: 0.8778 - val_binary_accuracy: 0.7953 - val_loss: 0.4923 - val_precision: 0.7987 - val_recall: 0.6940 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 82/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8917 - binary_accuracy: 0.8125 - loss: 0.4669 - precision: 0.8040 - recall: 0.7390 - val_auc: 0.8791 - val_binary_accuracy: 0.7977 - val_loss: 0.4903 - val_precision: 0.8038 - val_recall: 0.6940 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 83/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8921 - binary_accuracy: 0.8125 - loss: 0.4651 - precision: 0.8064 - recall: 0.7386 - val_auc: 0.8797 - val_binary_accuracy: 0.7977 - val_loss: 0.4884 - val_precision: 0.8038 - val_recall: 0.6940 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 84/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8936 - binary_accuracy: 0.8133 - loss: 0.4624 - precision: 0.8084 - recall: 0.7391 - val_auc: 0.8806 - val_binary_accuracy: 0.7977 - val_loss: 0.4864 - val_precision: 0.8000 - val_recall: 0.6995 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 85/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8941 - binary_accuracy: 0.8148 - loss: 0.4607 - precision: 0.8091 - recall: 0.7427 - val_auc: 0.8814 - val_binary_accuracy: 0.7977 - val_loss: 0.4844 - val_precision: 0.8000 - val_recall: 0.6995 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 86/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8960 - binary_accuracy: 0.8188 - loss: 0.4573 - precision: 0.8083 - recall: 0.7518 - val_auc: 0.8815 - val_binary_accuracy: 0.8000 - val_loss: 0.4825 - val_precision: 0.8050 - val_recall: 0.6995 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 87/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8952 - binary_accuracy: 0.8172 - loss: 0.4566 - precision: 0.8094 - recall: 0.7505 - val_auc: 0.8818 - val_binary_accuracy: 0.8000 - val_loss: 0.4806 - val_precision: 0.8050 - val_recall: 0.6995 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 88/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8964 - binary_accuracy: 0.8172 - loss: 0.4539 - precision: 0.8047 - recall: 0.7546 - val_auc: 0.8827 - val_binary_accuracy: 0.8000 - val_loss: 0.4789 - val_precision: 0.8050 - val_recall: 0.6995 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 89/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8963 - binary_accuracy: 0.8180 - loss: 0.4529 - precision: 0.8039 - recall: 0.7582 - val_auc: 0.8829 - val_binary_accuracy: 0.8023 - val_loss: 0.4770 - val_precision: 0.8062 - val_recall: 0.7049 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 90/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8982 - binary_accuracy: 0.8188 - loss: 0.4498 - precision: 0.8066 - recall: 0.7596 - val_auc: 0.8836 - val_binary_accuracy: 0.8023 - val_loss: 0.4751 - val_precision: 0.8062 - val_recall: 0.7049 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 91/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9005 - binary_accuracy: 0.8219 - loss: 0.4458 - precision: 0.8085 - recall: 0.7642 - val_auc: 0.8846 - val_binary_accuracy: 0.8023 - val_loss: 0.4733 - val_precision: 0.8062 - val_recall: 0.7049 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 92/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9018 - binary_accuracy: 0.8242 - loss: 0.4430 - precision: 0.8092 - recall: 0.7692 - val_auc: 0.8856 - val_binary_accuracy: 0.8023 - val_loss: 0.4715 - val_precision: 0.8062 - val_recall: 0.7049 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 93/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9006 - binary_accuracy: 0.8219 - loss: 0.4427 - precision: 0.8065 - recall: 0.7682 - val_auc: 0.8855 - val_binary_accuracy: 0.8047 - val_loss: 0.4697 - val_precision: 0.8075 - val_recall: 0.7104 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 94/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9014 - binary_accuracy: 0.8242 - loss: 0.4415 - precision: 0.8073 - recall: 0.7733 - val_auc: 0.8859 - val_binary_accuracy: 0.8070 - val_loss: 0.4679 - val_precision: 0.8086 - val_recall: 0.7158 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 95/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9023 - binary_accuracy: 0.8250 - loss: 0.4382 - precision: 0.8046 - recall: 0.7780 - val_auc: 0.8870 - val_binary_accuracy: 0.8047 - val_loss: 0.4661 - val_precision: 0.8037 - val_recall: 0.7158 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 96/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9026 - binary_accuracy: 0.8258 - loss: 0.4367 - precision: 0.8053 - recall: 0.7802 - val_auc: 0.8880 - val_binary_accuracy: 0.8070 - val_loss: 0.4642 - val_precision: 0.8012 - val_recall: 0.7268 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 97/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9032 - binary_accuracy: 0.8289 - loss: 0.4352 - precision: 0.8094 - recall: 0.7843 - val_auc: 0.8882 - val_binary_accuracy: 0.8116 - val_loss: 0.4623 - val_precision: 0.8036 - val_recall: 0.7377 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 98/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9049 - binary_accuracy: 0.8289 - loss: 0.4322 - precision: 0.8083 - recall: 0.7861 - val_auc: 0.8893 - val_binary_accuracy: 0.8093 - val_loss: 0.4606 - val_precision: 0.8024 - val_recall: 0.7322 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 99/300                                           \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9053 - binary_accuracy: 0.8297 - loss: 0.4298 - precision: 0.8064 - recall: 0.7886 - val_auc: 0.8895 - val_binary_accuracy: 0.8093 - val_loss: 0.4588 - val_precision: 0.8024 - val_recall: 0.7322 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 100/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9055 - binary_accuracy: 0.8313 - loss: 0.4285 - precision: 0.8098 - recall: 0.7890 - val_auc: 0.8905 - val_binary_accuracy: 0.8093 - val_loss: 0.4571 - val_precision: 0.8024 - val_recall: 0.7322 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 101/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9063 - binary_accuracy: 0.8328 - loss: 0.4267 - precision: 0.8097 - recall: 0.7949 - val_auc: 0.8912 - val_binary_accuracy: 0.8116 - val_loss: 0.4553 - val_precision: 0.8036 - val_recall: 0.7377 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 102/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9070 - binary_accuracy: 0.8359 - loss: 0.4251 - precision: 0.8145 - recall: 0.7996 - val_auc: 0.8919 - val_binary_accuracy: 0.8186 - val_loss: 0.4535 - val_precision: 0.8035 - val_recall: 0.7596 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 103/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9075 - binary_accuracy: 0.8375 - loss: 0.4228 - precision: 0.8153 - recall: 0.8004 - val_auc: 0.8922 - val_binary_accuracy: 0.8163 - val_loss: 0.4519 - val_precision: 0.7989 - val_recall: 0.7596 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 104/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9088 - binary_accuracy: 0.8391 - loss: 0.4205 - precision: 0.8160 - recall: 0.8040 - val_auc: 0.8932 - val_binary_accuracy: 0.8163 - val_loss: 0.4502 - val_precision: 0.7989 - val_recall: 0.7596 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 105/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9087 - binary_accuracy: 0.8375 - loss: 0.4194 - precision: 0.8145 - recall: 0.8026 - val_auc: 0.8933 - val_binary_accuracy: 0.8209 - val_loss: 0.4485 - val_precision: 0.8011 - val_recall: 0.7705 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 106/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9094 - binary_accuracy: 0.8375 - loss: 0.4174 - precision: 0.8126 - recall: 0.8037 - val_auc: 0.8937 - val_binary_accuracy: 0.8186 - val_loss: 0.4469 - val_precision: 0.7966 - val_recall: 0.7705 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 107/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9102 - binary_accuracy: 0.8398 - loss: 0.4156 - precision: 0.8152 - recall: 0.8077 - val_auc: 0.8947 - val_binary_accuracy: 0.8186 - val_loss: 0.4452 - val_precision: 0.7966 - val_recall: 0.7705 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 108/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9115 - binary_accuracy: 0.8414 - loss: 0.4131 - precision: 0.8167 - recall: 0.8092 - val_auc: 0.8951 - val_binary_accuracy: 0.8209 - val_loss: 0.4436 - val_precision: 0.8011 - val_recall: 0.7705 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 109/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9114 - binary_accuracy: 0.8406 - loss: 0.4121 - precision: 0.8147 - recall: 0.8117 - val_auc: 0.8957 - val_binary_accuracy: 0.8233 - val_loss: 0.4420 - val_precision: 0.8023 - val_recall: 0.7760 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 110/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9116 - binary_accuracy: 0.8414 - loss: 0.4107 - precision: 0.8128 - recall: 0.8143 - val_auc: 0.8959 - val_binary_accuracy: 0.8233 - val_loss: 0.4405 - val_precision: 0.8023 - val_recall: 0.7760 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 111/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9123 - binary_accuracy: 0.8430 - loss: 0.4088 - precision: 0.8145 - recall: 0.8190 - val_auc: 0.8965 - val_binary_accuracy: 0.8256 - val_loss: 0.4390 - val_precision: 0.8034 - val_recall: 0.7814 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 112/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9129 - binary_accuracy: 0.8430 - loss: 0.4067 - precision: 0.8149 - recall: 0.8193 - val_auc: 0.8967 - val_binary_accuracy: 0.8256 - val_loss: 0.4376 - val_precision: 0.8034 - val_recall: 0.7814 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 113/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9141 - binary_accuracy: 0.8445 - loss: 0.4040 - precision: 0.8152 - recall: 0.8227 - val_auc: 0.8973 - val_binary_accuracy: 0.8256 - val_loss: 0.4361 - val_precision: 0.8034 - val_recall: 0.7814 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 114/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9142 - binary_accuracy: 0.8445 - loss: 0.4033 - precision: 0.8152 - recall: 0.8227 - val_auc: 0.8979 - val_binary_accuracy: 0.8279 - val_loss: 0.4347 - val_precision: 0.8045 - val_recall: 0.7869 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 115/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9157 - binary_accuracy: 0.8461 - loss: 0.4001 - precision: 0.8170 - recall: 0.8245 - val_auc: 0.8984 - val_binary_accuracy: 0.8256 - val_loss: 0.4332 - val_precision: 0.8000 - val_recall: 0.7869 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 116/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9152 - binary_accuracy: 0.8453 - loss: 0.3996 - precision: 0.8152 - recall: 0.8242 - val_auc: 0.8991 - val_binary_accuracy: 0.8279 - val_loss: 0.4319 - val_precision: 0.8011 - val_recall: 0.7923 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 117/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9155 - binary_accuracy: 0.8445 - loss: 0.3978 - precision: 0.8141 - recall: 0.8245 - val_auc: 0.8993 - val_binary_accuracy: 0.8279 - val_loss: 0.4305 - val_precision: 0.8011 - val_recall: 0.7923 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 118/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9157 - binary_accuracy: 0.8453 - loss: 0.3971 - precision: 0.8152 - recall: 0.8242 - val_auc: 0.9000 - val_binary_accuracy: 0.8326 - val_loss: 0.4291 - val_precision: 0.8066 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 119/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9160 - binary_accuracy: 0.8445 - loss: 0.3955 - precision: 0.8152 - recall: 0.8227 - val_auc: 0.9001 - val_binary_accuracy: 0.8326 - val_loss: 0.4279 - val_precision: 0.8066 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 120/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9163 - binary_accuracy: 0.8453 - loss: 0.3944 - precision: 0.8159 - recall: 0.8248 - val_auc: 0.9008 - val_binary_accuracy: 0.8302 - val_loss: 0.4266 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 121/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9166 - binary_accuracy: 0.8477 - loss: 0.3931 - precision: 0.8162 - recall: 0.8297 - val_auc: 0.9013 - val_binary_accuracy: 0.8302 - val_loss: 0.4254 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 122/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9174 - binary_accuracy: 0.8492 - loss: 0.3909 - precision: 0.8183 - recall: 0.8318 - val_auc: 0.9017 - val_binary_accuracy: 0.8302 - val_loss: 0.4243 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 123/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9179 - binary_accuracy: 0.8484 - loss: 0.3897 - precision: 0.8162 - recall: 0.8312 - val_auc: 0.9022 - val_binary_accuracy: 0.8302 - val_loss: 0.4231 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 124/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9182 - binary_accuracy: 0.8500 - loss: 0.3879 - precision: 0.8180 - recall: 0.8330 - val_auc: 0.9022 - val_binary_accuracy: 0.8326 - val_loss: 0.4219 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 125/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9191 - binary_accuracy: 0.8500 - loss: 0.3863 - precision: 0.8190 - recall: 0.8339 - val_auc: 0.9026 - val_binary_accuracy: 0.8326 - val_loss: 0.4208 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 126/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9181 - binary_accuracy: 0.8484 - loss: 0.3870 - precision: 0.8157 - recall: 0.8336 - val_auc: 0.9031 - val_binary_accuracy: 0.8326 - val_loss: 0.4196 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 127/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9191 - binary_accuracy: 0.8500 - loss: 0.3845 - precision: 0.8146 - recall: 0.8385 - val_auc: 0.9032 - val_binary_accuracy: 0.8326 - val_loss: 0.4185 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 128/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9204 - binary_accuracy: 0.8516 - loss: 0.3821 - precision: 0.8174 - recall: 0.8412 - val_auc: 0.9030 - val_binary_accuracy: 0.8349 - val_loss: 0.4174 - val_precision: 0.8043 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 129/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9190 - binary_accuracy: 0.8484 - loss: 0.3832 - precision: 0.8135 - recall: 0.8373 - val_auc: 0.9035 - val_binary_accuracy: 0.8326 - val_loss: 0.4164 - val_precision: 0.8000 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 130/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9201 - binary_accuracy: 0.8516 - loss: 0.3803 - precision: 0.8167 - recall: 0.8407 - val_auc: 0.9038 - val_binary_accuracy: 0.8326 - val_loss: 0.4153 - val_precision: 0.8000 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 131/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9198 - binary_accuracy: 0.8531 - loss: 0.3805 - precision: 0.8163 - recall: 0.8462 - val_auc: 0.9038 - val_binary_accuracy: 0.8326 - val_loss: 0.4143 - val_precision: 0.8000 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 132/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9204 - binary_accuracy: 0.8531 - loss: 0.3788 - precision: 0.8163 - recall: 0.8462 - val_auc: 0.9041 - val_binary_accuracy: 0.8326 - val_loss: 0.4133 - val_precision: 0.8000 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 133/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9212 - binary_accuracy: 0.8539 - loss: 0.3770 - precision: 0.8177 - recall: 0.8462 - val_auc: 0.9046 - val_binary_accuracy: 0.8326 - val_loss: 0.4123 - val_precision: 0.8000 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 134/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9203 - binary_accuracy: 0.8516 - loss: 0.3781 - precision: 0.8155 - recall: 0.8452 - val_auc: 0.9047 - val_binary_accuracy: 0.8326 - val_loss: 0.4113 - val_precision: 0.8000 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 135/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9211 - binary_accuracy: 0.8531 - loss: 0.3760 - precision: 0.8155 - recall: 0.8483 - val_auc: 0.9049 - val_binary_accuracy: 0.8349 - val_loss: 0.4105 - val_precision: 0.8011 - val_recall: 0.8142 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 136/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9213 - binary_accuracy: 0.8539 - loss: 0.3749 - precision: 0.8166 - recall: 0.8480 - val_auc: 0.9048 - val_binary_accuracy: 0.8372 - val_loss: 0.4095 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 137/300                                          \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9212 - binary_accuracy: 0.8531 - loss: 0.3744 - precision: 0.8166 - recall: 0.8464 - val_auc: 0.9054 - val_binary_accuracy: 0.8372 - val_loss: 0.4086 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 138/300                                          \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9218 - binary_accuracy: 0.8531 - loss: 0.3729 - precision: 0.8177 - recall: 0.8446 - val_auc: 0.9056 - val_binary_accuracy: 0.8419 - val_loss: 0.4078 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 139/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9226 - binary_accuracy: 0.8547 - loss: 0.3708 - precision: 0.8191 - recall: 0.8462 - val_auc: 0.9057 - val_binary_accuracy: 0.8419 - val_loss: 0.4069 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 140/300                                          \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9244 - binary_accuracy: 0.8555 - loss: 0.3672 - precision: 0.8169 - recall: 0.8514 - val_auc: 0.9061 - val_binary_accuracy: 0.8419 - val_loss: 0.4061 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 141/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9228 - binary_accuracy: 0.8555 - loss: 0.3694 - precision: 0.8180 - recall: 0.8495 - val_auc: 0.9063 - val_binary_accuracy: 0.8419 - val_loss: 0.4052 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 142/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9223 - binary_accuracy: 0.8531 - loss: 0.3697 - precision: 0.8166 - recall: 0.8464 - val_auc: 0.9066 - val_binary_accuracy: 0.8419 - val_loss: 0.4044 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 143/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9237 - binary_accuracy: 0.8531 - loss: 0.3670 - precision: 0.8151 - recall: 0.8480 - val_auc: 0.9067 - val_binary_accuracy: 0.8419 - val_loss: 0.4036 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 144/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9231 - binary_accuracy: 0.8555 - loss: 0.3676 - precision: 0.8193 - recall: 0.8506 - val_auc: 0.9068 - val_binary_accuracy: 0.8419 - val_loss: 0.4029 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 145/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9230 - binary_accuracy: 0.8539 - loss: 0.3671 - precision: 0.8161 - recall: 0.8504 - val_auc: 0.9067 - val_binary_accuracy: 0.8419 - val_loss: 0.4021 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 146/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9231 - binary_accuracy: 0.8531 - loss: 0.3665 - precision: 0.8137 - recall: 0.8495 - val_auc: 0.9070 - val_binary_accuracy: 0.8419 - val_loss: 0.4014 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 147/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9235 - binary_accuracy: 0.8539 - loss: 0.3652 - precision: 0.8140 - recall: 0.8514 - val_auc: 0.9073 - val_binary_accuracy: 0.8419 - val_loss: 0.4007 - val_precision: 0.8075 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 148/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9243 - binary_accuracy: 0.8562 - loss: 0.3636 - precision: 0.8153 - recall: 0.8571 - val_auc: 0.9076 - val_binary_accuracy: 0.8395 - val_loss: 0.4000 - val_precision: 0.8032 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 149/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9238 - binary_accuracy: 0.8547 - loss: 0.3641 - precision: 0.8150 - recall: 0.8537 - val_auc: 0.9078 - val_binary_accuracy: 0.8372 - val_loss: 0.3993 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 150/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9255 - binary_accuracy: 0.8570 - loss: 0.3614 - precision: 0.8182 - recall: 0.8556 - val_auc: 0.9078 - val_binary_accuracy: 0.8372 - val_loss: 0.3987 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 151/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9270 - binary_accuracy: 0.8578 - loss: 0.3583 - precision: 0.8297 - recall: 0.8388 - val_auc: 0.9080 - val_binary_accuracy: 0.8302 - val_loss: 0.3980 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 152/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9247 - binary_accuracy: 0.8547 - loss: 0.3616 - precision: 0.8243 - recall: 0.8364 - val_auc: 0.9083 - val_binary_accuracy: 0.8302 - val_loss: 0.3974 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 153/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9251 - binary_accuracy: 0.8555 - loss: 0.3601 - precision: 0.8267 - recall: 0.8373 - val_auc: 0.9082 - val_binary_accuracy: 0.8302 - val_loss: 0.3968 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 154/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9251 - binary_accuracy: 0.8555 - loss: 0.3601 - precision: 0.8252 - recall: 0.8388 - val_auc: 0.9082 - val_binary_accuracy: 0.8302 - val_loss: 0.3963 - val_precision: 0.8022 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 155/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9251 - binary_accuracy: 0.8555 - loss: 0.3594 - precision: 0.8267 - recall: 0.8373 - val_auc: 0.9085 - val_binary_accuracy: 0.8279 - val_loss: 0.3957 - val_precision: 0.7978 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 156/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9263 - binary_accuracy: 0.8570 - loss: 0.3568 - precision: 0.8285 - recall: 0.8391 - val_auc: 0.9086 - val_binary_accuracy: 0.8256 - val_loss: 0.3951 - val_precision: 0.7935 - val_recall: 0.7978 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 157/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9258 - binary_accuracy: 0.8562 - loss: 0.3578 - precision: 0.8270 - recall: 0.8391 - val_auc: 0.9088 - val_binary_accuracy: 0.8279 - val_loss: 0.3946 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 158/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9264 - binary_accuracy: 0.8570 - loss: 0.3560 - precision: 0.8273 - recall: 0.8410 - val_auc: 0.9092 - val_binary_accuracy: 0.8279 - val_loss: 0.3940 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 159/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9269 - binary_accuracy: 0.8578 - loss: 0.3552 - precision: 0.8294 - recall: 0.8415 - val_auc: 0.9092 - val_binary_accuracy: 0.8279 - val_loss: 0.3936 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 160/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9266 - binary_accuracy: 0.8586 - loss: 0.3554 - precision: 0.8291 - recall: 0.8428 - val_auc: 0.9093 - val_binary_accuracy: 0.8279 - val_loss: 0.3931 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 161/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9263 - binary_accuracy: 0.8570 - loss: 0.3554 - precision: 0.8276 - recall: 0.8412 - val_auc: 0.9095 - val_binary_accuracy: 0.8279 - val_loss: 0.3925 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 162/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9266 - binary_accuracy: 0.8578 - loss: 0.3543 - precision: 0.8276 - recall: 0.8428 - val_auc: 0.9094 - val_binary_accuracy: 0.8279 - val_loss: 0.3920 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 163/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9270 - binary_accuracy: 0.8578 - loss: 0.3535 - precision: 0.8270 - recall: 0.8422 - val_auc: 0.9092 - val_binary_accuracy: 0.8279 - val_loss: 0.3916 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 164/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9270 - binary_accuracy: 0.8586 - loss: 0.3531 - precision: 0.8280 - recall: 0.8446 - val_auc: 0.9092 - val_binary_accuracy: 0.8279 - val_loss: 0.3911 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 165/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9268 - binary_accuracy: 0.8562 - loss: 0.3529 - precision: 0.8246 - recall: 0.8398 - val_auc: 0.9094 - val_binary_accuracy: 0.8279 - val_loss: 0.3907 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 166/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9264 - binary_accuracy: 0.8555 - loss: 0.3530 - precision: 0.8246 - recall: 0.8382 - val_auc: 0.9096 - val_binary_accuracy: 0.8279 - val_loss: 0.3902 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 167/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9273 - binary_accuracy: 0.8562 - loss: 0.3514 - precision: 0.8282 - recall: 0.8373 - val_auc: 0.9097 - val_binary_accuracy: 0.8279 - val_loss: 0.3898 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 168/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9276 - binary_accuracy: 0.8570 - loss: 0.3509 - precision: 0.8259 - recall: 0.8425 - val_auc: 0.9097 - val_binary_accuracy: 0.8279 - val_loss: 0.3894 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 169/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9275 - binary_accuracy: 0.8555 - loss: 0.3504 - precision: 0.8261 - recall: 0.8367 - val_auc: 0.9098 - val_binary_accuracy: 0.8279 - val_loss: 0.3890 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 170/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9275 - binary_accuracy: 0.8555 - loss: 0.3505 - precision: 0.8255 - recall: 0.8391 - val_auc: 0.9099 - val_binary_accuracy: 0.8279 - val_loss: 0.3886 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 171/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9275 - binary_accuracy: 0.8547 - loss: 0.3500 - precision: 0.8264 - recall: 0.8355 - val_auc: 0.9101 - val_binary_accuracy: 0.8302 - val_loss: 0.3882 - val_precision: 0.7989 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 172/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9284 - binary_accuracy: 0.8570 - loss: 0.3480 - precision: 0.8270 - recall: 0.8407 - val_auc: 0.9101 - val_binary_accuracy: 0.8279 - val_loss: 0.3878 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 173/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9276 - binary_accuracy: 0.8570 - loss: 0.3492 - precision: 0.8285 - recall: 0.8391 - val_auc: 0.9103 - val_binary_accuracy: 0.8279 - val_loss: 0.3874 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 174/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9282 - binary_accuracy: 0.8586 - loss: 0.3478 - precision: 0.8288 - recall: 0.8425 - val_auc: 0.9104 - val_binary_accuracy: 0.8279 - val_loss: 0.3870 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 175/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9281 - binary_accuracy: 0.8578 - loss: 0.3475 - precision: 0.8297 - recall: 0.8388 - val_auc: 0.9107 - val_binary_accuracy: 0.8279 - val_loss: 0.3866 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 176/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9278 - binary_accuracy: 0.8570 - loss: 0.3483 - precision: 0.8288 - recall: 0.8394 - val_auc: 0.9109 - val_binary_accuracy: 0.8279 - val_loss: 0.3863 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 177/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9288 - binary_accuracy: 0.8594 - loss: 0.3465 - precision: 0.8301 - recall: 0.8452 - val_auc: 0.9110 - val_binary_accuracy: 0.8279 - val_loss: 0.3860 - val_precision: 0.7946 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 178/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9285 - binary_accuracy: 0.8586 - loss: 0.3461 - precision: 0.8282 - recall: 0.8419 - val_auc: 0.9112 - val_binary_accuracy: 0.8256 - val_loss: 0.3856 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 179/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9283 - binary_accuracy: 0.8578 - loss: 0.3468 - precision: 0.8262 - recall: 0.8443 - val_auc: 0.9111 - val_binary_accuracy: 0.8256 - val_loss: 0.3853 - val_precision: 0.7903 - val_recall: 0.8033 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 180/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9287 - binary_accuracy: 0.8586 - loss: 0.3456 - precision: 0.8280 - recall: 0.8446 - val_auc: 0.9110 - val_binary_accuracy: 0.8279 - val_loss: 0.3850 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 181/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9295 - binary_accuracy: 0.8594 - loss: 0.3434 - precision: 0.8306 - recall: 0.8428 - val_auc: 0.9114 - val_binary_accuracy: 0.8279 - val_loss: 0.3846 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 182/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9284 - binary_accuracy: 0.8578 - loss: 0.3454 - precision: 0.8273 - recall: 0.8425 - val_auc: 0.9115 - val_binary_accuracy: 0.8279 - val_loss: 0.3843 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 183/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9286 - binary_accuracy: 0.8578 - loss: 0.3449 - precision: 0.8276 - recall: 0.8428 - val_auc: 0.9115 - val_binary_accuracy: 0.8279 - val_loss: 0.3840 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 184/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9289 - binary_accuracy: 0.8586 - loss: 0.3442 - precision: 0.8291 - recall: 0.8428 - val_auc: 0.9117 - val_binary_accuracy: 0.8279 - val_loss: 0.3837 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 185/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9293 - binary_accuracy: 0.8594 - loss: 0.3429 - precision: 0.8306 - recall: 0.8428 - val_auc: 0.9116 - val_binary_accuracy: 0.8279 - val_loss: 0.3835 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 186/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9292 - binary_accuracy: 0.8578 - loss: 0.3431 - precision: 0.8273 - recall: 0.8425 - val_auc: 0.9116 - val_binary_accuracy: 0.8279 - val_loss: 0.3831 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 187/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9291 - binary_accuracy: 0.8578 - loss: 0.3431 - precision: 0.8273 - recall: 0.8425 - val_auc: 0.9118 - val_binary_accuracy: 0.8279 - val_loss: 0.3828 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 188/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9296 - binary_accuracy: 0.8578 - loss: 0.3418 - precision: 0.8273 - recall: 0.8425 - val_auc: 0.9118 - val_binary_accuracy: 0.8279 - val_loss: 0.3826 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 189/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9297 - binary_accuracy: 0.8586 - loss: 0.3419 - precision: 0.8280 - recall: 0.8446 - val_auc: 0.9119 - val_binary_accuracy: 0.8279 - val_loss: 0.3823 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 190/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9294 - binary_accuracy: 0.8578 - loss: 0.3419 - precision: 0.8255 - recall: 0.8438 - val_auc: 0.9120 - val_binary_accuracy: 0.8279 - val_loss: 0.3821 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 191/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9299 - binary_accuracy: 0.8586 - loss: 0.3412 - precision: 0.8268 - recall: 0.8464 - val_auc: 0.9121 - val_binary_accuracy: 0.8279 - val_loss: 0.3818 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 192/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9311 - binary_accuracy: 0.8602 - loss: 0.3382 - precision: 0.8297 - recall: 0.8464 - val_auc: 0.9121 - val_binary_accuracy: 0.8279 - val_loss: 0.3815 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 193/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9298 - binary_accuracy: 0.8578 - loss: 0.3411 - precision: 0.8268 - recall: 0.8449 - val_auc: 0.9122 - val_binary_accuracy: 0.8279 - val_loss: 0.3813 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 194/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9319 - binary_accuracy: 0.8602 - loss: 0.3366 - precision: 0.8315 - recall: 0.8452 - val_auc: 0.9123 - val_binary_accuracy: 0.8279 - val_loss: 0.3811 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 195/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9303 - binary_accuracy: 0.8586 - loss: 0.3394 - precision: 0.8283 - recall: 0.8449 - val_auc: 0.9125 - val_binary_accuracy: 0.8279 - val_loss: 0.3808 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 196/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9319 - binary_accuracy: 0.8594 - loss: 0.3361 - precision: 0.8273 - recall: 0.8456 - val_auc: 0.9124 - val_binary_accuracy: 0.8279 - val_loss: 0.3806 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 197/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9305 - binary_accuracy: 0.8578 - loss: 0.3389 - precision: 0.8265 - recall: 0.8446 - val_auc: 0.9125 - val_binary_accuracy: 0.8279 - val_loss: 0.3804 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 198/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9307 - binary_accuracy: 0.8586 - loss: 0.3380 - precision: 0.8294 - recall: 0.8431 - val_auc: 0.9127 - val_binary_accuracy: 0.8279 - val_loss: 0.3801 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 199/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9312 - binary_accuracy: 0.8602 - loss: 0.3369 - precision: 0.8315 - recall: 0.8452 - val_auc: 0.9130 - val_binary_accuracy: 0.8279 - val_loss: 0.3799 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 200/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9303 - binary_accuracy: 0.8578 - loss: 0.3388 - precision: 0.8268 - recall: 0.8449 - val_auc: 0.9130 - val_binary_accuracy: 0.8279 - val_loss: 0.3797 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 201/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9307 - binary_accuracy: 0.8586 - loss: 0.3375 - precision: 0.8259 - recall: 0.8456 - val_auc: 0.9130 - val_binary_accuracy: 0.8279 - val_loss: 0.3795 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 202/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9307 - binary_accuracy: 0.8578 - loss: 0.3376 - precision: 0.8268 - recall: 0.8449 - val_auc: 0.9131 - val_binary_accuracy: 0.8279 - val_loss: 0.3793 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 203/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9316 - binary_accuracy: 0.8594 - loss: 0.3357 - precision: 0.8276 - recall: 0.8459 - val_auc: 0.9132 - val_binary_accuracy: 0.8279 - val_loss: 0.3791 - val_precision: 0.7914 - val_recall: 0.8087 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 204/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9312 - binary_accuracy: 0.8594 - loss: 0.3362 - precision: 0.8276 - recall: 0.8459 - val_auc: 0.9133 - val_binary_accuracy: 0.8302 - val_loss: 0.3789 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 205/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9321 - binary_accuracy: 0.8594 - loss: 0.3344 - precision: 0.8291 - recall: 0.8443 - val_auc: 0.9133 - val_binary_accuracy: 0.8326 - val_loss: 0.3786 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 206/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9318 - binary_accuracy: 0.8594 - loss: 0.3352 - precision: 0.8286 - recall: 0.8467 - val_auc: 0.9133 - val_binary_accuracy: 0.8326 - val_loss: 0.3784 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 207/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9311 - binary_accuracy: 0.8578 - loss: 0.3363 - precision: 0.8262 - recall: 0.8443 - val_auc: 0.9135 - val_binary_accuracy: 0.8326 - val_loss: 0.3782 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 208/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9310 - binary_accuracy: 0.8578 - loss: 0.3360 - precision: 0.8265 - recall: 0.8446 - val_auc: 0.9136 - val_binary_accuracy: 0.8326 - val_loss: 0.3781 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 209/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9311 - binary_accuracy: 0.8578 - loss: 0.3358 - precision: 0.8259 - recall: 0.8440 - val_auc: 0.9134 - val_binary_accuracy: 0.8326 - val_loss: 0.3778 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 210/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9311 - binary_accuracy: 0.8570 - loss: 0.3355 - precision: 0.8247 - recall: 0.8443 - val_auc: 0.9136 - val_binary_accuracy: 0.8326 - val_loss: 0.3777 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 211/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9322 - binary_accuracy: 0.8586 - loss: 0.3331 - precision: 0.8280 - recall: 0.8446 - val_auc: 0.9137 - val_binary_accuracy: 0.8326 - val_loss: 0.3775 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 212/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9327 - binary_accuracy: 0.8586 - loss: 0.3321 - precision: 0.8265 - recall: 0.8462 - val_auc: 0.9137 - val_binary_accuracy: 0.8326 - val_loss: 0.3773 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 213/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9316 - binary_accuracy: 0.8586 - loss: 0.3343 - precision: 0.8276 - recall: 0.8443 - val_auc: 0.9137 - val_binary_accuracy: 0.8326 - val_loss: 0.3772 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 214/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9321 - binary_accuracy: 0.8586 - loss: 0.3331 - precision: 0.8276 - recall: 0.8443 - val_auc: 0.9138 - val_binary_accuracy: 0.8326 - val_loss: 0.3770 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 215/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9318 - binary_accuracy: 0.8594 - loss: 0.3338 - precision: 0.8301 - recall: 0.8452 - val_auc: 0.9141 - val_binary_accuracy: 0.8326 - val_loss: 0.3768 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 216/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9316 - binary_accuracy: 0.8586 - loss: 0.3340 - precision: 0.8276 - recall: 0.8443 - val_auc: 0.9140 - val_binary_accuracy: 0.8326 - val_loss: 0.3767 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 217/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9327 - binary_accuracy: 0.8594 - loss: 0.3314 - precision: 0.8276 - recall: 0.8459 - val_auc: 0.9140 - val_binary_accuracy: 0.8326 - val_loss: 0.3765 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 218/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9334 - binary_accuracy: 0.8609 - loss: 0.3303 - precision: 0.8312 - recall: 0.8464 - val_auc: 0.9142 - val_binary_accuracy: 0.8326 - val_loss: 0.3763 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 219/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9325 - binary_accuracy: 0.8594 - loss: 0.3320 - precision: 0.8301 - recall: 0.8452 - val_auc: 0.9142 - val_binary_accuracy: 0.8326 - val_loss: 0.3762 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 220/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9325 - binary_accuracy: 0.8594 - loss: 0.3321 - precision: 0.8304 - recall: 0.8455 - val_auc: 0.9142 - val_binary_accuracy: 0.8326 - val_loss: 0.3760 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 221/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9321 - binary_accuracy: 0.8586 - loss: 0.3326 - precision: 0.8276 - recall: 0.8443 - val_auc: 0.9142 - val_binary_accuracy: 0.8326 - val_loss: 0.3758 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 222/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9320 - binary_accuracy: 0.8586 - loss: 0.3329 - precision: 0.8283 - recall: 0.8449 - val_auc: 0.9144 - val_binary_accuracy: 0.8326 - val_loss: 0.3757 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 223/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9330 - binary_accuracy: 0.8602 - loss: 0.3307 - precision: 0.8289 - recall: 0.8485 - val_auc: 0.9144 - val_binary_accuracy: 0.8326 - val_loss: 0.3755 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 224/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9326 - binary_accuracy: 0.8602 - loss: 0.3313 - precision: 0.8294 - recall: 0.8462 - val_auc: 0.9144 - val_binary_accuracy: 0.8326 - val_loss: 0.3754 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 225/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9329 - binary_accuracy: 0.8602 - loss: 0.3304 - precision: 0.8291 - recall: 0.8459 - val_auc: 0.9147 - val_binary_accuracy: 0.8326 - val_loss: 0.3752 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 226/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9334 - binary_accuracy: 0.8602 - loss: 0.3296 - precision: 0.8297 - recall: 0.8464 - val_auc: 0.9149 - val_binary_accuracy: 0.8326 - val_loss: 0.3751 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 227/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9327 - binary_accuracy: 0.8594 - loss: 0.3310 - precision: 0.8265 - recall: 0.8477 - val_auc: 0.9149 - val_binary_accuracy: 0.8326 - val_loss: 0.3749 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 228/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9334 - binary_accuracy: 0.8609 - loss: 0.3293 - precision: 0.8301 - recall: 0.8483 - val_auc: 0.9148 - val_binary_accuracy: 0.8326 - val_loss: 0.3748 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 229/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9335 - binary_accuracy: 0.8602 - loss: 0.3293 - precision: 0.8274 - recall: 0.8501 - val_auc: 0.9149 - val_binary_accuracy: 0.8326 - val_loss: 0.3746 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 230/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9335 - binary_accuracy: 0.8594 - loss: 0.3292 - precision: 0.8271 - recall: 0.8483 - val_auc: 0.9149 - val_binary_accuracy: 0.8326 - val_loss: 0.3745 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 231/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9330 - binary_accuracy: 0.8594 - loss: 0.3298 - precision: 0.8283 - recall: 0.8464 - val_auc: 0.9151 - val_binary_accuracy: 0.8326 - val_loss: 0.3743 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 232/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9329 - binary_accuracy: 0.8586 - loss: 0.3303 - precision: 0.8262 - recall: 0.8459 - val_auc: 0.9152 - val_binary_accuracy: 0.8326 - val_loss: 0.3742 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 233/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9335 - binary_accuracy: 0.8602 - loss: 0.3291 - precision: 0.8286 - recall: 0.8483 - val_auc: 0.9151 - val_binary_accuracy: 0.8326 - val_loss: 0.3741 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 234/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9334 - binary_accuracy: 0.8594 - loss: 0.3288 - precision: 0.8283 - recall: 0.8464 - val_auc: 0.9152 - val_binary_accuracy: 0.8326 - val_loss: 0.3739 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 235/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9338 - binary_accuracy: 0.8594 - loss: 0.3277 - precision: 0.8283 - recall: 0.8464 - val_auc: 0.9153 - val_binary_accuracy: 0.8326 - val_loss: 0.3738 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 236/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9327 - binary_accuracy: 0.8586 - loss: 0.3302 - precision: 0.8259 - recall: 0.8456 - val_auc: 0.9153 - val_binary_accuracy: 0.8326 - val_loss: 0.3737 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 237/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9332 - binary_accuracy: 0.8594 - loss: 0.3294 - precision: 0.8271 - recall: 0.8483 - val_auc: 0.9154 - val_binary_accuracy: 0.8326 - val_loss: 0.3735 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 238/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9331 - binary_accuracy: 0.8594 - loss: 0.3294 - precision: 0.8268 - recall: 0.8480 - val_auc: 0.9154 - val_binary_accuracy: 0.8326 - val_loss: 0.3734 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 239/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9334 - binary_accuracy: 0.8602 - loss: 0.3289 - precision: 0.8265 - recall: 0.8493 - val_auc: 0.9156 - val_binary_accuracy: 0.8326 - val_loss: 0.3733 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 240/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9340 - binary_accuracy: 0.8609 - loss: 0.3274 - precision: 0.8283 - recall: 0.8495 - val_auc: 0.9155 - val_binary_accuracy: 0.8326 - val_loss: 0.3732 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 241/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9337 - binary_accuracy: 0.8602 - loss: 0.3280 - precision: 0.8271 - recall: 0.8498 - val_auc: 0.9157 - val_binary_accuracy: 0.8326 - val_loss: 0.3731 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 242/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9344 - binary_accuracy: 0.8602 - loss: 0.3266 - precision: 0.8286 - recall: 0.8483 - val_auc: 0.9159 - val_binary_accuracy: 0.8326 - val_loss: 0.3729 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 243/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9336 - binary_accuracy: 0.8594 - loss: 0.3283 - precision: 0.8268 - recall: 0.8480 - val_auc: 0.9159 - val_binary_accuracy: 0.8326 - val_loss: 0.3728 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 244/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9337 - binary_accuracy: 0.8602 - loss: 0.3278 - precision: 0.8271 - recall: 0.8498 - val_auc: 0.9160 - val_binary_accuracy: 0.8326 - val_loss: 0.3726 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 245/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9350 - binary_accuracy: 0.8617 - loss: 0.3251 - precision: 0.8277 - recall: 0.8535 - val_auc: 0.9161 - val_binary_accuracy: 0.8349 - val_loss: 0.3725 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 246/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9336 - binary_accuracy: 0.8594 - loss: 0.3282 - precision: 0.8274 - recall: 0.8485 - val_auc: 0.9160 - val_binary_accuracy: 0.8349 - val_loss: 0.3723 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 247/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9351 - binary_accuracy: 0.8602 - loss: 0.3248 - precision: 0.8283 - recall: 0.8480 - val_auc: 0.9161 - val_binary_accuracy: 0.8349 - val_loss: 0.3722 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 248/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9344 - binary_accuracy: 0.8602 - loss: 0.3262 - precision: 0.8265 - recall: 0.8493 - val_auc: 0.9162 - val_binary_accuracy: 0.8349 - val_loss: 0.3721 - val_precision: 0.7947 - val_recall: 0.8251 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 249/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9345 - binary_accuracy: 0.8602 - loss: 0.3260 - precision: 0.8271 - recall: 0.8498 - val_auc: 0.9164 - val_binary_accuracy: 0.8326 - val_loss: 0.3719 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 250/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9341 - binary_accuracy: 0.8594 - loss: 0.3268 - precision: 0.8274 - recall: 0.8485 - val_auc: 0.9165 - val_binary_accuracy: 0.8326 - val_loss: 0.3718 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 251/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9342 - binary_accuracy: 0.8602 - loss: 0.3263 - precision: 0.8283 - recall: 0.8480 - val_auc: 0.9165 - val_binary_accuracy: 0.8326 - val_loss: 0.3716 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 252/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9337 - binary_accuracy: 0.8602 - loss: 0.3273 - precision: 0.8283 - recall: 0.8480 - val_auc: 0.9165 - val_binary_accuracy: 0.8302 - val_loss: 0.3715 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 253/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9343 - binary_accuracy: 0.8609 - loss: 0.3258 - precision: 0.8286 - recall: 0.8498 - val_auc: 0.9165 - val_binary_accuracy: 0.8302 - val_loss: 0.3714 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 254/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9345 - binary_accuracy: 0.8609 - loss: 0.3258 - precision: 0.8304 - recall: 0.8485 - val_auc: 0.9167 - val_binary_accuracy: 0.8302 - val_loss: 0.3712 - val_precision: 0.7926 - val_recall: 0.8142 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 255/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9341 - binary_accuracy: 0.8602 - loss: 0.3266 - precision: 0.8280 - recall: 0.8477 - val_auc: 0.9169 - val_binary_accuracy: 0.8326 - val_loss: 0.3711 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 256/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9372 - binary_accuracy: 0.8625 - loss: 0.3197 - precision: 0.8297 - recall: 0.8511 - val_auc: 0.9171 - val_binary_accuracy: 0.8326 - val_loss: 0.3710 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 257/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9350 - binary_accuracy: 0.8609 - loss: 0.3244 - precision: 0.8294 - recall: 0.8477 - val_auc: 0.9170 - val_binary_accuracy: 0.8326 - val_loss: 0.3709 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 258/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9345 - binary_accuracy: 0.8609 - loss: 0.3258 - precision: 0.8310 - recall: 0.8491 - val_auc: 0.9172 - val_binary_accuracy: 0.8326 - val_loss: 0.3707 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 259/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9348 - binary_accuracy: 0.8625 - loss: 0.3248 - precision: 0.8301 - recall: 0.8514 - val_auc: 0.9172 - val_binary_accuracy: 0.8326 - val_loss: 0.3706 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 260/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9358 - binary_accuracy: 0.8625 - loss: 0.3224 - precision: 0.8312 - recall: 0.8495 - val_auc: 0.9172 - val_binary_accuracy: 0.8326 - val_loss: 0.3705 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 261/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9346 - binary_accuracy: 0.8609 - loss: 0.3253 - precision: 0.8297 - recall: 0.8480 - val_auc: 0.9172 - val_binary_accuracy: 0.8326 - val_loss: 0.3704 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 262/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9346 - binary_accuracy: 0.8609 - loss: 0.3255 - precision: 0.8310 - recall: 0.8491 - val_auc: 0.9172 - val_binary_accuracy: 0.8326 - val_loss: 0.3702 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 263/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9356 - binary_accuracy: 0.8633 - loss: 0.3230 - precision: 0.8318 - recall: 0.8516 - val_auc: 0.9172 - val_binary_accuracy: 0.8326 - val_loss: 0.3701 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 264/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8625 - loss: 0.3237 - precision: 0.8312 - recall: 0.8495 - val_auc: 0.9172 - val_binary_accuracy: 0.8326 - val_loss: 0.3700 - val_precision: 0.7937 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 265/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9347 - binary_accuracy: 0.8617 - loss: 0.3251 - precision: 0.8301 - recall: 0.8498 - val_auc: 0.9172 - val_binary_accuracy: 0.8349 - val_loss: 0.3699 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 266/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9347 - binary_accuracy: 0.8625 - loss: 0.3250 - precision: 0.8318 - recall: 0.8501 - val_auc: 0.9174 - val_binary_accuracy: 0.8349 - val_loss: 0.3697 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 267/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9351 - binary_accuracy: 0.8633 - loss: 0.3245 - precision: 0.8324 - recall: 0.8522 - val_auc: 0.9174 - val_binary_accuracy: 0.8349 - val_loss: 0.3696 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 268/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8633 - loss: 0.3237 - precision: 0.8312 - recall: 0.8511 - val_auc: 0.9175 - val_binary_accuracy: 0.8349 - val_loss: 0.3695 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 269/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9356 - binary_accuracy: 0.8641 - loss: 0.3227 - precision: 0.8315 - recall: 0.8529 - val_auc: 0.9175 - val_binary_accuracy: 0.8349 - val_loss: 0.3694 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 270/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9349 - binary_accuracy: 0.8633 - loss: 0.3246 - precision: 0.8321 - recall: 0.8519 - val_auc: 0.9176 - val_binary_accuracy: 0.8349 - val_loss: 0.3693 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 271/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9365 - binary_accuracy: 0.8656 - loss: 0.3207 - precision: 0.8342 - recall: 0.8556 - val_auc: 0.9177 - val_binary_accuracy: 0.8349 - val_loss: 0.3692 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 272/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9358 - binary_accuracy: 0.8648 - loss: 0.3224 - precision: 0.8354 - recall: 0.8522 - val_auc: 0.9177 - val_binary_accuracy: 0.8349 - val_loss: 0.3691 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 273/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8633 - loss: 0.3240 - precision: 0.8330 - recall: 0.8527 - val_auc: 0.9178 - val_binary_accuracy: 0.8349 - val_loss: 0.3690 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 274/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9357 - binary_accuracy: 0.8656 - loss: 0.3226 - precision: 0.8336 - recall: 0.8550 - val_auc: 0.9178 - val_binary_accuracy: 0.8349 - val_loss: 0.3689 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 275/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8633 - loss: 0.3240 - precision: 0.8324 - recall: 0.8522 - val_auc: 0.9179 - val_binary_accuracy: 0.8349 - val_loss: 0.3688 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 276/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9352 - binary_accuracy: 0.8633 - loss: 0.3240 - precision: 0.8324 - recall: 0.8522 - val_auc: 0.9179 - val_binary_accuracy: 0.8349 - val_loss: 0.3687 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 277/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8641 - loss: 0.3220 - precision: 0.8339 - recall: 0.8522 - val_auc: 0.9179 - val_binary_accuracy: 0.8349 - val_loss: 0.3685 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 278/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9355 - binary_accuracy: 0.8641 - loss: 0.3225 - precision: 0.8330 - recall: 0.8514 - val_auc: 0.9179 - val_binary_accuracy: 0.8349 - val_loss: 0.3684 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 279/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9360 - binary_accuracy: 0.8641 - loss: 0.3216 - precision: 0.8321 - recall: 0.8535 - val_auc: 0.9181 - val_binary_accuracy: 0.8349 - val_loss: 0.3683 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 280/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9361 - binary_accuracy: 0.8656 - loss: 0.3215 - precision: 0.8354 - recall: 0.8537 - val_auc: 0.9182 - val_binary_accuracy: 0.8349 - val_loss: 0.3682 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 281/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8664 - loss: 0.3207 - precision: 0.8372 - recall: 0.8540 - val_auc: 0.9183 - val_binary_accuracy: 0.8349 - val_loss: 0.3681 - val_precision: 0.7979 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 282/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9356 - binary_accuracy: 0.8641 - loss: 0.3226 - precision: 0.8330 - recall: 0.8514 - val_auc: 0.9184 - val_binary_accuracy: 0.8372 - val_loss: 0.3679 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 283/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9357 - binary_accuracy: 0.8648 - loss: 0.3226 - precision: 0.8339 - recall: 0.8537 - val_auc: 0.9187 - val_binary_accuracy: 0.8372 - val_loss: 0.3678 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 284/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9362 - binary_accuracy: 0.8656 - loss: 0.3216 - precision: 0.8342 - recall: 0.8556 - val_auc: 0.9189 - val_binary_accuracy: 0.8372 - val_loss: 0.3677 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 285/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9356 - binary_accuracy: 0.8641 - loss: 0.3227 - precision: 0.8336 - recall: 0.8519 - val_auc: 0.9190 - val_binary_accuracy: 0.8372 - val_loss: 0.3676 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 286/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9362 - binary_accuracy: 0.8656 - loss: 0.3214 - precision: 0.8339 - recall: 0.8553 - val_auc: 0.9191 - val_binary_accuracy: 0.8372 - val_loss: 0.3674 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 287/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9359 - binary_accuracy: 0.8648 - loss: 0.3217 - precision: 0.8348 - recall: 0.8516 - val_auc: 0.9192 - val_binary_accuracy: 0.8372 - val_loss: 0.3673 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 288/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9361 - binary_accuracy: 0.8656 - loss: 0.3213 - precision: 0.8345 - recall: 0.8529 - val_auc: 0.9192 - val_binary_accuracy: 0.8372 - val_loss: 0.3672 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 289/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9361 - binary_accuracy: 0.8656 - loss: 0.3214 - precision: 0.8366 - recall: 0.8519 - val_auc: 0.9192 - val_binary_accuracy: 0.8372 - val_loss: 0.3670 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 290/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8664 - loss: 0.3207 - precision: 0.8357 - recall: 0.8556 - val_auc: 0.9193 - val_binary_accuracy: 0.8372 - val_loss: 0.3669 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 291/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9366 - binary_accuracy: 0.8664 - loss: 0.3199 - precision: 0.8372 - recall: 0.8540 - val_auc: 0.9193 - val_binary_accuracy: 0.8372 - val_loss: 0.3668 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 292/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9362 - binary_accuracy: 0.8656 - loss: 0.3214 - precision: 0.8354 - recall: 0.8537 - val_auc: 0.9195 - val_binary_accuracy: 0.8372 - val_loss: 0.3667 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 293/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8648 - loss: 0.3213 - precision: 0.8345 - recall: 0.8514 - val_auc: 0.9195 - val_binary_accuracy: 0.8372 - val_loss: 0.3666 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 294/300                                          \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9365 - binary_accuracy: 0.8656 - loss: 0.3206 - precision: 0.8372 - recall: 0.8525 - val_auc: 0.9196 - val_binary_accuracy: 0.8372 - val_loss: 0.3665 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 295/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8648 - loss: 0.3215 - precision: 0.8348 - recall: 0.8516 - val_auc: 0.9196 - val_binary_accuracy: 0.8372 - val_loss: 0.3663 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 296/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8648 - loss: 0.3216 - precision: 0.8348 - recall: 0.8516 - val_auc: 0.9196 - val_binary_accuracy: 0.8372 - val_loss: 0.3662 - val_precision: 0.8021 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 297/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9366 - binary_accuracy: 0.8656 - loss: 0.3202 - precision: 0.8366 - recall: 0.8519 - val_auc: 0.9197 - val_binary_accuracy: 0.8395 - val_loss: 0.3661 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 298/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8648 - loss: 0.3208 - precision: 0.8354 - recall: 0.8522 - val_auc: 0.9197 - val_binary_accuracy: 0.8395 - val_loss: 0.3661 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 299/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9376 - binary_accuracy: 0.8672 - loss: 0.3180 - precision: 0.8387 - recall: 0.8540 - val_auc: 0.9197 - val_binary_accuracy: 0.8395 - val_loss: 0.3659 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "Epoch 300/300                                          \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9366 - binary_accuracy: 0.8656 - loss: 0.3202 - precision: 0.8354 - recall: 0.8537 - val_auc: 0.9197 - val_binary_accuracy: 0.8395 - val_loss: 0.3658 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 2.5570e-05\n",
      "\n",
      "./plots/monumental-hen-706/learning_rate_vs_epoch.png  \n",
      "./plots/monumental-hen-706/auc_vs_epoch.png            \n",
      "./plots/monumental-hen-706/loss_vs_epoch.png           \n",
      "./plots/monumental-hen-706/binary_accuracy_vs_epoch.png\n",
      "./plots/monumental-hen-706/recall_vs_epoch.png         \n",
      "./plots/monumental-hen-706/precision_vs_epoch.png      \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 556ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n",
      "\n",
      " 75%|███████▌  | 15/20 [01:31<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
      "\n",
      " 75%|███████▌  | 15/20 [01:31<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11fb09f4817445896c9186a88a0523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 99/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step\n",
      "\u001b[1m 19/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m 37/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 75/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m288/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 28ms/step\n",
      "\u001b[1m 18/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 70/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m229/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 18/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m 41/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 67/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 76/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m196/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 76/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 98/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 47/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 71/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m259/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 76/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 75/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m259/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 76/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m101/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 76/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 48/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 75/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step\n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step\n",
      "\u001b[1m 19/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m 37/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 73/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m292/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step\n",
      "\u001b[1m 20/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m 39/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m288/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step\n",
      "\u001b[1m 22/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 48/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 74/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m101/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 49/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 72/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m101/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m259/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 40ms/step\n",
      "\u001b[1m 16/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step  \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m132/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 43/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 99/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 47/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 74/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step\n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m132/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m292/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 76/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 22/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 43/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 67/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 48/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 73/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "🏃 View run monumental-hen-706 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/366b856207914ef19880615b468045c6\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 80%|████████  | 16/20 [02:24<09:36, 144.24s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:38:25.747334: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:25.790045: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:25.831844: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:25.871884: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:25.911631: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:25.953174: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:25.994668: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.034591: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.074049: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.115010: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.158780: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.204149: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.250317: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.292231: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.333379: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:38:26.371921: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 4s - 50ms/step - auc: 0.1782 - binary_accuracy: 0.5547 - loss: 0.7672 - precision: 0.0769 - recall: 0.0036 - val_auc: 0.1951 - val_binary_accuracy: 0.5558 - val_loss: 0.7591 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.1924 - binary_accuracy: 0.5570 - loss: 0.7612 - precision: 0.0435 - recall: 0.0018 - val_auc: 0.2116 - val_binary_accuracy: 0.5605 - val_loss: 0.7542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2083 - binary_accuracy: 0.5594 - loss: 0.7561 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.2285 - val_binary_accuracy: 0.5605 - val_loss: 0.7495 - val_precision: 0.1250 - val_recall: 0.0055 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2224 - binary_accuracy: 0.5578 - loss: 0.7514 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.2483 - val_binary_accuracy: 0.5605 - val_loss: 0.7447 - val_precision: 0.1250 - val_recall: 0.0055 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.2429 - binary_accuracy: 0.5609 - loss: 0.7461 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.2702 - val_binary_accuracy: 0.5628 - val_loss: 0.7400 - val_precision: 0.1429 - val_recall: 0.0055 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2614 - binary_accuracy: 0.5609 - loss: 0.7417 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.2907 - val_binary_accuracy: 0.5605 - val_loss: 0.7354 - val_precision: 0.1250 - val_recall: 0.0055 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.2801 - binary_accuracy: 0.5641 - loss: 0.7371 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.3149 - val_binary_accuracy: 0.5605 - val_loss: 0.7307 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.3025 - binary_accuracy: 0.5664 - loss: 0.7322 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.3372 - val_binary_accuracy: 0.5628 - val_loss: 0.7260 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.3265 - binary_accuracy: 0.5688 - loss: 0.7270 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.3625 - val_binary_accuracy: 0.5651 - val_loss: 0.7213 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.3500 - binary_accuracy: 0.5695 - loss: 0.7220 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.3859 - val_binary_accuracy: 0.5698 - val_loss: 0.7165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.3783 - binary_accuracy: 0.5695 - loss: 0.7166 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4105 - val_binary_accuracy: 0.5721 - val_loss: 0.7116 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.4045 - binary_accuracy: 0.5688 - loss: 0.7118 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4379 - val_binary_accuracy: 0.5721 - val_loss: 0.7065 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.4299 - binary_accuracy: 0.5680 - loss: 0.7073 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4635 - val_binary_accuracy: 0.5721 - val_loss: 0.7016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.4604 - binary_accuracy: 0.5703 - loss: 0.7011 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4894 - val_binary_accuracy: 0.5744 - val_loss: 0.6964 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.4837 - binary_accuracy: 0.5727 - loss: 0.6962 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5167 - val_binary_accuracy: 0.5744 - val_loss: 0.6912 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5075 - binary_accuracy: 0.5711 - loss: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5414 - val_binary_accuracy: 0.5744 - val_loss: 0.6861 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.5298 - binary_accuracy: 0.5734 - loss: 0.6861 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5627 - val_binary_accuracy: 0.5744 - val_loss: 0.6811 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.5588 - binary_accuracy: 0.5750 - loss: 0.6801 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5835 - val_binary_accuracy: 0.5744 - val_loss: 0.6761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.5827 - binary_accuracy: 0.5734 - loss: 0.6755 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.6049 - val_binary_accuracy: 0.5744 - val_loss: 0.6712 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.6049 - binary_accuracy: 0.5727 - loss: 0.6707 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.6252 - val_binary_accuracy: 0.5744 - val_loss: 0.6664 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6257 - binary_accuracy: 0.5742 - loss: 0.6658 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.6453 - val_binary_accuracy: 0.5744 - val_loss: 0.6616 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6447 - binary_accuracy: 0.5734 - loss: 0.6608 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.6642 - val_binary_accuracy: 0.5744 - val_loss: 0.6569 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6612 - binary_accuracy: 0.5734 - loss: 0.6561 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.6812 - val_binary_accuracy: 0.5744 - val_loss: 0.6524 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6765 - binary_accuracy: 0.5719 - loss: 0.6522 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.6934 - val_binary_accuracy: 0.5744 - val_loss: 0.6479 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6939 - binary_accuracy: 0.5734 - loss: 0.6471 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7061 - val_binary_accuracy: 0.5744 - val_loss: 0.6435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7098 - binary_accuracy: 0.5711 - loss: 0.6424 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7246 - val_binary_accuracy: 0.5744 - val_loss: 0.6390 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7194 - binary_accuracy: 0.5734 - loss: 0.6381 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7364 - val_binary_accuracy: 0.5744 - val_loss: 0.6347 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7336 - binary_accuracy: 0.5734 - loss: 0.6337 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7490 - val_binary_accuracy: 0.5744 - val_loss: 0.6304 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7438 - binary_accuracy: 0.5727 - loss: 0.6296 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7596 - val_binary_accuracy: 0.5744 - val_loss: 0.6263 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7567 - binary_accuracy: 0.5719 - loss: 0.6245 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7719 - val_binary_accuracy: 0.5744 - val_loss: 0.6221 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7645 - binary_accuracy: 0.5703 - loss: 0.6211 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7826 - val_binary_accuracy: 0.5744 - val_loss: 0.6181 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7733 - binary_accuracy: 0.5719 - loss: 0.6167 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7922 - val_binary_accuracy: 0.5744 - val_loss: 0.6141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7817 - binary_accuracy: 0.5734 - loss: 0.6123 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7987 - val_binary_accuracy: 0.5744 - val_loss: 0.6102 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7875 - binary_accuracy: 0.5734 - loss: 0.6084 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.8039 - val_binary_accuracy: 0.5744 - val_loss: 0.6064 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.7937 - binary_accuracy: 0.5734 - loss: 0.6040 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.8129 - val_binary_accuracy: 0.5767 - val_loss: 0.6026 - val_precision: 1.0000 - val_recall: 0.0055 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7973 - binary_accuracy: 0.5875 - loss: 0.6007 - precision: 0.8276 - recall: 0.0439 - val_auc: 0.8157 - val_binary_accuracy: 0.5907 - val_loss: 0.5990 - val_precision: 1.0000 - val_recall: 0.0383 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8016 - binary_accuracy: 0.6086 - loss: 0.5957 - precision: 0.7683 - recall: 0.1156 - val_auc: 0.8213 - val_binary_accuracy: 0.5953 - val_loss: 0.5954 - val_precision: 0.7143 - val_recall: 0.0820 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8067 - binary_accuracy: 0.6187 - loss: 0.5932 - precision: 0.7500 - recall: 0.1642 - val_auc: 0.8257 - val_binary_accuracy: 0.6186 - val_loss: 0.5919 - val_precision: 0.7436 - val_recall: 0.1585 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8113 - binary_accuracy: 0.6234 - loss: 0.5888 - precision: 0.7059 - recall: 0.1982 - val_auc: 0.8290 - val_binary_accuracy: 0.6326 - val_loss: 0.5884 - val_precision: 0.7551 - val_recall: 0.2022 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8174 - binary_accuracy: 0.6320 - loss: 0.5852 - precision: 0.7059 - recall: 0.2409 - val_auc: 0.8304 - val_binary_accuracy: 0.6465 - val_loss: 0.5850 - val_precision: 0.7541 - val_recall: 0.2514 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8218 - binary_accuracy: 0.6414 - loss: 0.5815 - precision: 0.7101 - recall: 0.2692 - val_auc: 0.8365 - val_binary_accuracy: 0.6512 - val_loss: 0.5816 - val_precision: 0.7619 - val_recall: 0.2623 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8255 - binary_accuracy: 0.6477 - loss: 0.5783 - precision: 0.7017 - recall: 0.3053 - val_auc: 0.8387 - val_binary_accuracy: 0.6674 - val_loss: 0.5783 - val_precision: 0.7857 - val_recall: 0.3005 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8290 - binary_accuracy: 0.6562 - loss: 0.5747 - precision: 0.7087 - recall: 0.3297 - val_auc: 0.8428 - val_binary_accuracy: 0.6721 - val_loss: 0.5751 - val_precision: 0.7838 - val_recall: 0.3169 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8333 - binary_accuracy: 0.6625 - loss: 0.5710 - precision: 0.7176 - recall: 0.3443 - val_auc: 0.8471 - val_binary_accuracy: 0.6721 - val_loss: 0.5719 - val_precision: 0.7838 - val_recall: 0.3169 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8362 - binary_accuracy: 0.6656 - loss: 0.5683 - precision: 0.7262 - recall: 0.3492 - val_auc: 0.8478 - val_binary_accuracy: 0.6767 - val_loss: 0.5688 - val_precision: 0.7895 - val_recall: 0.3279 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8391 - binary_accuracy: 0.6672 - loss: 0.5650 - precision: 0.7239 - recall: 0.3553 - val_auc: 0.8532 - val_binary_accuracy: 0.6791 - val_loss: 0.5658 - val_precision: 0.7922 - val_recall: 0.3333 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8446 - binary_accuracy: 0.6766 - loss: 0.5614 - precision: 0.7428 - recall: 0.3741 - val_auc: 0.8589 - val_binary_accuracy: 0.6837 - val_loss: 0.5628 - val_precision: 0.7975 - val_recall: 0.3443 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8460 - binary_accuracy: 0.6812 - loss: 0.5587 - precision: 0.7430 - recall: 0.3864 - val_auc: 0.8591 - val_binary_accuracy: 0.6814 - val_loss: 0.5599 - val_precision: 0.7805 - val_recall: 0.3497 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8506 - binary_accuracy: 0.6828 - loss: 0.5548 - precision: 0.7405 - recall: 0.3927 - val_auc: 0.8581 - val_binary_accuracy: 0.6884 - val_loss: 0.5569 - val_precision: 0.7952 - val_recall: 0.3607 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8548 - binary_accuracy: 0.6859 - loss: 0.5516 - precision: 0.7449 - recall: 0.4011 - val_auc: 0.8624 - val_binary_accuracy: 0.6930 - val_loss: 0.5541 - val_precision: 0.8000 - val_recall: 0.3716 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8543 - binary_accuracy: 0.6906 - loss: 0.5488 - precision: 0.7475 - recall: 0.4128 - val_auc: 0.8662 - val_binary_accuracy: 0.7023 - val_loss: 0.5512 - val_precision: 0.8090 - val_recall: 0.3934 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8592 - binary_accuracy: 0.6938 - loss: 0.5460 - precision: 0.7541 - recall: 0.4205 - val_auc: 0.8684 - val_binary_accuracy: 0.7140 - val_loss: 0.5484 - val_precision: 0.8191 - val_recall: 0.4208 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8620 - binary_accuracy: 0.7000 - loss: 0.5434 - precision: 0.7613 - recall: 0.4322 - val_auc: 0.8716 - val_binary_accuracy: 0.7209 - val_loss: 0.5456 - val_precision: 0.8182 - val_recall: 0.4426 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8653 - binary_accuracy: 0.7031 - loss: 0.5400 - precision: 0.7618 - recall: 0.4442 - val_auc: 0.8736 - val_binary_accuracy: 0.7186 - val_loss: 0.5428 - val_precision: 0.7981 - val_recall: 0.4536 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8710 - binary_accuracy: 0.7063 - loss: 0.5367 - precision: 0.7638 - recall: 0.4544 - val_auc: 0.8751 - val_binary_accuracy: 0.7209 - val_loss: 0.5401 - val_precision: 0.8000 - val_recall: 0.4590 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8721 - binary_accuracy: 0.7141 - loss: 0.5342 - precision: 0.7688 - recall: 0.4697 - val_auc: 0.8788 - val_binary_accuracy: 0.7233 - val_loss: 0.5374 - val_precision: 0.7963 - val_recall: 0.4699 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8746 - binary_accuracy: 0.7188 - loss: 0.5315 - precision: 0.7701 - recall: 0.4891 - val_auc: 0.8804 - val_binary_accuracy: 0.7209 - val_loss: 0.5346 - val_precision: 0.7739 - val_recall: 0.4863 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8769 - binary_accuracy: 0.7234 - loss: 0.5281 - precision: 0.7675 - recall: 0.5028 - val_auc: 0.8841 - val_binary_accuracy: 0.7279 - val_loss: 0.5319 - val_precision: 0.7797 - val_recall: 0.5027 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8796 - binary_accuracy: 0.7297 - loss: 0.5248 - precision: 0.7684 - recall: 0.5193 - val_auc: 0.8850 - val_binary_accuracy: 0.7419 - val_loss: 0.5291 - val_precision: 0.7903 - val_recall: 0.5355 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8825 - binary_accuracy: 0.7422 - loss: 0.5231 - precision: 0.7809 - recall: 0.5529 - val_auc: 0.8881 - val_binary_accuracy: 0.7535 - val_loss: 0.5264 - val_precision: 0.7939 - val_recall: 0.5683 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8852 - binary_accuracy: 0.7531 - loss: 0.5210 - precision: 0.7891 - recall: 0.5792 - val_auc: 0.8897 - val_binary_accuracy: 0.7651 - val_loss: 0.5237 - val_precision: 0.7929 - val_recall: 0.6066 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8877 - binary_accuracy: 0.7664 - loss: 0.5169 - precision: 0.7929 - recall: 0.6110 - val_auc: 0.8901 - val_binary_accuracy: 0.7674 - val_loss: 0.5210 - val_precision: 0.7862 - val_recall: 0.6230 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8902 - binary_accuracy: 0.7773 - loss: 0.5138 - precision: 0.8009 - recall: 0.6349 - val_auc: 0.8943 - val_binary_accuracy: 0.7698 - val_loss: 0.5183 - val_precision: 0.7800 - val_recall: 0.6393 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8952 - binary_accuracy: 0.7852 - loss: 0.5102 - precision: 0.8036 - recall: 0.6581 - val_auc: 0.8959 - val_binary_accuracy: 0.7837 - val_loss: 0.5155 - val_precision: 0.7922 - val_recall: 0.6667 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8955 - binary_accuracy: 0.7969 - loss: 0.5079 - precision: 0.8082 - recall: 0.6868 - val_auc: 0.8977 - val_binary_accuracy: 0.8000 - val_loss: 0.5128 - val_precision: 0.8012 - val_recall: 0.7049 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8977 - binary_accuracy: 0.8062 - loss: 0.5050 - precision: 0.8109 - recall: 0.7096 - val_auc: 0.8998 - val_binary_accuracy: 0.8093 - val_loss: 0.5102 - val_precision: 0.8061 - val_recall: 0.7268 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8996 - binary_accuracy: 0.8125 - loss: 0.5022 - precision: 0.8081 - recall: 0.7339 - val_auc: 0.9010 - val_binary_accuracy: 0.8093 - val_loss: 0.5075 - val_precision: 0.7988 - val_recall: 0.7377 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9027 - binary_accuracy: 0.8242 - loss: 0.4998 - precision: 0.8157 - recall: 0.7605 - val_auc: 0.9042 - val_binary_accuracy: 0.8163 - val_loss: 0.5047 - val_precision: 0.8023 - val_recall: 0.7541 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9040 - binary_accuracy: 0.8242 - loss: 0.4969 - precision: 0.8104 - recall: 0.7674 - val_auc: 0.9054 - val_binary_accuracy: 0.8140 - val_loss: 0.5020 - val_precision: 0.7977 - val_recall: 0.7541 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9066 - binary_accuracy: 0.8289 - loss: 0.4933 - precision: 0.8133 - recall: 0.7792 - val_auc: 0.9077 - val_binary_accuracy: 0.8186 - val_loss: 0.4993 - val_precision: 0.7966 - val_recall: 0.7705 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9079 - binary_accuracy: 0.8313 - loss: 0.4910 - precision: 0.8132 - recall: 0.7865 - val_auc: 0.9088 - val_binary_accuracy: 0.8326 - val_loss: 0.4966 - val_precision: 0.8033 - val_recall: 0.8033 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9095 - binary_accuracy: 0.8352 - loss: 0.4884 - precision: 0.8141 - recall: 0.7978 - val_auc: 0.9107 - val_binary_accuracy: 0.8349 - val_loss: 0.4939 - val_precision: 0.8043 - val_recall: 0.8087 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9124 - binary_accuracy: 0.8391 - loss: 0.4831 - precision: 0.8118 - recall: 0.8088 - val_auc: 0.9121 - val_binary_accuracy: 0.8372 - val_loss: 0.4912 - val_precision: 0.8054 - val_recall: 0.8142 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9121 - binary_accuracy: 0.8398 - loss: 0.4817 - precision: 0.8128 - recall: 0.8114 - val_auc: 0.9134 - val_binary_accuracy: 0.8372 - val_loss: 0.4886 - val_precision: 0.8054 - val_recall: 0.8142 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9138 - binary_accuracy: 0.8422 - loss: 0.4788 - precision: 0.8162 - recall: 0.8132 - val_auc: 0.9149 - val_binary_accuracy: 0.8395 - val_loss: 0.4859 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9164 - binary_accuracy: 0.8453 - loss: 0.4751 - precision: 0.8170 - recall: 0.8230 - val_auc: 0.9166 - val_binary_accuracy: 0.8395 - val_loss: 0.4833 - val_precision: 0.8065 - val_recall: 0.8197 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9171 - binary_accuracy: 0.8477 - loss: 0.4732 - precision: 0.8188 - recall: 0.8263 - val_auc: 0.9164 - val_binary_accuracy: 0.8419 - val_loss: 0.4806 - val_precision: 0.8108 - val_recall: 0.8197 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9192 - binary_accuracy: 0.8477 - loss: 0.4693 - precision: 0.8174 - recall: 0.8278 - val_auc: 0.9173 - val_binary_accuracy: 0.8465 - val_loss: 0.4780 - val_precision: 0.8128 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9198 - binary_accuracy: 0.8492 - loss: 0.4669 - precision: 0.8207 - recall: 0.8282 - val_auc: 0.9183 - val_binary_accuracy: 0.8442 - val_loss: 0.4753 - val_precision: 0.8085 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9211 - binary_accuracy: 0.8523 - loss: 0.4646 - precision: 0.8226 - recall: 0.8361 - val_auc: 0.9196 - val_binary_accuracy: 0.8465 - val_loss: 0.4728 - val_precision: 0.8095 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 6ms/step - auc: 0.9217 - binary_accuracy: 0.8516 - loss: 0.4613 - precision: 0.8190 - recall: 0.8370 - val_auc: 0.9200 - val_binary_accuracy: 0.8465 - val_loss: 0.4703 - val_precision: 0.8095 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9227 - binary_accuracy: 0.8531 - loss: 0.4581 - precision: 0.8200 - recall: 0.8410 - val_auc: 0.9209 - val_binary_accuracy: 0.8465 - val_loss: 0.4677 - val_precision: 0.8095 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9230 - binary_accuracy: 0.8539 - loss: 0.4555 - precision: 0.8208 - recall: 0.8404 - val_auc: 0.9212 - val_binary_accuracy: 0.8535 - val_loss: 0.4652 - val_precision: 0.8125 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9234 - binary_accuracy: 0.8523 - loss: 0.4539 - precision: 0.8185 - recall: 0.8410 - val_auc: 0.9222 - val_binary_accuracy: 0.8535 - val_loss: 0.4628 - val_precision: 0.8125 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9244 - binary_accuracy: 0.8539 - loss: 0.4507 - precision: 0.8203 - recall: 0.8428 - val_auc: 0.9222 - val_binary_accuracy: 0.8558 - val_loss: 0.4603 - val_precision: 0.8135 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 86/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9255 - binary_accuracy: 0.8562 - loss: 0.4468 - precision: 0.8203 - recall: 0.8474 - val_auc: 0.9229 - val_binary_accuracy: 0.8558 - val_loss: 0.4579 - val_precision: 0.8135 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 87/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9254 - binary_accuracy: 0.8547 - loss: 0.4460 - precision: 0.8198 - recall: 0.8467 - val_auc: 0.9239 - val_binary_accuracy: 0.8558 - val_loss: 0.4554 - val_precision: 0.8135 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 88/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9266 - binary_accuracy: 0.8555 - loss: 0.4429 - precision: 0.8212 - recall: 0.8467 - val_auc: 0.9241 - val_binary_accuracy: 0.8581 - val_loss: 0.4530 - val_precision: 0.8144 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 89/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9266 - binary_accuracy: 0.8547 - loss: 0.4402 - precision: 0.8180 - recall: 0.8480 - val_auc: 0.9247 - val_binary_accuracy: 0.8581 - val_loss: 0.4507 - val_precision: 0.8144 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 90/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9284 - binary_accuracy: 0.8570 - loss: 0.4369 - precision: 0.8222 - recall: 0.8506 - val_auc: 0.9254 - val_binary_accuracy: 0.8581 - val_loss: 0.4484 - val_precision: 0.8144 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 91/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9294 - binary_accuracy: 0.8570 - loss: 0.4333 - precision: 0.8201 - recall: 0.8516 - val_auc: 0.9246 - val_binary_accuracy: 0.8558 - val_loss: 0.4461 - val_precision: 0.8103 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 92/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9285 - binary_accuracy: 0.8562 - loss: 0.4321 - precision: 0.8182 - recall: 0.8540 - val_auc: 0.9254 - val_binary_accuracy: 0.8558 - val_loss: 0.4438 - val_precision: 0.8103 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 93/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9294 - binary_accuracy: 0.8555 - loss: 0.4295 - precision: 0.8179 - recall: 0.8522 - val_auc: 0.9262 - val_binary_accuracy: 0.8558 - val_loss: 0.4415 - val_precision: 0.8103 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 94/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9300 - binary_accuracy: 0.8570 - loss: 0.4262 - precision: 0.8182 - recall: 0.8556 - val_auc: 0.9265 - val_binary_accuracy: 0.8558 - val_loss: 0.4392 - val_precision: 0.8103 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 95/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9295 - binary_accuracy: 0.8555 - loss: 0.4242 - precision: 0.8175 - recall: 0.8519 - val_auc: 0.9270 - val_binary_accuracy: 0.8558 - val_loss: 0.4370 - val_precision: 0.8103 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 96/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9305 - binary_accuracy: 0.8562 - loss: 0.4212 - precision: 0.8168 - recall: 0.8556 - val_auc: 0.9272 - val_binary_accuracy: 0.8581 - val_loss: 0.4348 - val_precision: 0.8112 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 97/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9304 - binary_accuracy: 0.8570 - loss: 0.4200 - precision: 0.8182 - recall: 0.8556 - val_auc: 0.9275 - val_binary_accuracy: 0.8605 - val_loss: 0.4327 - val_precision: 0.8154 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 98/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9305 - binary_accuracy: 0.8562 - loss: 0.4173 - precision: 0.8164 - recall: 0.8553 - val_auc: 0.9276 - val_binary_accuracy: 0.8605 - val_loss: 0.4305 - val_precision: 0.8154 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 99/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9314 - binary_accuracy: 0.8578 - loss: 0.4145 - precision: 0.8174 - recall: 0.8592 - val_auc: 0.9282 - val_binary_accuracy: 0.8605 - val_loss: 0.4284 - val_precision: 0.8154 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 100/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9323 - binary_accuracy: 0.8578 - loss: 0.4121 - precision: 0.8174 - recall: 0.8592 - val_auc: 0.9284 - val_binary_accuracy: 0.8605 - val_loss: 0.4264 - val_precision: 0.8154 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 101/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9322 - binary_accuracy: 0.8586 - loss: 0.4094 - precision: 0.8185 - recall: 0.8590 - val_auc: 0.9282 - val_binary_accuracy: 0.8605 - val_loss: 0.4244 - val_precision: 0.8154 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 102/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9323 - binary_accuracy: 0.8578 - loss: 0.4074 - precision: 0.8174 - recall: 0.8592 - val_auc: 0.9286 - val_binary_accuracy: 0.8605 - val_loss: 0.4224 - val_precision: 0.8154 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 103/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9329 - binary_accuracy: 0.8578 - loss: 0.4059 - precision: 0.8191 - recall: 0.8579 - val_auc: 0.9288 - val_binary_accuracy: 0.8605 - val_loss: 0.4205 - val_precision: 0.8154 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 104/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9335 - binary_accuracy: 0.8594 - loss: 0.4022 - precision: 0.8191 - recall: 0.8611 - val_auc: 0.9288 - val_binary_accuracy: 0.8581 - val_loss: 0.4186 - val_precision: 0.8112 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 105/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9327 - binary_accuracy: 0.8578 - loss: 0.4018 - precision: 0.8183 - recall: 0.8600 - val_auc: 0.9288 - val_binary_accuracy: 0.8581 - val_loss: 0.4168 - val_precision: 0.8112 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 106/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9326 - binary_accuracy: 0.8586 - loss: 0.3992 - precision: 0.8185 - recall: 0.8590 - val_auc: 0.9294 - val_binary_accuracy: 0.8581 - val_loss: 0.4150 - val_precision: 0.8112 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 107/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9328 - binary_accuracy: 0.8594 - loss: 0.3976 - precision: 0.8202 - recall: 0.8592 - val_auc: 0.9289 - val_binary_accuracy: 0.8581 - val_loss: 0.4132 - val_precision: 0.8112 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 108/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9337 - binary_accuracy: 0.8602 - loss: 0.3943 - precision: 0.8202 - recall: 0.8608 - val_auc: 0.9290 - val_binary_accuracy: 0.8581 - val_loss: 0.4115 - val_precision: 0.8112 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 109/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9333 - binary_accuracy: 0.8586 - loss: 0.3933 - precision: 0.8188 - recall: 0.8592 - val_auc: 0.9295 - val_binary_accuracy: 0.8558 - val_loss: 0.4098 - val_precision: 0.8071 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 110/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9333 - binary_accuracy: 0.8594 - loss: 0.3920 - precision: 0.8209 - recall: 0.8597 - val_auc: 0.9296 - val_binary_accuracy: 0.8558 - val_loss: 0.4082 - val_precision: 0.8071 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 111/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9347 - binary_accuracy: 0.8625 - loss: 0.3880 - precision: 0.8226 - recall: 0.8647 - val_auc: 0.9297 - val_binary_accuracy: 0.8535 - val_loss: 0.4065 - val_precision: 0.8030 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 112/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9338 - binary_accuracy: 0.8609 - loss: 0.3878 - precision: 0.8202 - recall: 0.8624 - val_auc: 0.9296 - val_binary_accuracy: 0.8535 - val_loss: 0.4049 - val_precision: 0.8030 - val_recall: 0.8689 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 113/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9348 - binary_accuracy: 0.8625 - loss: 0.3844 - precision: 0.8231 - recall: 0.8624 - val_auc: 0.9299 - val_binary_accuracy: 0.8512 - val_loss: 0.4034 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 114/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9350 - binary_accuracy: 0.8633 - loss: 0.3826 - precision: 0.8252 - recall: 0.8629 - val_auc: 0.9299 - val_binary_accuracy: 0.8512 - val_loss: 0.4019 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 115/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9350 - binary_accuracy: 0.8633 - loss: 0.3812 - precision: 0.8255 - recall: 0.8631 - val_auc: 0.9300 - val_binary_accuracy: 0.8512 - val_loss: 0.4004 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 116/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9361 - binary_accuracy: 0.8633 - loss: 0.3783 - precision: 0.8243 - recall: 0.8650 - val_auc: 0.9300 - val_binary_accuracy: 0.8512 - val_loss: 0.3989 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 117/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9349 - binary_accuracy: 0.8617 - loss: 0.3784 - precision: 0.8240 - recall: 0.8616 - val_auc: 0.9298 - val_binary_accuracy: 0.8512 - val_loss: 0.3975 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 118/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9349 - binary_accuracy: 0.8625 - loss: 0.3769 - precision: 0.8249 - recall: 0.8611 - val_auc: 0.9300 - val_binary_accuracy: 0.8512 - val_loss: 0.3961 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 119/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9353 - binary_accuracy: 0.8617 - loss: 0.3755 - precision: 0.8234 - recall: 0.8611 - val_auc: 0.9300 - val_binary_accuracy: 0.8512 - val_loss: 0.3947 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 120/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9355 - binary_accuracy: 0.8617 - loss: 0.3729 - precision: 0.8220 - recall: 0.8626 - val_auc: 0.9301 - val_binary_accuracy: 0.8512 - val_loss: 0.3934 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 121/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9368 - binary_accuracy: 0.8633 - loss: 0.3698 - precision: 0.8246 - recall: 0.8624 - val_auc: 0.9303 - val_binary_accuracy: 0.8512 - val_loss: 0.3921 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 122/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9357 - binary_accuracy: 0.8633 - loss: 0.3701 - precision: 0.8246 - recall: 0.8624 - val_auc: 0.9300 - val_binary_accuracy: 0.8512 - val_loss: 0.3909 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 123/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9353 - binary_accuracy: 0.8625 - loss: 0.3702 - precision: 0.8252 - recall: 0.8613 - val_auc: 0.9304 - val_binary_accuracy: 0.8512 - val_loss: 0.3896 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 124/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9359 - binary_accuracy: 0.8625 - loss: 0.3678 - precision: 0.8246 - recall: 0.8608 - val_auc: 0.9302 - val_binary_accuracy: 0.8512 - val_loss: 0.3884 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 125/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9357 - binary_accuracy: 0.8625 - loss: 0.3671 - precision: 0.8252 - recall: 0.8613 - val_auc: 0.9306 - val_binary_accuracy: 0.8512 - val_loss: 0.3873 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 126/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9378 - binary_accuracy: 0.8656 - loss: 0.3615 - precision: 0.8266 - recall: 0.8661 - val_auc: 0.9305 - val_binary_accuracy: 0.8488 - val_loss: 0.3861 - val_precision: 0.7980 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 127/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9372 - binary_accuracy: 0.8656 - loss: 0.3615 - precision: 0.8266 - recall: 0.8661 - val_auc: 0.9305 - val_binary_accuracy: 0.8488 - val_loss: 0.3850 - val_precision: 0.7980 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 128/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9363 - binary_accuracy: 0.8641 - loss: 0.3624 - precision: 0.8249 - recall: 0.8642 - val_auc: 0.9306 - val_binary_accuracy: 0.8488 - val_loss: 0.3839 - val_precision: 0.7980 - val_recall: 0.8634 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 129/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9361 - binary_accuracy: 0.8633 - loss: 0.3617 - precision: 0.8249 - recall: 0.8626 - val_auc: 0.9305 - val_binary_accuracy: 0.8465 - val_loss: 0.3829 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 130/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8648 - loss: 0.3606 - precision: 0.8264 - recall: 0.8670 - val_auc: 0.9309 - val_binary_accuracy: 0.8465 - val_loss: 0.3819 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 131/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9375 - binary_accuracy: 0.8672 - loss: 0.3577 - precision: 0.8287 - recall: 0.8681 - val_auc: 0.9307 - val_binary_accuracy: 0.8465 - val_loss: 0.3809 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 132/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9368 - binary_accuracy: 0.8656 - loss: 0.3569 - precision: 0.8266 - recall: 0.8661 - val_auc: 0.9309 - val_binary_accuracy: 0.8465 - val_loss: 0.3800 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 133/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9365 - binary_accuracy: 0.8656 - loss: 0.3571 - precision: 0.8275 - recall: 0.8668 - val_auc: 0.9305 - val_binary_accuracy: 0.8465 - val_loss: 0.3791 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 134/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9373 - binary_accuracy: 0.8664 - loss: 0.3542 - precision: 0.8284 - recall: 0.8663 - val_auc: 0.9309 - val_binary_accuracy: 0.8465 - val_loss: 0.3782 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 135/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9373 - binary_accuracy: 0.8664 - loss: 0.3538 - precision: 0.8275 - recall: 0.8684 - val_auc: 0.9308 - val_binary_accuracy: 0.8465 - val_loss: 0.3774 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 136/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9374 - binary_accuracy: 0.8656 - loss: 0.3524 - precision: 0.8272 - recall: 0.8665 - val_auc: 0.9308 - val_binary_accuracy: 0.8465 - val_loss: 0.3765 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 137/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8672 - loss: 0.3506 - precision: 0.8287 - recall: 0.8681 - val_auc: 0.9308 - val_binary_accuracy: 0.8465 - val_loss: 0.3757 - val_precision: 0.7970 - val_recall: 0.8579 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 138/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8672 - loss: 0.3468 - precision: 0.8284 - recall: 0.8679 - val_auc: 0.9307 - val_binary_accuracy: 0.8419 - val_loss: 0.3749 - val_precision: 0.7919 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 139/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8672 - loss: 0.3493 - precision: 0.8275 - recall: 0.8700 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3742 - val_precision: 0.7919 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 140/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8672 - loss: 0.3481 - precision: 0.8284 - recall: 0.8679 - val_auc: 0.9309 - val_binary_accuracy: 0.8419 - val_loss: 0.3734 - val_precision: 0.7919 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 141/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8664 - loss: 0.3472 - precision: 0.8275 - recall: 0.8684 - val_auc: 0.9307 - val_binary_accuracy: 0.8419 - val_loss: 0.3727 - val_precision: 0.7919 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 142/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8664 - loss: 0.3466 - precision: 0.8264 - recall: 0.8702 - val_auc: 0.9309 - val_binary_accuracy: 0.8419 - val_loss: 0.3720 - val_precision: 0.7919 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 143/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9376 - binary_accuracy: 0.8656 - loss: 0.3470 - precision: 0.8261 - recall: 0.8684 - val_auc: 0.9310 - val_binary_accuracy: 0.8419 - val_loss: 0.3714 - val_precision: 0.7919 - val_recall: 0.8525 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 144/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9381 - binary_accuracy: 0.8664 - loss: 0.3447 - precision: 0.8278 - recall: 0.8686 - val_auc: 0.9309 - val_binary_accuracy: 0.8395 - val_loss: 0.3708 - val_precision: 0.7908 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 145/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8656 - loss: 0.3445 - precision: 0.8275 - recall: 0.8668 - val_auc: 0.9311 - val_binary_accuracy: 0.8372 - val_loss: 0.3701 - val_precision: 0.7868 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 146/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9386 - binary_accuracy: 0.8672 - loss: 0.3422 - precision: 0.8293 - recall: 0.8686 - val_auc: 0.9311 - val_binary_accuracy: 0.8372 - val_loss: 0.3695 - val_precision: 0.7868 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 147/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8648 - loss: 0.3429 - precision: 0.8252 - recall: 0.8661 - val_auc: 0.9309 - val_binary_accuracy: 0.8372 - val_loss: 0.3690 - val_precision: 0.7868 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 148/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8664 - loss: 0.3404 - precision: 0.8298 - recall: 0.8647 - val_auc: 0.9310 - val_binary_accuracy: 0.8372 - val_loss: 0.3684 - val_precision: 0.7868 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 149/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8656 - loss: 0.3419 - precision: 0.8269 - recall: 0.8663 - val_auc: 0.9310 - val_binary_accuracy: 0.8395 - val_loss: 0.3678 - val_precision: 0.7908 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 150/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9385 - binary_accuracy: 0.8664 - loss: 0.3404 - precision: 0.8290 - recall: 0.8668 - val_auc: 0.9312 - val_binary_accuracy: 0.8419 - val_loss: 0.3673 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 151/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9381 - binary_accuracy: 0.8664 - loss: 0.3400 - precision: 0.8275 - recall: 0.8684 - val_auc: 0.9313 - val_binary_accuracy: 0.8419 - val_loss: 0.3668 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 152/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9390 - binary_accuracy: 0.8680 - loss: 0.3378 - precision: 0.8287 - recall: 0.8697 - val_auc: 0.9310 - val_binary_accuracy: 0.8419 - val_loss: 0.3664 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 153/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9384 - binary_accuracy: 0.8672 - loss: 0.3389 - precision: 0.8293 - recall: 0.8686 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3659 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 154/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8680 - loss: 0.3379 - precision: 0.8304 - recall: 0.8684 - val_auc: 0.9310 - val_binary_accuracy: 0.8419 - val_loss: 0.3654 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 155/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8687 - loss: 0.3358 - precision: 0.8290 - recall: 0.8716 - val_auc: 0.9312 - val_binary_accuracy: 0.8419 - val_loss: 0.3650 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 156/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9387 - binary_accuracy: 0.8680 - loss: 0.3364 - precision: 0.8307 - recall: 0.8686 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3646 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 157/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9389 - binary_accuracy: 0.8680 - loss: 0.3357 - precision: 0.8304 - recall: 0.8684 - val_auc: 0.9312 - val_binary_accuracy: 0.8419 - val_loss: 0.3642 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 158/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8687 - loss: 0.3346 - precision: 0.8310 - recall: 0.8704 - val_auc: 0.9310 - val_binary_accuracy: 0.8419 - val_loss: 0.3638 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 159/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8672 - loss: 0.3352 - precision: 0.8293 - recall: 0.8686 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3634 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 160/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9394 - binary_accuracy: 0.8680 - loss: 0.3335 - precision: 0.8290 - recall: 0.8700 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3631 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 161/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9397 - binary_accuracy: 0.8687 - loss: 0.3324 - precision: 0.8307 - recall: 0.8702 - val_auc: 0.9312 - val_binary_accuracy: 0.8419 - val_loss: 0.3627 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 162/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9389 - binary_accuracy: 0.8687 - loss: 0.3341 - precision: 0.8310 - recall: 0.8704 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3624 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 163/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8695 - loss: 0.3321 - precision: 0.8319 - recall: 0.8700 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3621 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 164/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9399 - binary_accuracy: 0.8687 - loss: 0.3304 - precision: 0.8295 - recall: 0.8692 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3618 - val_precision: 0.7949 - val_recall: 0.8470 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 165/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9405 - binary_accuracy: 0.8695 - loss: 0.3300 - precision: 0.8333 - recall: 0.8684 - val_auc: 0.9311 - val_binary_accuracy: 0.8395 - val_loss: 0.3615 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 166/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8680 - loss: 0.3318 - precision: 0.8307 - recall: 0.8686 - val_auc: 0.9313 - val_binary_accuracy: 0.8395 - val_loss: 0.3612 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 167/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9389 - binary_accuracy: 0.8672 - loss: 0.3314 - precision: 0.8278 - recall: 0.8674 - val_auc: 0.9314 - val_binary_accuracy: 0.8395 - val_loss: 0.3609 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 168/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8695 - loss: 0.3309 - precision: 0.8333 - recall: 0.8684 - val_auc: 0.9312 - val_binary_accuracy: 0.8395 - val_loss: 0.3607 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 169/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8687 - loss: 0.3303 - precision: 0.8319 - recall: 0.8684 - val_auc: 0.9314 - val_binary_accuracy: 0.8395 - val_loss: 0.3604 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 170/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8695 - loss: 0.3306 - precision: 0.8333 - recall: 0.8684 - val_auc: 0.9315 - val_binary_accuracy: 0.8395 - val_loss: 0.3601 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 171/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8695 - loss: 0.3303 - precision: 0.8336 - recall: 0.8686 - val_auc: 0.9314 - val_binary_accuracy: 0.8395 - val_loss: 0.3599 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 172/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9402 - binary_accuracy: 0.8703 - loss: 0.3281 - precision: 0.8348 - recall: 0.8684 - val_auc: 0.9314 - val_binary_accuracy: 0.8395 - val_loss: 0.3597 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 173/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8695 - loss: 0.3297 - precision: 0.8333 - recall: 0.8684 - val_auc: 0.9314 - val_binary_accuracy: 0.8395 - val_loss: 0.3595 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 174/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8695 - loss: 0.3291 - precision: 0.8333 - recall: 0.8684 - val_auc: 0.9315 - val_binary_accuracy: 0.8395 - val_loss: 0.3592 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 175/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9402 - binary_accuracy: 0.8703 - loss: 0.3270 - precision: 0.8336 - recall: 0.8702 - val_auc: 0.9312 - val_binary_accuracy: 0.8395 - val_loss: 0.3590 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 176/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9393 - binary_accuracy: 0.8695 - loss: 0.3285 - precision: 0.8327 - recall: 0.8679 - val_auc: 0.9312 - val_binary_accuracy: 0.8395 - val_loss: 0.3588 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 177/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9397 - binary_accuracy: 0.8695 - loss: 0.3275 - precision: 0.8342 - recall: 0.8663 - val_auc: 0.9314 - val_binary_accuracy: 0.8395 - val_loss: 0.3586 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 178/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9396 - binary_accuracy: 0.8687 - loss: 0.3275 - precision: 0.8333 - recall: 0.8668 - val_auc: 0.9314 - val_binary_accuracy: 0.8395 - val_loss: 0.3585 - val_precision: 0.7938 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 179/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8680 - loss: 0.3281 - precision: 0.8330 - recall: 0.8650 - val_auc: 0.9314 - val_binary_accuracy: 0.8419 - val_loss: 0.3583 - val_precision: 0.7979 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 180/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9397 - binary_accuracy: 0.8687 - loss: 0.3271 - precision: 0.8348 - recall: 0.8652 - val_auc: 0.9311 - val_binary_accuracy: 0.8419 - val_loss: 0.3581 - val_precision: 0.7979 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 181/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9410 - binary_accuracy: 0.8703 - loss: 0.3241 - precision: 0.8348 - recall: 0.8684 - val_auc: 0.9313 - val_binary_accuracy: 0.8419 - val_loss: 0.3579 - val_precision: 0.7979 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 182/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9396 - binary_accuracy: 0.8680 - loss: 0.3267 - precision: 0.8322 - recall: 0.8642 - val_auc: 0.9313 - val_binary_accuracy: 0.8419 - val_loss: 0.3578 - val_precision: 0.7979 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 183/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9398 - binary_accuracy: 0.8680 - loss: 0.3263 - precision: 0.8322 - recall: 0.8642 - val_auc: 0.9313 - val_binary_accuracy: 0.8419 - val_loss: 0.3576 - val_precision: 0.7979 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 184/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9399 - binary_accuracy: 0.8687 - loss: 0.3262 - precision: 0.8327 - recall: 0.8663 - val_auc: 0.9312 - val_binary_accuracy: 0.8442 - val_loss: 0.3574 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 185/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9397 - binary_accuracy: 0.8687 - loss: 0.3259 - precision: 0.8345 - recall: 0.8650 - val_auc: 0.9313 - val_binary_accuracy: 0.8442 - val_loss: 0.3573 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 186/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9407 - binary_accuracy: 0.8695 - loss: 0.3239 - precision: 0.8342 - recall: 0.8663 - val_auc: 0.9313 - val_binary_accuracy: 0.8442 - val_loss: 0.3571 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 187/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8680 - loss: 0.3259 - precision: 0.8322 - recall: 0.8642 - val_auc: 0.9312 - val_binary_accuracy: 0.8442 - val_loss: 0.3570 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 188/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9397 - binary_accuracy: 0.8687 - loss: 0.3255 - precision: 0.8342 - recall: 0.8647 - val_auc: 0.9312 - val_binary_accuracy: 0.8442 - val_loss: 0.3569 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 189/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9402 - binary_accuracy: 0.8695 - loss: 0.3243 - precision: 0.8360 - recall: 0.8650 - val_auc: 0.9312 - val_binary_accuracy: 0.8442 - val_loss: 0.3568 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 190/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9399 - binary_accuracy: 0.8687 - loss: 0.3249 - precision: 0.8342 - recall: 0.8647 - val_auc: 0.9312 - val_binary_accuracy: 0.8442 - val_loss: 0.3567 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 191/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8703 - loss: 0.3204 - precision: 0.8345 - recall: 0.8681 - val_auc: 0.9311 - val_binary_accuracy: 0.8442 - val_loss: 0.3565 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 192/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9402 - binary_accuracy: 0.8695 - loss: 0.3236 - precision: 0.8351 - recall: 0.8642 - val_auc: 0.9310 - val_binary_accuracy: 0.8442 - val_loss: 0.3564 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 193/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9399 - binary_accuracy: 0.8687 - loss: 0.3243 - precision: 0.8339 - recall: 0.8645 - val_auc: 0.9310 - val_binary_accuracy: 0.8442 - val_loss: 0.3563 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 194/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9403 - binary_accuracy: 0.8695 - loss: 0.3234 - precision: 0.8345 - recall: 0.8665 - val_auc: 0.9310 - val_binary_accuracy: 0.8442 - val_loss: 0.3562 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 195/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9400 - binary_accuracy: 0.8703 - loss: 0.3240 - precision: 0.8372 - recall: 0.8647 - val_auc: 0.9310 - val_binary_accuracy: 0.8442 - val_loss: 0.3562 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 196/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9405 - binary_accuracy: 0.8711 - loss: 0.3229 - precision: 0.8387 - recall: 0.8647 - val_auc: 0.9309 - val_binary_accuracy: 0.8442 - val_loss: 0.3560 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 197/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9408 - binary_accuracy: 0.8719 - loss: 0.3220 - precision: 0.8387 - recall: 0.8663 - val_auc: 0.9308 - val_binary_accuracy: 0.8442 - val_loss: 0.3559 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 198/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9406 - binary_accuracy: 0.8711 - loss: 0.3219 - precision: 0.8381 - recall: 0.8642 - val_auc: 0.9308 - val_binary_accuracy: 0.8442 - val_loss: 0.3559 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 199/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9406 - binary_accuracy: 0.8711 - loss: 0.3225 - precision: 0.8392 - recall: 0.8652 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3558 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 200/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8711 - loss: 0.3206 - precision: 0.8372 - recall: 0.8663 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3557 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 201/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9400 - binary_accuracy: 0.8703 - loss: 0.3232 - precision: 0.8366 - recall: 0.8642 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3556 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 202/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9403 - binary_accuracy: 0.8703 - loss: 0.3225 - precision: 0.8369 - recall: 0.8645 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3556 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 203/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9407 - binary_accuracy: 0.8703 - loss: 0.3215 - precision: 0.8372 - recall: 0.8647 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3555 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 204/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9409 - binary_accuracy: 0.8703 - loss: 0.3212 - precision: 0.8369 - recall: 0.8645 - val_auc: 0.9305 - val_binary_accuracy: 0.8442 - val_loss: 0.3554 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 205/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9403 - binary_accuracy: 0.8695 - loss: 0.3226 - precision: 0.8366 - recall: 0.8626 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3554 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 206/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9405 - binary_accuracy: 0.8695 - loss: 0.3224 - precision: 0.8375 - recall: 0.8634 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3553 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 207/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9405 - binary_accuracy: 0.8695 - loss: 0.3220 - precision: 0.8369 - recall: 0.8629 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3552 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 208/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9406 - binary_accuracy: 0.8695 - loss: 0.3213 - precision: 0.8366 - recall: 0.8626 - val_auc: 0.9305 - val_binary_accuracy: 0.8442 - val_loss: 0.3551 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 209/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9403 - binary_accuracy: 0.8695 - loss: 0.3219 - precision: 0.8360 - recall: 0.8621 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3550 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 210/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8711 - loss: 0.3209 - precision: 0.8392 - recall: 0.8652 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3550 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 211/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9404 - binary_accuracy: 0.8703 - loss: 0.3217 - precision: 0.8384 - recall: 0.8629 - val_auc: 0.9306 - val_binary_accuracy: 0.8442 - val_loss: 0.3549 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 212/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9416 - binary_accuracy: 0.8719 - loss: 0.3188 - precision: 0.8404 - recall: 0.8650 - val_auc: 0.9305 - val_binary_accuracy: 0.8442 - val_loss: 0.3548 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 213/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8711 - loss: 0.3201 - precision: 0.8387 - recall: 0.8647 - val_auc: 0.9307 - val_binary_accuracy: 0.8442 - val_loss: 0.3547 - val_precision: 0.8021 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 214/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9407 - binary_accuracy: 0.8711 - loss: 0.3205 - precision: 0.8384 - recall: 0.8645 - val_auc: 0.9306 - val_binary_accuracy: 0.8465 - val_loss: 0.3547 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 215/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8711 - loss: 0.3185 - precision: 0.8387 - recall: 0.8647 - val_auc: 0.9307 - val_binary_accuracy: 0.8465 - val_loss: 0.3546 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 216/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8711 - loss: 0.3207 - precision: 0.8389 - recall: 0.8650 - val_auc: 0.9307 - val_binary_accuracy: 0.8465 - val_loss: 0.3546 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 217/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8711 - loss: 0.3199 - precision: 0.8384 - recall: 0.8645 - val_auc: 0.9306 - val_binary_accuracy: 0.8465 - val_loss: 0.3545 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 218/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9405 - binary_accuracy: 0.8703 - loss: 0.3208 - precision: 0.8378 - recall: 0.8624 - val_auc: 0.9306 - val_binary_accuracy: 0.8465 - val_loss: 0.3544 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 219/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8711 - loss: 0.3188 - precision: 0.8396 - recall: 0.8626 - val_auc: 0.9306 - val_binary_accuracy: 0.8465 - val_loss: 0.3544 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 220/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8711 - loss: 0.3191 - precision: 0.8396 - recall: 0.8626 - val_auc: 0.9306 - val_binary_accuracy: 0.8465 - val_loss: 0.3543 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 221/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8719 - loss: 0.3182 - precision: 0.8408 - recall: 0.8624 - val_auc: 0.9305 - val_binary_accuracy: 0.8465 - val_loss: 0.3543 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 222/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8703 - loss: 0.3190 - precision: 0.8381 - recall: 0.8626 - val_auc: 0.9305 - val_binary_accuracy: 0.8465 - val_loss: 0.3542 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 223/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9408 - binary_accuracy: 0.8703 - loss: 0.3196 - precision: 0.8372 - recall: 0.8619 - val_auc: 0.9305 - val_binary_accuracy: 0.8465 - val_loss: 0.3542 - val_precision: 0.8063 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 224/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9410 - binary_accuracy: 0.8695 - loss: 0.3195 - precision: 0.8384 - recall: 0.8613 - val_auc: 0.9305 - val_binary_accuracy: 0.8488 - val_loss: 0.3541 - val_precision: 0.8105 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 225/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9407 - binary_accuracy: 0.8695 - loss: 0.3198 - precision: 0.8381 - recall: 0.8611 - val_auc: 0.9305 - val_binary_accuracy: 0.8488 - val_loss: 0.3540 - val_precision: 0.8105 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 226/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8703 - loss: 0.3191 - precision: 0.8399 - recall: 0.8613 - val_auc: 0.9305 - val_binary_accuracy: 0.8488 - val_loss: 0.3540 - val_precision: 0.8105 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 227/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8703 - loss: 0.3176 - precision: 0.8384 - recall: 0.8629 - val_auc: 0.9305 - val_binary_accuracy: 0.8488 - val_loss: 0.3539 - val_precision: 0.8105 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 228/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8711 - loss: 0.3166 - precision: 0.8384 - recall: 0.8645 - val_auc: 0.9305 - val_binary_accuracy: 0.8512 - val_loss: 0.3539 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 229/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8695 - loss: 0.3190 - precision: 0.8387 - recall: 0.8616 - val_auc: 0.9306 - val_binary_accuracy: 0.8512 - val_loss: 0.3538 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 230/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8703 - loss: 0.3175 - precision: 0.8390 - recall: 0.8606 - val_auc: 0.9304 - val_binary_accuracy: 0.8512 - val_loss: 0.3538 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 231/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9407 - binary_accuracy: 0.8695 - loss: 0.3197 - precision: 0.8384 - recall: 0.8613 - val_auc: 0.9305 - val_binary_accuracy: 0.8512 - val_loss: 0.3537 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 232/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8703 - loss: 0.3165 - precision: 0.8387 - recall: 0.8631 - val_auc: 0.9306 - val_binary_accuracy: 0.8512 - val_loss: 0.3537 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 233/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8719 - loss: 0.3166 - precision: 0.8396 - recall: 0.8642 - val_auc: 0.9306 - val_binary_accuracy: 0.8512 - val_loss: 0.3537 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 234/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8711 - loss: 0.3163 - precision: 0.8396 - recall: 0.8626 - val_auc: 0.9306 - val_binary_accuracy: 0.8512 - val_loss: 0.3536 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 235/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9419 - binary_accuracy: 0.8719 - loss: 0.3165 - precision: 0.8387 - recall: 0.8663 - val_auc: 0.9305 - val_binary_accuracy: 0.8512 - val_loss: 0.3536 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 236/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9412 - binary_accuracy: 0.8703 - loss: 0.3180 - precision: 0.8381 - recall: 0.8626 - val_auc: 0.9305 - val_binary_accuracy: 0.8488 - val_loss: 0.3535 - val_precision: 0.8138 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 237/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9411 - binary_accuracy: 0.8695 - loss: 0.3182 - precision: 0.8375 - recall: 0.8606 - val_auc: 0.9306 - val_binary_accuracy: 0.8488 - val_loss: 0.3535 - val_precision: 0.8138 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 238/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8703 - loss: 0.3163 - precision: 0.8399 - recall: 0.8613 - val_auc: 0.9306 - val_binary_accuracy: 0.8488 - val_loss: 0.3534 - val_precision: 0.8138 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 239/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8695 - loss: 0.3185 - precision: 0.8390 - recall: 0.8590 - val_auc: 0.9306 - val_binary_accuracy: 0.8488 - val_loss: 0.3534 - val_precision: 0.8138 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 240/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8703 - loss: 0.3155 - precision: 0.8393 - recall: 0.8608 - val_auc: 0.9306 - val_binary_accuracy: 0.8488 - val_loss: 0.3534 - val_precision: 0.8138 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 241/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8703 - loss: 0.3168 - precision: 0.8408 - recall: 0.8592 - val_auc: 0.9305 - val_binary_accuracy: 0.8512 - val_loss: 0.3533 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 242/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8703 - loss: 0.3154 - precision: 0.8396 - recall: 0.8611 - val_auc: 0.9304 - val_binary_accuracy: 0.8512 - val_loss: 0.3532 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 243/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8695 - loss: 0.3183 - precision: 0.8396 - recall: 0.8595 - val_auc: 0.9304 - val_binary_accuracy: 0.8512 - val_loss: 0.3532 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 244/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8703 - loss: 0.3171 - precision: 0.8402 - recall: 0.8587 - val_auc: 0.9305 - val_binary_accuracy: 0.8512 - val_loss: 0.3531 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 245/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8711 - loss: 0.3166 - precision: 0.8390 - recall: 0.8621 - val_auc: 0.9305 - val_binary_accuracy: 0.8512 - val_loss: 0.3531 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 246/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8703 - loss: 0.3157 - precision: 0.8390 - recall: 0.8606 - val_auc: 0.9306 - val_binary_accuracy: 0.8512 - val_loss: 0.3531 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 247/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8695 - loss: 0.3173 - precision: 0.8387 - recall: 0.8587 - val_auc: 0.9306 - val_binary_accuracy: 0.8512 - val_loss: 0.3530 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 248/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8687 - loss: 0.3176 - precision: 0.8393 - recall: 0.8577 - val_auc: 0.9307 - val_binary_accuracy: 0.8512 - val_loss: 0.3530 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 249/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8711 - loss: 0.3153 - precision: 0.8402 - recall: 0.8603 - val_auc: 0.9307 - val_binary_accuracy: 0.8512 - val_loss: 0.3529 - val_precision: 0.8182 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 250/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8687 - loss: 0.3175 - precision: 0.8393 - recall: 0.8577 - val_auc: 0.9306 - val_binary_accuracy: 0.8535 - val_loss: 0.3529 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 251/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8695 - loss: 0.3168 - precision: 0.8408 - recall: 0.8577 - val_auc: 0.9305 - val_binary_accuracy: 0.8535 - val_loss: 0.3529 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 252/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8695 - loss: 0.3163 - precision: 0.8393 - recall: 0.8592 - val_auc: 0.9306 - val_binary_accuracy: 0.8535 - val_loss: 0.3528 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 253/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8703 - loss: 0.3145 - precision: 0.8405 - recall: 0.8590 - val_auc: 0.9306 - val_binary_accuracy: 0.8535 - val_loss: 0.3528 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 254/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8695 - loss: 0.3168 - precision: 0.8402 - recall: 0.8571 - val_auc: 0.9306 - val_binary_accuracy: 0.8535 - val_loss: 0.3527 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 255/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8719 - loss: 0.3156 - precision: 0.8444 - recall: 0.8597 - val_auc: 0.9306 - val_binary_accuracy: 0.8535 - val_loss: 0.3527 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 256/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8695 - loss: 0.3167 - precision: 0.8408 - recall: 0.8577 - val_auc: 0.9306 - val_binary_accuracy: 0.8535 - val_loss: 0.3526 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 257/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8695 - loss: 0.3167 - precision: 0.8394 - recall: 0.8564 - val_auc: 0.9306 - val_binary_accuracy: 0.8535 - val_loss: 0.3526 - val_precision: 0.8226 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 258/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8703 - loss: 0.3164 - precision: 0.8405 - recall: 0.8590 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3526 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 259/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8703 - loss: 0.3159 - precision: 0.8408 - recall: 0.8592 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3525 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 260/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8719 - loss: 0.3148 - precision: 0.8429 - recall: 0.8613 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3525 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 261/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8703 - loss: 0.3143 - precision: 0.8399 - recall: 0.8585 - val_auc: 0.9306 - val_binary_accuracy: 0.8558 - val_loss: 0.3525 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 262/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8703 - loss: 0.3156 - precision: 0.8405 - recall: 0.8590 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3524 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 263/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8727 - loss: 0.3114 - precision: 0.8435 - recall: 0.8606 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3525 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 264/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8703 - loss: 0.3160 - precision: 0.8420 - recall: 0.8574 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3524 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 265/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9418 - binary_accuracy: 0.8719 - loss: 0.3155 - precision: 0.8450 - recall: 0.8574 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3524 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 266/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8727 - loss: 0.3146 - precision: 0.8466 - recall: 0.8574 - val_auc: 0.9306 - val_binary_accuracy: 0.8558 - val_loss: 0.3523 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 267/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8719 - loss: 0.3154 - precision: 0.8448 - recall: 0.8571 - val_auc: 0.9306 - val_binary_accuracy: 0.8558 - val_loss: 0.3523 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 268/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8719 - loss: 0.3152 - precision: 0.8453 - recall: 0.8577 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3522 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 269/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8711 - loss: 0.3161 - precision: 0.8438 - recall: 0.8577 - val_auc: 0.9306 - val_binary_accuracy: 0.8558 - val_loss: 0.3522 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 270/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8711 - loss: 0.3159 - precision: 0.8432 - recall: 0.8571 - val_auc: 0.9306 - val_binary_accuracy: 0.8558 - val_loss: 0.3522 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 271/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8719 - loss: 0.3148 - precision: 0.8453 - recall: 0.8577 - val_auc: 0.9307 - val_binary_accuracy: 0.8558 - val_loss: 0.3521 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 272/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8734 - loss: 0.3155 - precision: 0.8478 - recall: 0.8571 - val_auc: 0.9307 - val_binary_accuracy: 0.8558 - val_loss: 0.3521 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 273/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8727 - loss: 0.3158 - precision: 0.8463 - recall: 0.8571 - val_auc: 0.9307 - val_binary_accuracy: 0.8558 - val_loss: 0.3521 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 274/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8727 - loss: 0.3148 - precision: 0.8456 - recall: 0.8595 - val_auc: 0.9306 - val_binary_accuracy: 0.8558 - val_loss: 0.3520 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 275/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8734 - loss: 0.3153 - precision: 0.8466 - recall: 0.8590 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3520 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 276/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8750 - loss: 0.3142 - precision: 0.8502 - recall: 0.8595 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3520 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 277/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8742 - loss: 0.3151 - precision: 0.8499 - recall: 0.8577 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3519 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 278/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8750 - loss: 0.3149 - precision: 0.8517 - recall: 0.8579 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3519 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 279/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8750 - loss: 0.3158 - precision: 0.8514 - recall: 0.8577 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3518 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 280/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8766 - loss: 0.3126 - precision: 0.8527 - recall: 0.8590 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3518 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 281/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8750 - loss: 0.3151 - precision: 0.8501 - recall: 0.8564 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3518 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 282/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8758 - loss: 0.3147 - precision: 0.8527 - recall: 0.8574 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3518 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 283/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9429 - binary_accuracy: 0.8773 - loss: 0.3122 - precision: 0.8533 - recall: 0.8611 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3518 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 284/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9419 - binary_accuracy: 0.8758 - loss: 0.3148 - precision: 0.8530 - recall: 0.8577 - val_auc: 0.9305 - val_binary_accuracy: 0.8558 - val_loss: 0.3517 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 285/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8750 - loss: 0.3149 - precision: 0.8512 - recall: 0.8574 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3517 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 286/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8758 - loss: 0.3137 - precision: 0.8506 - recall: 0.8585 - val_auc: 0.9303 - val_binary_accuracy: 0.8558 - val_loss: 0.3517 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 287/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8758 - loss: 0.3116 - precision: 0.8504 - recall: 0.8582 - val_auc: 0.9303 - val_binary_accuracy: 0.8558 - val_loss: 0.3516 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 288/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8750 - loss: 0.3143 - precision: 0.8504 - recall: 0.8566 - val_auc: 0.9304 - val_binary_accuracy: 0.8558 - val_loss: 0.3516 - val_precision: 0.8270 - val_recall: 0.8361 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 289/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8758 - loss: 0.3146 - precision: 0.8527 - recall: 0.8574 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3516 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 290/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9418 - binary_accuracy: 0.8758 - loss: 0.3148 - precision: 0.8519 - recall: 0.8566 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3516 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 291/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9424 - binary_accuracy: 0.8773 - loss: 0.3131 - precision: 0.8543 - recall: 0.8590 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3515 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 292/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8766 - loss: 0.3138 - precision: 0.8527 - recall: 0.8590 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3515 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 293/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8766 - loss: 0.3132 - precision: 0.8540 - recall: 0.8571 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3515 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 294/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8758 - loss: 0.3145 - precision: 0.8525 - recall: 0.8571 - val_auc: 0.9305 - val_binary_accuracy: 0.8535 - val_loss: 0.3514 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 295/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9425 - binary_accuracy: 0.8766 - loss: 0.3131 - precision: 0.8540 - recall: 0.8571 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3514 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 296/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9426 - binary_accuracy: 0.8766 - loss: 0.3126 - precision: 0.8522 - recall: 0.8585 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3513 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 297/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9423 - binary_accuracy: 0.8758 - loss: 0.3137 - precision: 0.8527 - recall: 0.8574 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3513 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 298/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8758 - loss: 0.3145 - precision: 0.8535 - recall: 0.8582 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3513 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 299/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9421 - binary_accuracy: 0.8758 - loss: 0.3141 - precision: 0.8525 - recall: 0.8571 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3513 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "Epoch 300/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9422 - binary_accuracy: 0.8758 - loss: 0.3141 - precision: 0.8530 - recall: 0.8577 - val_auc: 0.9304 - val_binary_accuracy: 0.8535 - val_loss: 0.3512 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 4.0899e-05\n",
      "\n",
      "./plots/omniscient-deer-948/learning_rate_vs_epoch.png                            \n",
      "./plots/omniscient-deer-948/auc_vs_epoch.png                                      \n",
      "./plots/omniscient-deer-948/loss_vs_epoch.png                                     \n",
      "./plots/omniscient-deer-948/binary_accuracy_vs_epoch.png                          \n",
      "./plots/omniscient-deer-948/recall_vs_epoch.png                                   \n",
      "./plots/omniscient-deer-948/precision_vs_epoch.png                                \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 428ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step         \n",
      "\n",
      " 80%|████████  | 16/20 [03:53<09:36, 144.24s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step         \n",
      "\n",
      " 80%|████████  | 16/20 [03:54<09:36, 144.24s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ec1c43de824925adf75b2e2cf2a9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m196/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m196/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 47/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 73/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 22/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 42/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 16/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step        \n",
      "\u001b[1m 36/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 99/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step                \n",
      "\u001b[1m 19/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 38/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m101/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 21/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 42/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 46/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 68/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 22/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 44/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 20/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 38/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 66/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 98/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 64/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m196/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run omniscient-deer-948 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/8c55be382ad848618b6261b7e77c050b\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 85%|████████▌ | 17/20 [04:44<07:05, 141.89s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:40:46.043429: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.101056: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.157336: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.221763: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.274169: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.323728: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.375447: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.428346: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.485260: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.537624: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.590807: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.640534: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.695071: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.745298: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.792421: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:40:46.856332: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 5s - 58ms/step - auc: 0.4906 - binary_accuracy: 0.4437 - loss: 0.7847 - precision: 0.4325 - recall: 0.9580 - val_auc: 0.5197 - val_binary_accuracy: 0.4302 - val_loss: 0.7651 - val_precision: 0.4258 - val_recall: 0.9727 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.5608 - binary_accuracy: 0.4516 - loss: 0.7546 - precision: 0.4358 - recall: 0.9616 - val_auc: 0.5895 - val_binary_accuracy: 0.4395 - val_loss: 0.7373 - val_precision: 0.4296 - val_recall: 0.9672 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6263 - binary_accuracy: 0.4641 - loss: 0.7286 - precision: 0.4409 - recall: 0.9651 - val_auc: 0.6558 - val_binary_accuracy: 0.4535 - val_loss: 0.7120 - val_precision: 0.4360 - val_recall: 0.9672 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6875 - binary_accuracy: 0.4781 - loss: 0.7021 - precision: 0.4495 - recall: 0.9654 - val_auc: 0.7135 - val_binary_accuracy: 0.4814 - val_loss: 0.6889 - val_precision: 0.4490 - val_recall: 0.9617 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7404 - binary_accuracy: 0.5055 - loss: 0.6791 - precision: 0.4623 - recall: 0.9634 - val_auc: 0.7624 - val_binary_accuracy: 0.5256 - val_loss: 0.6671 - val_precision: 0.4718 - val_recall: 0.9617 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7843 - binary_accuracy: 0.5320 - loss: 0.6580 - precision: 0.4768 - recall: 0.9580 - val_auc: 0.8013 - val_binary_accuracy: 0.5512 - val_loss: 0.6471 - val_precision: 0.4862 - val_recall: 0.9617 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8188 - binary_accuracy: 0.5641 - loss: 0.6382 - precision: 0.4943 - recall: 0.9524 - val_auc: 0.8329 - val_binary_accuracy: 0.5814 - val_loss: 0.6284 - val_precision: 0.5043 - val_recall: 0.9617 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8425 - binary_accuracy: 0.5914 - loss: 0.6193 - precision: 0.5124 - recall: 0.9453 - val_auc: 0.8568 - val_binary_accuracy: 0.6047 - val_loss: 0.6113 - val_precision: 0.5193 - val_recall: 0.9563 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8620 - binary_accuracy: 0.6148 - loss: 0.6028 - precision: 0.5262 - recall: 0.9412 - val_auc: 0.8715 - val_binary_accuracy: 0.6488 - val_loss: 0.5956 - val_precision: 0.5503 - val_recall: 0.9563 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8759 - binary_accuracy: 0.6430 - loss: 0.5865 - precision: 0.5479 - recall: 0.9415 - val_auc: 0.8833 - val_binary_accuracy: 0.6628 - val_loss: 0.5812 - val_precision: 0.5609 - val_recall: 0.9563 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8846 - binary_accuracy: 0.6641 - loss: 0.5732 - precision: 0.5648 - recall: 0.9324 - val_auc: 0.8906 - val_binary_accuracy: 0.6814 - val_loss: 0.5683 - val_precision: 0.5767 - val_recall: 0.9454 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8929 - binary_accuracy: 0.6820 - loss: 0.5600 - precision: 0.5792 - recall: 0.9304 - val_auc: 0.8970 - val_binary_accuracy: 0.7023 - val_loss: 0.5562 - val_precision: 0.5952 - val_recall: 0.9399 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9006 - binary_accuracy: 0.6953 - loss: 0.5471 - precision: 0.5900 - recall: 0.9283 - val_auc: 0.9025 - val_binary_accuracy: 0.7186 - val_loss: 0.5449 - val_precision: 0.6099 - val_recall: 0.9399 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9051 - binary_accuracy: 0.7055 - loss: 0.5357 - precision: 0.6014 - recall: 0.9214 - val_auc: 0.9063 - val_binary_accuracy: 0.7372 - val_loss: 0.5344 - val_precision: 0.6296 - val_recall: 0.9290 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9093 - binary_accuracy: 0.7211 - loss: 0.5252 - precision: 0.6170 - recall: 0.9159 - val_auc: 0.9092 - val_binary_accuracy: 0.7628 - val_loss: 0.5243 - val_precision: 0.6576 - val_recall: 0.9235 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9125 - binary_accuracy: 0.7414 - loss: 0.5140 - precision: 0.6388 - recall: 0.9086 - val_auc: 0.9117 - val_binary_accuracy: 0.7814 - val_loss: 0.5146 - val_precision: 0.6787 - val_recall: 0.9235 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9149 - binary_accuracy: 0.7625 - loss: 0.5052 - precision: 0.6627 - recall: 0.9089 - val_auc: 0.9140 - val_binary_accuracy: 0.7860 - val_loss: 0.5055 - val_precision: 0.6888 - val_recall: 0.9071 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9187 - binary_accuracy: 0.7859 - loss: 0.4953 - precision: 0.6895 - recall: 0.9046 - val_auc: 0.9157 - val_binary_accuracy: 0.8000 - val_loss: 0.4968 - val_precision: 0.7064 - val_recall: 0.9071 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9211 - binary_accuracy: 0.8031 - loss: 0.4851 - precision: 0.7141 - recall: 0.8995 - val_auc: 0.9181 - val_binary_accuracy: 0.8070 - val_loss: 0.4882 - val_precision: 0.7212 - val_recall: 0.8907 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9226 - binary_accuracy: 0.8195 - loss: 0.4770 - precision: 0.7390 - recall: 0.8919 - val_auc: 0.9191 - val_binary_accuracy: 0.8256 - val_loss: 0.4800 - val_precision: 0.7477 - val_recall: 0.8907 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9245 - binary_accuracy: 0.8281 - loss: 0.4686 - precision: 0.7555 - recall: 0.8828 - val_auc: 0.9200 - val_binary_accuracy: 0.8302 - val_loss: 0.4721 - val_precision: 0.7570 - val_recall: 0.8852 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9261 - binary_accuracy: 0.8328 - loss: 0.4604 - precision: 0.7635 - recall: 0.8810 - val_auc: 0.9213 - val_binary_accuracy: 0.8442 - val_loss: 0.4647 - val_precision: 0.7788 - val_recall: 0.8852 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9272 - binary_accuracy: 0.8391 - loss: 0.4522 - precision: 0.7762 - recall: 0.8780 - val_auc: 0.9222 - val_binary_accuracy: 0.8488 - val_loss: 0.4574 - val_precision: 0.7864 - val_recall: 0.8852 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9287 - binary_accuracy: 0.8453 - loss: 0.4446 - precision: 0.7871 - recall: 0.8736 - val_auc: 0.9232 - val_binary_accuracy: 0.8512 - val_loss: 0.4505 - val_precision: 0.7902 - val_recall: 0.8852 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9299 - binary_accuracy: 0.8500 - loss: 0.4374 - precision: 0.7973 - recall: 0.8702 - val_auc: 0.9240 - val_binary_accuracy: 0.8512 - val_loss: 0.4439 - val_precision: 0.7960 - val_recall: 0.8743 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9320 - binary_accuracy: 0.8547 - loss: 0.4299 - precision: 0.8061 - recall: 0.8681 - val_auc: 0.9242 - val_binary_accuracy: 0.8488 - val_loss: 0.4376 - val_precision: 0.7950 - val_recall: 0.8689 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9333 - binary_accuracy: 0.8562 - loss: 0.4212 - precision: 0.8110 - recall: 0.8645 - val_auc: 0.9248 - val_binary_accuracy: 0.8488 - val_loss: 0.4314 - val_precision: 0.7950 - val_recall: 0.8689 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9327 - binary_accuracy: 0.8609 - loss: 0.4167 - precision: 0.8217 - recall: 0.8608 - val_auc: 0.9248 - val_binary_accuracy: 0.8512 - val_loss: 0.4255 - val_precision: 0.8020 - val_recall: 0.8634 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9334 - binary_accuracy: 0.8633 - loss: 0.4112 - precision: 0.8280 - recall: 0.8569 - val_auc: 0.9253 - val_binary_accuracy: 0.8512 - val_loss: 0.4201 - val_precision: 0.8051 - val_recall: 0.8579 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9350 - binary_accuracy: 0.8648 - loss: 0.4029 - precision: 0.8363 - recall: 0.8501 - val_auc: 0.9256 - val_binary_accuracy: 0.8488 - val_loss: 0.4147 - val_precision: 0.8073 - val_recall: 0.8470 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9349 - binary_accuracy: 0.8664 - loss: 0.3990 - precision: 0.8409 - recall: 0.8485 - val_auc: 0.9264 - val_binary_accuracy: 0.8512 - val_loss: 0.4098 - val_precision: 0.8115 - val_recall: 0.8470 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9354 - binary_accuracy: 0.8680 - loss: 0.3934 - precision: 0.8428 - recall: 0.8474 - val_auc: 0.9264 - val_binary_accuracy: 0.8512 - val_loss: 0.4048 - val_precision: 0.8148 - val_recall: 0.8415 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9366 - binary_accuracy: 0.8680 - loss: 0.3866 - precision: 0.8467 - recall: 0.8452 - val_auc: 0.9265 - val_binary_accuracy: 0.8535 - val_loss: 0.4001 - val_precision: 0.8261 - val_recall: 0.8306 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9365 - binary_accuracy: 0.8695 - loss: 0.3824 - precision: 0.8503 - recall: 0.8425 - val_auc: 0.9271 - val_binary_accuracy: 0.8512 - val_loss: 0.3956 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9365 - binary_accuracy: 0.8695 - loss: 0.3785 - precision: 0.8516 - recall: 0.8407 - val_auc: 0.9274 - val_binary_accuracy: 0.8512 - val_loss: 0.3914 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8711 - loss: 0.3740 - precision: 0.8547 - recall: 0.8407 - val_auc: 0.9274 - val_binary_accuracy: 0.8512 - val_loss: 0.3875 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9383 - binary_accuracy: 0.8719 - loss: 0.3684 - precision: 0.8561 - recall: 0.8404 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3835 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8742 - loss: 0.3637 - precision: 0.8630 - recall: 0.8394 - val_auc: 0.9277 - val_binary_accuracy: 0.8512 - val_loss: 0.3799 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9386 - binary_accuracy: 0.8734 - loss: 0.3597 - precision: 0.8639 - recall: 0.8355 - val_auc: 0.9275 - val_binary_accuracy: 0.8512 - val_loss: 0.3764 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9385 - binary_accuracy: 0.8727 - loss: 0.3564 - precision: 0.8639 - recall: 0.8339 - val_auc: 0.9279 - val_binary_accuracy: 0.8512 - val_loss: 0.3732 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9387 - binary_accuracy: 0.8734 - loss: 0.3533 - precision: 0.8655 - recall: 0.8339 - val_auc: 0.9279 - val_binary_accuracy: 0.8512 - val_loss: 0.3702 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9392 - binary_accuracy: 0.8742 - loss: 0.3495 - precision: 0.8653 - recall: 0.8352 - val_auc: 0.9282 - val_binary_accuracy: 0.8512 - val_loss: 0.3674 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9397 - binary_accuracy: 0.8727 - loss: 0.3459 - precision: 0.8648 - recall: 0.8315 - val_auc: 0.9283 - val_binary_accuracy: 0.8512 - val_loss: 0.3647 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8719 - loss: 0.3432 - precision: 0.8655 - recall: 0.8309 - val_auc: 0.9284 - val_binary_accuracy: 0.8512 - val_loss: 0.3623 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9401 - binary_accuracy: 0.8727 - loss: 0.3396 - precision: 0.8650 - recall: 0.8318 - val_auc: 0.9281 - val_binary_accuracy: 0.8488 - val_loss: 0.3600 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9400 - binary_accuracy: 0.8734 - loss: 0.3372 - precision: 0.8662 - recall: 0.8312 - val_auc: 0.9282 - val_binary_accuracy: 0.8488 - val_loss: 0.3579 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9402 - binary_accuracy: 0.8734 - loss: 0.3346 - precision: 0.8678 - recall: 0.8297 - val_auc: 0.9284 - val_binary_accuracy: 0.8488 - val_loss: 0.3559 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9406 - binary_accuracy: 0.8734 - loss: 0.3321 - precision: 0.8681 - recall: 0.8300 - val_auc: 0.9286 - val_binary_accuracy: 0.8488 - val_loss: 0.3540 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8742 - loss: 0.3291 - precision: 0.8681 - recall: 0.8315 - val_auc: 0.9287 - val_binary_accuracy: 0.8488 - val_loss: 0.3523 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8734 - loss: 0.3277 - precision: 0.8690 - recall: 0.8275 - val_auc: 0.9289 - val_binary_accuracy: 0.8488 - val_loss: 0.3508 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8750 - loss: 0.3241 - precision: 0.8726 - recall: 0.8278 - val_auc: 0.9292 - val_binary_accuracy: 0.8488 - val_loss: 0.3493 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8758 - loss: 0.3220 - precision: 0.8707 - recall: 0.8306 - val_auc: 0.9293 - val_binary_accuracy: 0.8512 - val_loss: 0.3478 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8766 - loss: 0.3193 - precision: 0.8762 - recall: 0.8282 - val_auc: 0.9293 - val_binary_accuracy: 0.8512 - val_loss: 0.3466 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8734 - loss: 0.3206 - precision: 0.8723 - recall: 0.8245 - val_auc: 0.9294 - val_binary_accuracy: 0.8512 - val_loss: 0.3455 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8727 - loss: 0.3187 - precision: 0.8718 - recall: 0.8223 - val_auc: 0.9295 - val_binary_accuracy: 0.8512 - val_loss: 0.3445 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9427 - binary_accuracy: 0.8719 - loss: 0.3154 - precision: 0.8733 - recall: 0.8190 - val_auc: 0.9297 - val_binary_accuracy: 0.8512 - val_loss: 0.3435 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8719 - loss: 0.3148 - precision: 0.8718 - recall: 0.8208 - val_auc: 0.9296 - val_binary_accuracy: 0.8512 - val_loss: 0.3426 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8719 - loss: 0.3155 - precision: 0.8716 - recall: 0.8205 - val_auc: 0.9296 - val_binary_accuracy: 0.8512 - val_loss: 0.3418 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8734 - loss: 0.3135 - precision: 0.8755 - recall: 0.8212 - val_auc: 0.9298 - val_binary_accuracy: 0.8512 - val_loss: 0.3411 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9427 - binary_accuracy: 0.8742 - loss: 0.3117 - precision: 0.8740 - recall: 0.8245 - val_auc: 0.9297 - val_binary_accuracy: 0.8512 - val_loss: 0.3404 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8742 - loss: 0.3110 - precision: 0.8750 - recall: 0.8220 - val_auc: 0.9298 - val_binary_accuracy: 0.8512 - val_loss: 0.3398 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8742 - loss: 0.3102 - precision: 0.8740 - recall: 0.8245 - val_auc: 0.9300 - val_binary_accuracy: 0.8512 - val_loss: 0.3393 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9431 - binary_accuracy: 0.8742 - loss: 0.3089 - precision: 0.8738 - recall: 0.8242 - val_auc: 0.9301 - val_binary_accuracy: 0.8512 - val_loss: 0.3388 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9438 - binary_accuracy: 0.8742 - loss: 0.3070 - precision: 0.8733 - recall: 0.8235 - val_auc: 0.9303 - val_binary_accuracy: 0.8512 - val_loss: 0.3383 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9431 - binary_accuracy: 0.8742 - loss: 0.3083 - precision: 0.8757 - recall: 0.8230 - val_auc: 0.9303 - val_binary_accuracy: 0.8488 - val_loss: 0.3379 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8742 - loss: 0.3066 - precision: 0.8755 - recall: 0.8227 - val_auc: 0.9306 - val_binary_accuracy: 0.8488 - val_loss: 0.3376 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9430 - binary_accuracy: 0.8734 - loss: 0.3073 - precision: 0.8733 - recall: 0.8220 - val_auc: 0.9307 - val_binary_accuracy: 0.8488 - val_loss: 0.3372 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9438 - binary_accuracy: 0.8742 - loss: 0.3054 - precision: 0.8762 - recall: 0.8236 - val_auc: 0.9306 - val_binary_accuracy: 0.8488 - val_loss: 0.3370 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9437 - binary_accuracy: 0.8734 - loss: 0.3055 - precision: 0.8740 - recall: 0.8230 - val_auc: 0.9307 - val_binary_accuracy: 0.8488 - val_loss: 0.3367 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9443 - binary_accuracy: 0.8750 - loss: 0.3036 - precision: 0.8760 - recall: 0.8248 - val_auc: 0.9308 - val_binary_accuracy: 0.8488 - val_loss: 0.3365 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9453 - binary_accuracy: 0.8758 - loss: 0.3014 - precision: 0.8738 - recall: 0.8272 - val_auc: 0.9309 - val_binary_accuracy: 0.8488 - val_loss: 0.3363 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9445 - binary_accuracy: 0.8750 - loss: 0.3025 - precision: 0.8757 - recall: 0.8245 - val_auc: 0.9308 - val_binary_accuracy: 0.8488 - val_loss: 0.3361 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9440 - binary_accuracy: 0.8750 - loss: 0.3035 - precision: 0.8740 - recall: 0.8260 - val_auc: 0.9310 - val_binary_accuracy: 0.8488 - val_loss: 0.3359 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9444 - binary_accuracy: 0.8758 - loss: 0.3022 - precision: 0.8779 - recall: 0.8251 - val_auc: 0.9309 - val_binary_accuracy: 0.8488 - val_loss: 0.3358 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9439 - binary_accuracy: 0.8742 - loss: 0.3035 - precision: 0.8740 - recall: 0.8245 - val_auc: 0.9310 - val_binary_accuracy: 0.8488 - val_loss: 0.3356 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9441 - binary_accuracy: 0.8742 - loss: 0.3027 - precision: 0.8735 - recall: 0.8239 - val_auc: 0.9312 - val_binary_accuracy: 0.8488 - val_loss: 0.3355 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9444 - binary_accuracy: 0.8750 - loss: 0.3020 - precision: 0.8738 - recall: 0.8257 - val_auc: 0.9311 - val_binary_accuracy: 0.8488 - val_loss: 0.3355 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9447 - binary_accuracy: 0.8750 - loss: 0.3010 - precision: 0.8760 - recall: 0.8248 - val_auc: 0.9312 - val_binary_accuracy: 0.8488 - val_loss: 0.3353 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9450 - binary_accuracy: 0.8766 - loss: 0.2998 - precision: 0.8743 - recall: 0.8294 - val_auc: 0.9314 - val_binary_accuracy: 0.8488 - val_loss: 0.3353 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8758 - loss: 0.3003 - precision: 0.8762 - recall: 0.8266 - val_auc: 0.9313 - val_binary_accuracy: 0.8488 - val_loss: 0.3352 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9459 - binary_accuracy: 0.8766 - loss: 0.2975 - precision: 0.8764 - recall: 0.8285 - val_auc: 0.9312 - val_binary_accuracy: 0.8488 - val_loss: 0.3352 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8766 - loss: 0.3001 - precision: 0.8740 - recall: 0.8290 - val_auc: 0.9315 - val_binary_accuracy: 0.8488 - val_loss: 0.3352 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8758 - loss: 0.2983 - precision: 0.8740 - recall: 0.8275 - val_auc: 0.9316 - val_binary_accuracy: 0.8488 - val_loss: 0.3351 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8781 - loss: 0.2972 - precision: 0.8764 - recall: 0.8315 - val_auc: 0.9316 - val_binary_accuracy: 0.8488 - val_loss: 0.3351 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9452 - binary_accuracy: 0.8773 - loss: 0.2991 - precision: 0.8781 - recall: 0.8285 - val_auc: 0.9317 - val_binary_accuracy: 0.8488 - val_loss: 0.3351 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 86/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8773 - loss: 0.2973 - precision: 0.8769 - recall: 0.8306 - val_auc: 0.9318 - val_binary_accuracy: 0.8488 - val_loss: 0.3352 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 87/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9444 - binary_accuracy: 0.8758 - loss: 0.3008 - precision: 0.8740 - recall: 0.8275 - val_auc: 0.9316 - val_binary_accuracy: 0.8488 - val_loss: 0.3351 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 88/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9447 - binary_accuracy: 0.8758 - loss: 0.2999 - precision: 0.8728 - recall: 0.8297 - val_auc: 0.9316 - val_binary_accuracy: 0.8488 - val_loss: 0.3352 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 89/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9445 - binary_accuracy: 0.8766 - loss: 0.3005 - precision: 0.8743 - recall: 0.8294 - val_auc: 0.9315 - val_binary_accuracy: 0.8488 - val_loss: 0.3352 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 90/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9452 - binary_accuracy: 0.8766 - loss: 0.2990 - precision: 0.8731 - recall: 0.8315 - val_auc: 0.9316 - val_binary_accuracy: 0.8512 - val_loss: 0.3351 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 91/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8773 - loss: 0.2961 - precision: 0.8769 - recall: 0.8306 - val_auc: 0.9317 - val_binary_accuracy: 0.8512 - val_loss: 0.3351 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 92/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8766 - loss: 0.2997 - precision: 0.8748 - recall: 0.8300 - val_auc: 0.9317 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 93/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9449 - binary_accuracy: 0.8766 - loss: 0.2993 - precision: 0.8723 - recall: 0.8306 - val_auc: 0.9318 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 94/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9452 - binary_accuracy: 0.8758 - loss: 0.2990 - precision: 0.8733 - recall: 0.8303 - val_auc: 0.9317 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 95/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9456 - binary_accuracy: 0.8773 - loss: 0.2975 - precision: 0.8762 - recall: 0.8297 - val_auc: 0.9318 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 96/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9451 - binary_accuracy: 0.8766 - loss: 0.2986 - precision: 0.8736 - recall: 0.8321 - val_auc: 0.9318 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 97/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8766 - loss: 0.2979 - precision: 0.8745 - recall: 0.8297 - val_auc: 0.9319 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 98/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8766 - loss: 0.2985 - precision: 0.8750 - recall: 0.8303 - val_auc: 0.9320 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 99/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8766 - loss: 0.2978 - precision: 0.8745 - recall: 0.8297 - val_auc: 0.9321 - val_binary_accuracy: 0.8512 - val_loss: 0.3353 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 100/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8766 - loss: 0.2974 - precision: 0.8736 - recall: 0.8321 - val_auc: 0.9321 - val_binary_accuracy: 0.8512 - val_loss: 0.3353 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 101/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8758 - loss: 0.2978 - precision: 0.8736 - recall: 0.8306 - val_auc: 0.9322 - val_binary_accuracy: 0.8512 - val_loss: 0.3353 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 102/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8766 - loss: 0.2981 - precision: 0.8748 - recall: 0.8300 - val_auc: 0.9322 - val_binary_accuracy: 0.8535 - val_loss: 0.3353 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 103/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9450 - binary_accuracy: 0.8758 - loss: 0.2988 - precision: 0.8728 - recall: 0.8297 - val_auc: 0.9322 - val_binary_accuracy: 0.8535 - val_loss: 0.3353 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 104/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9467 - binary_accuracy: 0.8789 - loss: 0.2944 - precision: 0.8786 - recall: 0.8321 - val_auc: 0.9319 - val_binary_accuracy: 0.8535 - val_loss: 0.3353 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 105/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9457 - binary_accuracy: 0.8773 - loss: 0.2970 - precision: 0.8750 - recall: 0.8318 - val_auc: 0.9321 - val_binary_accuracy: 0.8535 - val_loss: 0.3353 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 5.0049e-05\n",
      "\n",
      "Epoch 106/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9454 - binary_accuracy: 0.8773 - loss: 0.2978 - precision: 0.8750 - recall: 0.8318 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.3353 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 107/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9453 - binary_accuracy: 0.8766 - loss: 0.2979 - precision: 0.8728 - recall: 0.8312 - val_auc: 0.9323 - val_binary_accuracy: 0.8535 - val_loss: 0.3353 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 108/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9463 - binary_accuracy: 0.8773 - loss: 0.2953 - precision: 0.8748 - recall: 0.8315 - val_auc: 0.9322 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 109/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9460 - binary_accuracy: 0.8789 - loss: 0.2960 - precision: 0.8755 - recall: 0.8355 - val_auc: 0.9323 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 110/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9458 - binary_accuracy: 0.8781 - loss: 0.2968 - precision: 0.8731 - recall: 0.8346 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 111/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8773 - loss: 0.2979 - precision: 0.8733 - recall: 0.8333 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 112/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9455 - binary_accuracy: 0.8773 - loss: 0.2977 - precision: 0.8733 - recall: 0.8333 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 113/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9458 - binary_accuracy: 0.8789 - loss: 0.2965 - precision: 0.8731 - recall: 0.8361 - val_auc: 0.9323 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 114/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9455 - binary_accuracy: 0.8781 - loss: 0.2973 - precision: 0.8733 - recall: 0.8349 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 115/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9461 - binary_accuracy: 0.8797 - loss: 0.2956 - precision: 0.8752 - recall: 0.8367 - val_auc: 0.9324 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 116/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9464 - binary_accuracy: 0.8789 - loss: 0.2951 - precision: 0.8738 - recall: 0.8370 - val_auc: 0.9323 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 117/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9458 - binary_accuracy: 0.8773 - loss: 0.2967 - precision: 0.8738 - recall: 0.8339 - val_auc: 0.9324 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 118/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8781 - loss: 0.2965 - precision: 0.8733 - recall: 0.8349 - val_auc: 0.9324 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 119/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9457 - binary_accuracy: 0.8781 - loss: 0.2967 - precision: 0.8750 - recall: 0.8333 - val_auc: 0.9324 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 120/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9459 - binary_accuracy: 0.8781 - loss: 0.2963 - precision: 0.8752 - recall: 0.8336 - val_auc: 0.9323 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 121/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9457 - binary_accuracy: 0.8781 - loss: 0.2966 - precision: 0.8731 - recall: 0.8346 - val_auc: 0.9325 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 122/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9459 - binary_accuracy: 0.8773 - loss: 0.2965 - precision: 0.8738 - recall: 0.8339 - val_auc: 0.9326 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 123/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9463 - binary_accuracy: 0.8789 - loss: 0.2951 - precision: 0.8752 - recall: 0.8352 - val_auc: 0.9325 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 124/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9460 - binary_accuracy: 0.8781 - loss: 0.2961 - precision: 0.8755 - recall: 0.8339 - val_auc: 0.9325 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 125/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9468 - binary_accuracy: 0.8797 - loss: 0.2939 - precision: 0.8755 - recall: 0.8370 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 3.6767e-05\n",
      "\n",
      "Epoch 126/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9461 - binary_accuracy: 0.8789 - loss: 0.2955 - precision: 0.8743 - recall: 0.8376 - val_auc: 0.9323 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 2.7010e-05\n",
      "\n",
      "Epoch 127/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9459 - binary_accuracy: 0.8781 - loss: 0.2964 - precision: 0.8752 - recall: 0.8336 - val_auc: 0.9322 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 2.7010e-05\n",
      "\n",
      "Epoch 128/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9461 - binary_accuracy: 0.8797 - loss: 0.2953 - precision: 0.8750 - recall: 0.8364 - val_auc: 0.9322 - val_binary_accuracy: 0.8535 - val_loss: 0.3355 - val_precision: 0.8333 - val_recall: 0.8197 - learning_rate: 2.7010e-05\n",
      "\n",
      "Epoch 129/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9465 - binary_accuracy: 0.8789 - loss: 0.2949 - precision: 0.8757 - recall: 0.8358 - val_auc: 0.9323 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 2.7010e-05\n",
      "\n",
      "Epoch 130/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9470 - binary_accuracy: 0.8789 - loss: 0.2938 - precision: 0.8745 - recall: 0.8343 - val_auc: 0.9323 - val_binary_accuracy: 0.8512 - val_loss: 0.3354 - val_precision: 0.8287 - val_recall: 0.8197 - learning_rate: 2.7010e-05\n",
      "\n",
      "./plots/popular-eel-517/learning_rate_vs_epoch.png                                \n",
      "./plots/popular-eel-517/auc_vs_epoch.png                                          \n",
      "./plots/popular-eel-517/loss_vs_epoch.png                                         \n",
      "./plots/popular-eel-517/binary_accuracy_vs_epoch.png                              \n",
      "./plots/popular-eel-517/recall_vs_epoch.png                                       \n",
      "./plots/popular-eel-517/precision_vs_epoch.png                                    \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 535ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step         \n",
      "\n",
      " 85%|████████▌ | 17/20 [05:24<07:05, 141.89s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step         \n",
      "\n",
      " 85%|████████▌ | 17/20 [05:25<07:05, 141.89s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0366bff2a2c04c1f9eecae756888a453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m229/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 20/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 41/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m229/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 18/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 37/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m132/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 21/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 43/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m194/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 87/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m229/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m225/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m143/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m284/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m125/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 70/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 15/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step                 \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step       \n",
      "\u001b[1m 44/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step       \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 75/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m101/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m200/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m132/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m236/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 75/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m292/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m296/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step                \n",
      "\u001b[1m 22/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 46/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 72/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m292/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run popular-eel-517 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/3a359ab4b981436799f2c7771d052c52\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 90%|█████████ | 18/20 [06:15<03:56, 118.50s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:42:16.661162: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:16.710765: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:16.758043: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:16.807593: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:16.853888: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:16.907169: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:16.952646: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:16.994379: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.037648: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.082640: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.127653: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.168550: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.209710: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.249981: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.291307: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:42:17.333914: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 5s - 58ms/step - auc: 0.5935 - binary_accuracy: 0.5297 - loss: 0.7806 - precision: 0.4583 - recall: 0.5641 - val_auc: 0.6163 - val_binary_accuracy: 0.5488 - val_loss: 0.7700 - val_precision: 0.4732 - val_recall: 0.5301 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6063 - binary_accuracy: 0.5359 - loss: 0.7699 - precision: 0.4649 - recall: 0.5686 - val_auc: 0.6261 - val_binary_accuracy: 0.5581 - val_loss: 0.7609 - val_precision: 0.4828 - val_recall: 0.5355 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6155 - binary_accuracy: 0.5469 - loss: 0.7632 - precision: 0.4775 - recall: 0.5800 - val_auc: 0.6356 - val_binary_accuracy: 0.5698 - val_loss: 0.7522 - val_precision: 0.4950 - val_recall: 0.5464 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.6286 - binary_accuracy: 0.5555 - loss: 0.7520 - precision: 0.4833 - recall: 0.5832 - val_auc: 0.6444 - val_binary_accuracy: 0.5860 - val_loss: 0.7439 - val_precision: 0.5123 - val_recall: 0.5683 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6400 - binary_accuracy: 0.5703 - loss: 0.7434 - precision: 0.4977 - recall: 0.6051 - val_auc: 0.6529 - val_binary_accuracy: 0.5907 - val_loss: 0.7359 - val_precision: 0.5171 - val_recall: 0.5792 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6513 - binary_accuracy: 0.5766 - loss: 0.7343 - precision: 0.5038 - recall: 0.6088 - val_auc: 0.6623 - val_binary_accuracy: 0.5953 - val_loss: 0.7280 - val_precision: 0.5217 - val_recall: 0.5902 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6596 - binary_accuracy: 0.5852 - loss: 0.7274 - precision: 0.5128 - recall: 0.6223 - val_auc: 0.6712 - val_binary_accuracy: 0.6023 - val_loss: 0.7201 - val_precision: 0.5294 - val_recall: 0.5902 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6702 - binary_accuracy: 0.5930 - loss: 0.7185 - precision: 0.5203 - recall: 0.6314 - val_auc: 0.6804 - val_binary_accuracy: 0.6116 - val_loss: 0.7125 - val_precision: 0.5388 - val_recall: 0.6066 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.6804 - binary_accuracy: 0.5977 - loss: 0.7110 - precision: 0.5228 - recall: 0.6312 - val_auc: 0.6895 - val_binary_accuracy: 0.6163 - val_loss: 0.7050 - val_precision: 0.5437 - val_recall: 0.6120 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6909 - binary_accuracy: 0.6078 - loss: 0.7027 - precision: 0.5335 - recall: 0.6410 - val_auc: 0.6991 - val_binary_accuracy: 0.6186 - val_loss: 0.6978 - val_precision: 0.5463 - val_recall: 0.6120 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7003 - binary_accuracy: 0.6141 - loss: 0.6952 - precision: 0.5396 - recall: 0.6484 - val_auc: 0.7078 - val_binary_accuracy: 0.6163 - val_loss: 0.6908 - val_precision: 0.5441 - val_recall: 0.6066 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7083 - binary_accuracy: 0.6227 - loss: 0.6890 - precision: 0.5474 - recall: 0.6569 - val_auc: 0.7159 - val_binary_accuracy: 0.6279 - val_loss: 0.6838 - val_precision: 0.5561 - val_recall: 0.6230 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7219 - binary_accuracy: 0.6398 - loss: 0.6787 - precision: 0.5681 - recall: 0.6685 - val_auc: 0.7245 - val_binary_accuracy: 0.6326 - val_loss: 0.6770 - val_precision: 0.5616 - val_recall: 0.6230 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7263 - binary_accuracy: 0.6453 - loss: 0.6745 - precision: 0.5712 - recall: 0.6758 - val_auc: 0.7330 - val_binary_accuracy: 0.6395 - val_loss: 0.6704 - val_precision: 0.5693 - val_recall: 0.6284 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7376 - binary_accuracy: 0.6516 - loss: 0.6662 - precision: 0.5792 - recall: 0.6807 - val_auc: 0.7412 - val_binary_accuracy: 0.6442 - val_loss: 0.6639 - val_precision: 0.5750 - val_recall: 0.6284 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7459 - binary_accuracy: 0.6594 - loss: 0.6594 - precision: 0.5883 - recall: 0.6807 - val_auc: 0.7496 - val_binary_accuracy: 0.6558 - val_loss: 0.6574 - val_precision: 0.5871 - val_recall: 0.6448 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7539 - binary_accuracy: 0.6680 - loss: 0.6523 - precision: 0.5971 - recall: 0.6856 - val_auc: 0.7582 - val_binary_accuracy: 0.6581 - val_loss: 0.6511 - val_precision: 0.5900 - val_recall: 0.6448 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7632 - binary_accuracy: 0.6727 - loss: 0.6449 - precision: 0.6032 - recall: 0.6880 - val_auc: 0.7652 - val_binary_accuracy: 0.6744 - val_loss: 0.6450 - val_precision: 0.6091 - val_recall: 0.6557 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7687 - binary_accuracy: 0.6820 - loss: 0.6399 - precision: 0.6139 - recall: 0.6934 - val_auc: 0.7724 - val_binary_accuracy: 0.6884 - val_loss: 0.6390 - val_precision: 0.6269 - val_recall: 0.6612 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7737 - binary_accuracy: 0.6883 - loss: 0.6354 - precision: 0.6203 - recall: 0.6941 - val_auc: 0.7793 - val_binary_accuracy: 0.6953 - val_loss: 0.6331 - val_precision: 0.6368 - val_recall: 0.6612 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7820 - binary_accuracy: 0.6969 - loss: 0.6277 - precision: 0.6293 - recall: 0.7009 - val_auc: 0.7852 - val_binary_accuracy: 0.7070 - val_loss: 0.6274 - val_precision: 0.6541 - val_recall: 0.6612 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7869 - binary_accuracy: 0.7094 - loss: 0.6236 - precision: 0.6467 - recall: 0.7080 - val_auc: 0.7913 - val_binary_accuracy: 0.7163 - val_loss: 0.6218 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.7953 - binary_accuracy: 0.7234 - loss: 0.6149 - precision: 0.6610 - recall: 0.7169 - val_auc: 0.7974 - val_binary_accuracy: 0.7279 - val_loss: 0.6162 - val_precision: 0.6833 - val_recall: 0.6721 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.7995 - binary_accuracy: 0.7289 - loss: 0.6110 - precision: 0.6713 - recall: 0.7143 - val_auc: 0.8032 - val_binary_accuracy: 0.7326 - val_loss: 0.6109 - val_precision: 0.6889 - val_recall: 0.6776 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8072 - binary_accuracy: 0.7391 - loss: 0.6042 - precision: 0.6883 - recall: 0.7158 - val_auc: 0.8100 - val_binary_accuracy: 0.7395 - val_loss: 0.6055 - val_precision: 0.6983 - val_recall: 0.6831 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.8110 - binary_accuracy: 0.7469 - loss: 0.6001 - precision: 0.6986 - recall: 0.7190 - val_auc: 0.8154 - val_binary_accuracy: 0.7535 - val_loss: 0.6003 - val_precision: 0.7200 - val_recall: 0.6885 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8187 - binary_accuracy: 0.7516 - loss: 0.5924 - precision: 0.7068 - recall: 0.7172 - val_auc: 0.8204 - val_binary_accuracy: 0.7674 - val_loss: 0.5951 - val_precision: 0.7399 - val_recall: 0.6995 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8224 - binary_accuracy: 0.7547 - loss: 0.5875 - precision: 0.7104 - recall: 0.7156 - val_auc: 0.8247 - val_binary_accuracy: 0.7698 - val_loss: 0.5902 - val_precision: 0.7442 - val_recall: 0.6995 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8271 - binary_accuracy: 0.7578 - loss: 0.5826 - precision: 0.7143 - recall: 0.7221 - val_auc: 0.8291 - val_binary_accuracy: 0.7744 - val_loss: 0.5853 - val_precision: 0.7529 - val_recall: 0.6995 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.8311 - binary_accuracy: 0.7641 - loss: 0.5782 - precision: 0.7218 - recall: 0.7271 - val_auc: 0.8336 - val_binary_accuracy: 0.7791 - val_loss: 0.5805 - val_precision: 0.7588 - val_recall: 0.7049 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.8365 - binary_accuracy: 0.7711 - loss: 0.5720 - precision: 0.7321 - recall: 0.7308 - val_auc: 0.8375 - val_binary_accuracy: 0.7791 - val_loss: 0.5758 - val_precision: 0.7558 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.8412 - binary_accuracy: 0.7805 - loss: 0.5659 - precision: 0.7435 - recall: 0.7394 - val_auc: 0.8414 - val_binary_accuracy: 0.7860 - val_loss: 0.5711 - val_precision: 0.7692 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 6ms/step - auc: 0.8456 - binary_accuracy: 0.7867 - loss: 0.5607 - precision: 0.7551 - recall: 0.7399 - val_auc: 0.8450 - val_binary_accuracy: 0.7837 - val_loss: 0.5667 - val_precision: 0.7679 - val_recall: 0.7049 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8482 - binary_accuracy: 0.7891 - loss: 0.5571 - precision: 0.7618 - recall: 0.7367 - val_auc: 0.8483 - val_binary_accuracy: 0.7884 - val_loss: 0.5623 - val_precision: 0.7805 - val_recall: 0.6995 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8540 - binary_accuracy: 0.7937 - loss: 0.5506 - precision: 0.7660 - recall: 0.7436 - val_auc: 0.8519 - val_binary_accuracy: 0.7977 - val_loss: 0.5578 - val_precision: 0.7927 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8575 - binary_accuracy: 0.7969 - loss: 0.5454 - precision: 0.7723 - recall: 0.7441 - val_auc: 0.8553 - val_binary_accuracy: 0.8000 - val_loss: 0.5536 - val_precision: 0.7975 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8603 - binary_accuracy: 0.7992 - loss: 0.5411 - precision: 0.7761 - recall: 0.7464 - val_auc: 0.8577 - val_binary_accuracy: 0.8023 - val_loss: 0.5494 - val_precision: 0.8025 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8624 - binary_accuracy: 0.8008 - loss: 0.5377 - precision: 0.7776 - recall: 0.7477 - val_auc: 0.8600 - val_binary_accuracy: 0.8023 - val_loss: 0.5453 - val_precision: 0.8025 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8677 - binary_accuracy: 0.8008 - loss: 0.5294 - precision: 0.7778 - recall: 0.7450 - val_auc: 0.8632 - val_binary_accuracy: 0.8047 - val_loss: 0.5413 - val_precision: 0.8075 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8710 - binary_accuracy: 0.8062 - loss: 0.5262 - precision: 0.7859 - recall: 0.7514 - val_auc: 0.8658 - val_binary_accuracy: 0.8023 - val_loss: 0.5374 - val_precision: 0.8025 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8716 - binary_accuracy: 0.8086 - loss: 0.5240 - precision: 0.7907 - recall: 0.7486 - val_auc: 0.8685 - val_binary_accuracy: 0.8000 - val_loss: 0.5335 - val_precision: 0.8012 - val_recall: 0.7049 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8741 - binary_accuracy: 0.8102 - loss: 0.5197 - precision: 0.7922 - recall: 0.7500 - val_auc: 0.8710 - val_binary_accuracy: 0.8023 - val_loss: 0.5297 - val_precision: 0.8025 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8777 - binary_accuracy: 0.8125 - loss: 0.5152 - precision: 0.7946 - recall: 0.7569 - val_auc: 0.8737 - val_binary_accuracy: 0.8047 - val_loss: 0.5260 - val_precision: 0.8075 - val_recall: 0.7104 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8793 - binary_accuracy: 0.8125 - loss: 0.5114 - precision: 0.7961 - recall: 0.7523 - val_auc: 0.8756 - val_binary_accuracy: 0.8093 - val_loss: 0.5224 - val_precision: 0.8137 - val_recall: 0.7158 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8813 - binary_accuracy: 0.8125 - loss: 0.5081 - precision: 0.7954 - recall: 0.7546 - val_auc: 0.8780 - val_binary_accuracy: 0.8116 - val_loss: 0.5189 - val_precision: 0.8148 - val_recall: 0.7213 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8843 - binary_accuracy: 0.8148 - loss: 0.5035 - precision: 0.7973 - recall: 0.7609 - val_auc: 0.8800 - val_binary_accuracy: 0.8140 - val_loss: 0.5155 - val_precision: 0.8199 - val_recall: 0.7213 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8859 - binary_accuracy: 0.8203 - loss: 0.4998 - precision: 0.8066 - recall: 0.7623 - val_auc: 0.8816 - val_binary_accuracy: 0.8163 - val_loss: 0.5121 - val_precision: 0.8210 - val_recall: 0.7268 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8872 - binary_accuracy: 0.8242 - loss: 0.4965 - precision: 0.8104 - recall: 0.7674 - val_auc: 0.8835 - val_binary_accuracy: 0.8209 - val_loss: 0.5089 - val_precision: 0.8232 - val_recall: 0.7377 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8894 - binary_accuracy: 0.8266 - loss: 0.4927 - precision: 0.8131 - recall: 0.7715 - val_auc: 0.8853 - val_binary_accuracy: 0.8233 - val_loss: 0.5057 - val_precision: 0.8242 - val_recall: 0.7432 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.8919 - binary_accuracy: 0.8320 - loss: 0.4883 - precision: 0.8214 - recall: 0.7747 - val_auc: 0.8866 - val_binary_accuracy: 0.8209 - val_loss: 0.5026 - val_precision: 0.8232 - val_recall: 0.7377 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 1s - 7ms/step - auc: 0.8956 - binary_accuracy: 0.8344 - loss: 0.4826 - precision: 0.8249 - recall: 0.7766 - val_auc: 0.8878 - val_binary_accuracy: 0.8233 - val_loss: 0.4997 - val_precision: 0.8282 - val_recall: 0.7377 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8956 - binary_accuracy: 0.8367 - loss: 0.4806 - precision: 0.8278 - recall: 0.7776 - val_auc: 0.8889 - val_binary_accuracy: 0.8233 - val_loss: 0.4968 - val_precision: 0.8282 - val_recall: 0.7377 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8971 - binary_accuracy: 0.8375 - loss: 0.4781 - precision: 0.8320 - recall: 0.7774 - val_auc: 0.8909 - val_binary_accuracy: 0.8233 - val_loss: 0.4938 - val_precision: 0.8282 - val_recall: 0.7377 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8986 - binary_accuracy: 0.8391 - loss: 0.4741 - precision: 0.8327 - recall: 0.7776 - val_auc: 0.8917 - val_binary_accuracy: 0.8233 - val_loss: 0.4910 - val_precision: 0.8242 - val_recall: 0.7432 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8991 - binary_accuracy: 0.8375 - loss: 0.4729 - precision: 0.8343 - recall: 0.7733 - val_auc: 0.8928 - val_binary_accuracy: 0.8233 - val_loss: 0.4883 - val_precision: 0.8242 - val_recall: 0.7432 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9008 - binary_accuracy: 0.8391 - loss: 0.4694 - precision: 0.8330 - recall: 0.7780 - val_auc: 0.8938 - val_binary_accuracy: 0.8256 - val_loss: 0.4856 - val_precision: 0.8293 - val_recall: 0.7432 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9030 - binary_accuracy: 0.8414 - loss: 0.4655 - precision: 0.8366 - recall: 0.7798 - val_auc: 0.8952 - val_binary_accuracy: 0.8279 - val_loss: 0.4830 - val_precision: 0.8303 - val_recall: 0.7486 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9042 - binary_accuracy: 0.8414 - loss: 0.4631 - precision: 0.8386 - recall: 0.7788 - val_auc: 0.8964 - val_binary_accuracy: 0.8279 - val_loss: 0.4804 - val_precision: 0.8303 - val_recall: 0.7486 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9045 - binary_accuracy: 0.8398 - loss: 0.4611 - precision: 0.8376 - recall: 0.7747 - val_auc: 0.8971 - val_binary_accuracy: 0.8302 - val_loss: 0.4778 - val_precision: 0.8313 - val_recall: 0.7541 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9060 - binary_accuracy: 0.8406 - loss: 0.4584 - precision: 0.8396 - recall: 0.7751 - val_auc: 0.8984 - val_binary_accuracy: 0.8372 - val_loss: 0.4754 - val_precision: 0.8383 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9078 - binary_accuracy: 0.8430 - loss: 0.4544 - precision: 0.8446 - recall: 0.7751 - val_auc: 0.8990 - val_binary_accuracy: 0.8395 - val_loss: 0.4729 - val_precision: 0.8393 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9097 - binary_accuracy: 0.8461 - loss: 0.4511 - precision: 0.8454 - recall: 0.7855 - val_auc: 0.8999 - val_binary_accuracy: 0.8465 - val_loss: 0.4707 - val_precision: 0.8462 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9094 - binary_accuracy: 0.8445 - loss: 0.4502 - precision: 0.8428 - recall: 0.7828 - val_auc: 0.9006 - val_binary_accuracy: 0.8442 - val_loss: 0.4684 - val_precision: 0.8452 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9109 - binary_accuracy: 0.8453 - loss: 0.4468 - precision: 0.8442 - recall: 0.7824 - val_auc: 0.9016 - val_binary_accuracy: 0.8442 - val_loss: 0.4662 - val_precision: 0.8452 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9127 - binary_accuracy: 0.8461 - loss: 0.4435 - precision: 0.8455 - recall: 0.7821 - val_auc: 0.9023 - val_binary_accuracy: 0.8465 - val_loss: 0.4641 - val_precision: 0.8462 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9138 - binary_accuracy: 0.8492 - loss: 0.4402 - precision: 0.8481 - recall: 0.7875 - val_auc: 0.9029 - val_binary_accuracy: 0.8442 - val_loss: 0.4621 - val_precision: 0.8412 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9151 - binary_accuracy: 0.8500 - loss: 0.4375 - precision: 0.8495 - recall: 0.7872 - val_auc: 0.9036 - val_binary_accuracy: 0.8442 - val_loss: 0.4601 - val_precision: 0.8412 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9143 - binary_accuracy: 0.8500 - loss: 0.4372 - precision: 0.8523 - recall: 0.7835 - val_auc: 0.9040 - val_binary_accuracy: 0.8512 - val_loss: 0.4581 - val_precision: 0.8480 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9143 - binary_accuracy: 0.8492 - loss: 0.4366 - precision: 0.8501 - recall: 0.7865 - val_auc: 0.9049 - val_binary_accuracy: 0.8488 - val_loss: 0.4563 - val_precision: 0.8430 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9160 - binary_accuracy: 0.8508 - loss: 0.4326 - precision: 0.8515 - recall: 0.7875 - val_auc: 0.9053 - val_binary_accuracy: 0.8488 - val_loss: 0.4545 - val_precision: 0.8471 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9177 - binary_accuracy: 0.8516 - loss: 0.4294 - precision: 0.8504 - recall: 0.7912 - val_auc: 0.9054 - val_binary_accuracy: 0.8465 - val_loss: 0.4528 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9196 - binary_accuracy: 0.8539 - loss: 0.4251 - precision: 0.8554 - recall: 0.7912 - val_auc: 0.9060 - val_binary_accuracy: 0.8465 - val_loss: 0.4512 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9179 - binary_accuracy: 0.8508 - loss: 0.4270 - precision: 0.8504 - recall: 0.7898 - val_auc: 0.9064 - val_binary_accuracy: 0.8465 - val_loss: 0.4496 - val_precision: 0.8421 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9188 - binary_accuracy: 0.8508 - loss: 0.4253 - precision: 0.8504 - recall: 0.7898 - val_auc: 0.9066 - val_binary_accuracy: 0.8419 - val_loss: 0.4481 - val_precision: 0.8402 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9202 - binary_accuracy: 0.8523 - loss: 0.4221 - precision: 0.8524 - recall: 0.7916 - val_auc: 0.9071 - val_binary_accuracy: 0.8419 - val_loss: 0.4466 - val_precision: 0.8402 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9200 - binary_accuracy: 0.8531 - loss: 0.4211 - precision: 0.8521 - recall: 0.7927 - val_auc: 0.9078 - val_binary_accuracy: 0.8419 - val_loss: 0.4452 - val_precision: 0.8402 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9209 - binary_accuracy: 0.8531 - loss: 0.4194 - precision: 0.8543 - recall: 0.7920 - val_auc: 0.9085 - val_binary_accuracy: 0.8395 - val_loss: 0.4438 - val_precision: 0.8393 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9214 - binary_accuracy: 0.8539 - loss: 0.4172 - precision: 0.8549 - recall: 0.7904 - val_auc: 0.9089 - val_binary_accuracy: 0.8372 - val_loss: 0.4424 - val_precision: 0.8383 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9215 - binary_accuracy: 0.8531 - loss: 0.4173 - precision: 0.8571 - recall: 0.7883 - val_auc: 0.9093 - val_binary_accuracy: 0.8349 - val_loss: 0.4411 - val_precision: 0.8333 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9221 - binary_accuracy: 0.8531 - loss: 0.4156 - precision: 0.8549 - recall: 0.7890 - val_auc: 0.9097 - val_binary_accuracy: 0.8349 - val_loss: 0.4399 - val_precision: 0.8333 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9225 - binary_accuracy: 0.8531 - loss: 0.4140 - precision: 0.8574 - recall: 0.7887 - val_auc: 0.9103 - val_binary_accuracy: 0.8372 - val_loss: 0.4387 - val_precision: 0.8343 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9225 - binary_accuracy: 0.8531 - loss: 0.4129 - precision: 0.8549 - recall: 0.7890 - val_auc: 0.9106 - val_binary_accuracy: 0.8372 - val_loss: 0.4375 - val_precision: 0.8343 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9234 - binary_accuracy: 0.8531 - loss: 0.4113 - precision: 0.8554 - recall: 0.7898 - val_auc: 0.9108 - val_binary_accuracy: 0.8372 - val_loss: 0.4364 - val_precision: 0.8343 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9250 - binary_accuracy: 0.8570 - loss: 0.4078 - precision: 0.8606 - recall: 0.7927 - val_auc: 0.9116 - val_binary_accuracy: 0.8349 - val_loss: 0.4353 - val_precision: 0.8294 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9239 - binary_accuracy: 0.8562 - loss: 0.4086 - precision: 0.8614 - recall: 0.7886 - val_auc: 0.9116 - val_binary_accuracy: 0.8349 - val_loss: 0.4342 - val_precision: 0.8294 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 86/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9244 - binary_accuracy: 0.8555 - loss: 0.4076 - precision: 0.8606 - recall: 0.7898 - val_auc: 0.9120 - val_binary_accuracy: 0.8349 - val_loss: 0.4333 - val_precision: 0.8294 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 87/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9247 - binary_accuracy: 0.8562 - loss: 0.4070 - precision: 0.8620 - recall: 0.7894 - val_auc: 0.9124 - val_binary_accuracy: 0.8326 - val_loss: 0.4322 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 88/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9251 - binary_accuracy: 0.8570 - loss: 0.4057 - precision: 0.8637 - recall: 0.7894 - val_auc: 0.9126 - val_binary_accuracy: 0.8326 - val_loss: 0.4312 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 89/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9251 - binary_accuracy: 0.8562 - loss: 0.4055 - precision: 0.8623 - recall: 0.7898 - val_auc: 0.9132 - val_binary_accuracy: 0.8326 - val_loss: 0.4303 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 90/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9259 - binary_accuracy: 0.8562 - loss: 0.4030 - precision: 0.8623 - recall: 0.7898 - val_auc: 0.9134 - val_binary_accuracy: 0.8302 - val_loss: 0.4294 - val_precision: 0.8235 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 91/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9262 - binary_accuracy: 0.8586 - loss: 0.4020 - precision: 0.8643 - recall: 0.7930 - val_auc: 0.9140 - val_binary_accuracy: 0.8302 - val_loss: 0.4285 - val_precision: 0.8235 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 92/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9270 - binary_accuracy: 0.8586 - loss: 0.4008 - precision: 0.8628 - recall: 0.7949 - val_auc: 0.9143 - val_binary_accuracy: 0.8279 - val_loss: 0.4276 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 93/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9278 - binary_accuracy: 0.8594 - loss: 0.3983 - precision: 0.8645 - recall: 0.7949 - val_auc: 0.9146 - val_binary_accuracy: 0.8279 - val_loss: 0.4269 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 94/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9268 - binary_accuracy: 0.8586 - loss: 0.3998 - precision: 0.8643 - recall: 0.7930 - val_auc: 0.9151 - val_binary_accuracy: 0.8279 - val_loss: 0.4260 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 95/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9269 - binary_accuracy: 0.8594 - loss: 0.3991 - precision: 0.8640 - recall: 0.7941 - val_auc: 0.9153 - val_binary_accuracy: 0.8279 - val_loss: 0.4252 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 96/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9281 - binary_accuracy: 0.8609 - loss: 0.3969 - precision: 0.8683 - recall: 0.7952 - val_auc: 0.9156 - val_binary_accuracy: 0.8279 - val_loss: 0.4245 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 97/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9275 - binary_accuracy: 0.8578 - loss: 0.3974 - precision: 0.8611 - recall: 0.7949 - val_auc: 0.9160 - val_binary_accuracy: 0.8279 - val_loss: 0.4237 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 98/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9294 - binary_accuracy: 0.8602 - loss: 0.3934 - precision: 0.8636 - recall: 0.7989 - val_auc: 0.9162 - val_binary_accuracy: 0.8279 - val_loss: 0.4230 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 99/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9279 - binary_accuracy: 0.8594 - loss: 0.3962 - precision: 0.8617 - recall: 0.7985 - val_auc: 0.9164 - val_binary_accuracy: 0.8279 - val_loss: 0.4224 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 100/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9291 - binary_accuracy: 0.8602 - loss: 0.3934 - precision: 0.8627 - recall: 0.8015 - val_auc: 0.9163 - val_binary_accuracy: 0.8279 - val_loss: 0.4217 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 101/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9301 - binary_accuracy: 0.8633 - loss: 0.3911 - precision: 0.8642 - recall: 0.8055 - val_auc: 0.9167 - val_binary_accuracy: 0.8279 - val_loss: 0.4211 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 102/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9288 - binary_accuracy: 0.8602 - loss: 0.3934 - precision: 0.8605 - recall: 0.8022 - val_auc: 0.9167 - val_binary_accuracy: 0.8256 - val_loss: 0.4205 - val_precision: 0.8176 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 103/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9297 - binary_accuracy: 0.8602 - loss: 0.3915 - precision: 0.8596 - recall: 0.8047 - val_auc: 0.9169 - val_binary_accuracy: 0.8256 - val_loss: 0.4198 - val_precision: 0.8176 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 104/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9293 - binary_accuracy: 0.8602 - loss: 0.3918 - precision: 0.8591 - recall: 0.8040 - val_auc: 0.9169 - val_binary_accuracy: 0.8256 - val_loss: 0.4193 - val_precision: 0.8176 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 105/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9311 - binary_accuracy: 0.8617 - loss: 0.3884 - precision: 0.8605 - recall: 0.8087 - val_auc: 0.9173 - val_binary_accuracy: 0.8256 - val_loss: 0.4187 - val_precision: 0.8176 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 106/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9314 - binary_accuracy: 0.8641 - loss: 0.3870 - precision: 0.8621 - recall: 0.8117 - val_auc: 0.9173 - val_binary_accuracy: 0.8233 - val_loss: 0.4182 - val_precision: 0.8129 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 107/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9309 - binary_accuracy: 0.8641 - loss: 0.3882 - precision: 0.8621 - recall: 0.8117 - val_auc: 0.9176 - val_binary_accuracy: 0.8233 - val_loss: 0.4177 - val_precision: 0.8129 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 108/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9301 - binary_accuracy: 0.8625 - loss: 0.3893 - precision: 0.8599 - recall: 0.8095 - val_auc: 0.9179 - val_binary_accuracy: 0.8233 - val_loss: 0.4173 - val_precision: 0.8129 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 109/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9303 - binary_accuracy: 0.8633 - loss: 0.3887 - precision: 0.8605 - recall: 0.8117 - val_auc: 0.9181 - val_binary_accuracy: 0.8209 - val_loss: 0.4168 - val_precision: 0.8081 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 110/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9305 - binary_accuracy: 0.8648 - loss: 0.3878 - precision: 0.8605 - recall: 0.8147 - val_auc: 0.9183 - val_binary_accuracy: 0.8233 - val_loss: 0.4164 - val_precision: 0.8092 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 111/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9309 - binary_accuracy: 0.8648 - loss: 0.3865 - precision: 0.8610 - recall: 0.8154 - val_auc: 0.9184 - val_binary_accuracy: 0.8209 - val_loss: 0.4160 - val_precision: 0.8081 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 112/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9304 - binary_accuracy: 0.8648 - loss: 0.3875 - precision: 0.8607 - recall: 0.8150 - val_auc: 0.9186 - val_binary_accuracy: 0.8209 - val_loss: 0.4156 - val_precision: 0.8081 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 113/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9309 - binary_accuracy: 0.8648 - loss: 0.3866 - precision: 0.8607 - recall: 0.8150 - val_auc: 0.9187 - val_binary_accuracy: 0.8233 - val_loss: 0.4152 - val_precision: 0.8092 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 114/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9318 - binary_accuracy: 0.8656 - loss: 0.3845 - precision: 0.8607 - recall: 0.8165 - val_auc: 0.9189 - val_binary_accuracy: 0.8209 - val_loss: 0.4149 - val_precision: 0.8081 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 115/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9326 - binary_accuracy: 0.8672 - loss: 0.3823 - precision: 0.8632 - recall: 0.8190 - val_auc: 0.9190 - val_binary_accuracy: 0.8209 - val_loss: 0.4145 - val_precision: 0.8081 - val_recall: 0.7596 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 116/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9315 - binary_accuracy: 0.8672 - loss: 0.3846 - precision: 0.8615 - recall: 0.8205 - val_auc: 0.9191 - val_binary_accuracy: 0.8233 - val_loss: 0.4141 - val_precision: 0.8092 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 117/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9316 - binary_accuracy: 0.8664 - loss: 0.3844 - precision: 0.8613 - recall: 0.8187 - val_auc: 0.9191 - val_binary_accuracy: 0.8256 - val_loss: 0.4138 - val_precision: 0.8140 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 118/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9321 - binary_accuracy: 0.8672 - loss: 0.3831 - precision: 0.8627 - recall: 0.8183 - val_auc: 0.9193 - val_binary_accuracy: 0.8256 - val_loss: 0.4135 - val_precision: 0.8140 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 119/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9320 - binary_accuracy: 0.8664 - loss: 0.3835 - precision: 0.8618 - recall: 0.8193 - val_auc: 0.9196 - val_binary_accuracy: 0.8256 - val_loss: 0.4131 - val_precision: 0.8140 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 120/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9320 - binary_accuracy: 0.8672 - loss: 0.3835 - precision: 0.8635 - recall: 0.8193 - val_auc: 0.9197 - val_binary_accuracy: 0.8279 - val_loss: 0.4128 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 121/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9321 - binary_accuracy: 0.8664 - loss: 0.3832 - precision: 0.8618 - recall: 0.8193 - val_auc: 0.9199 - val_binary_accuracy: 0.8279 - val_loss: 0.4125 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 122/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9327 - binary_accuracy: 0.8672 - loss: 0.3820 - precision: 0.8640 - recall: 0.8200 - val_auc: 0.9201 - val_binary_accuracy: 0.8279 - val_loss: 0.4122 - val_precision: 0.8187 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 123/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9329 - binary_accuracy: 0.8672 - loss: 0.3809 - precision: 0.8629 - recall: 0.8187 - val_auc: 0.9203 - val_binary_accuracy: 0.8302 - val_loss: 0.4119 - val_precision: 0.8235 - val_recall: 0.7650 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 124/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9326 - binary_accuracy: 0.8656 - loss: 0.3817 - precision: 0.8602 - recall: 0.8193 - val_auc: 0.9206 - val_binary_accuracy: 0.8326 - val_loss: 0.4116 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 125/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9332 - binary_accuracy: 0.8664 - loss: 0.3800 - precision: 0.8615 - recall: 0.8190 - val_auc: 0.9207 - val_binary_accuracy: 0.8326 - val_loss: 0.4113 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 126/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9332 - binary_accuracy: 0.8656 - loss: 0.3800 - precision: 0.8604 - recall: 0.8197 - val_auc: 0.9209 - val_binary_accuracy: 0.8326 - val_loss: 0.4111 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 127/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9334 - binary_accuracy: 0.8680 - loss: 0.3791 - precision: 0.8604 - recall: 0.8242 - val_auc: 0.9212 - val_binary_accuracy: 0.8326 - val_loss: 0.4108 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 128/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9334 - binary_accuracy: 0.8680 - loss: 0.3793 - precision: 0.8618 - recall: 0.8223 - val_auc: 0.9211 - val_binary_accuracy: 0.8326 - val_loss: 0.4105 - val_precision: 0.8246 - val_recall: 0.7705 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 129/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9336 - binary_accuracy: 0.8687 - loss: 0.3785 - precision: 0.8626 - recall: 0.8248 - val_auc: 0.9212 - val_binary_accuracy: 0.8349 - val_loss: 0.4102 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 130/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9331 - binary_accuracy: 0.8672 - loss: 0.3791 - precision: 0.8582 - recall: 0.8235 - val_auc: 0.9213 - val_binary_accuracy: 0.8349 - val_loss: 0.4100 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 131/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9337 - binary_accuracy: 0.8680 - loss: 0.3786 - precision: 0.8612 - recall: 0.8251 - val_auc: 0.9215 - val_binary_accuracy: 0.8372 - val_loss: 0.4097 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 132/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9344 - binary_accuracy: 0.8687 - loss: 0.3768 - precision: 0.8604 - recall: 0.8257 - val_auc: 0.9216 - val_binary_accuracy: 0.8372 - val_loss: 0.4095 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 133/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9339 - binary_accuracy: 0.8695 - loss: 0.3777 - precision: 0.8607 - recall: 0.8275 - val_auc: 0.9217 - val_binary_accuracy: 0.8372 - val_loss: 0.4092 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 134/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9346 - binary_accuracy: 0.8695 - loss: 0.3765 - precision: 0.8610 - recall: 0.8278 - val_auc: 0.9219 - val_binary_accuracy: 0.8372 - val_loss: 0.4090 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 135/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9343 - binary_accuracy: 0.8703 - loss: 0.3765 - precision: 0.8623 - recall: 0.8275 - val_auc: 0.9221 - val_binary_accuracy: 0.8372 - val_loss: 0.4087 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 136/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9348 - binary_accuracy: 0.8719 - loss: 0.3759 - precision: 0.8664 - recall: 0.8285 - val_auc: 0.9222 - val_binary_accuracy: 0.8372 - val_loss: 0.4085 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 137/300                                                                     \n",
      "\n",
      "80/80 - 1s - 7ms/step - auc: 0.9345 - binary_accuracy: 0.8695 - loss: 0.3761 - precision: 0.8623 - recall: 0.8260 - val_auc: 0.9221 - val_binary_accuracy: 0.8372 - val_loss: 0.4082 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 138/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9347 - binary_accuracy: 0.8687 - loss: 0.3756 - precision: 0.8623 - recall: 0.8245 - val_auc: 0.9222 - val_binary_accuracy: 0.8372 - val_loss: 0.4080 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 139/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9346 - binary_accuracy: 0.8687 - loss: 0.3759 - precision: 0.8615 - recall: 0.8235 - val_auc: 0.9222 - val_binary_accuracy: 0.8395 - val_loss: 0.4078 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 140/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8695 - loss: 0.3748 - precision: 0.8645 - recall: 0.8251 - val_auc: 0.9224 - val_binary_accuracy: 0.8395 - val_loss: 0.4076 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 141/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9351 - binary_accuracy: 0.8687 - loss: 0.3751 - precision: 0.8637 - recall: 0.8227 - val_auc: 0.9225 - val_binary_accuracy: 0.8395 - val_loss: 0.4074 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 142/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9351 - binary_accuracy: 0.8703 - loss: 0.3746 - precision: 0.8623 - recall: 0.8275 - val_auc: 0.9227 - val_binary_accuracy: 0.8395 - val_loss: 0.4071 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 143/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9361 - binary_accuracy: 0.8703 - loss: 0.3727 - precision: 0.8656 - recall: 0.8245 - val_auc: 0.9228 - val_binary_accuracy: 0.8395 - val_loss: 0.4070 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 144/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9357 - binary_accuracy: 0.8695 - loss: 0.3731 - precision: 0.8646 - recall: 0.8217 - val_auc: 0.9229 - val_binary_accuracy: 0.8395 - val_loss: 0.4068 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 145/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9352 - binary_accuracy: 0.8687 - loss: 0.3744 - precision: 0.8635 - recall: 0.8223 - val_auc: 0.9230 - val_binary_accuracy: 0.8395 - val_loss: 0.4066 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 146/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9357 - binary_accuracy: 0.8695 - loss: 0.3732 - precision: 0.8637 - recall: 0.8242 - val_auc: 0.9230 - val_binary_accuracy: 0.8395 - val_loss: 0.4063 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 147/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9352 - binary_accuracy: 0.8680 - loss: 0.3741 - precision: 0.8618 - recall: 0.8223 - val_auc: 0.9232 - val_binary_accuracy: 0.8395 - val_loss: 0.4061 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 148/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9354 - binary_accuracy: 0.8680 - loss: 0.3731 - precision: 0.8613 - recall: 0.8217 - val_auc: 0.9234 - val_binary_accuracy: 0.8395 - val_loss: 0.4060 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 149/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9356 - binary_accuracy: 0.8687 - loss: 0.3728 - precision: 0.8632 - recall: 0.8220 - val_auc: 0.9235 - val_binary_accuracy: 0.8395 - val_loss: 0.4058 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 150/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9365 - binary_accuracy: 0.8711 - loss: 0.3712 - precision: 0.8656 - recall: 0.8260 - val_auc: 0.9236 - val_binary_accuracy: 0.8395 - val_loss: 0.4056 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 151/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9365 - binary_accuracy: 0.8695 - loss: 0.3708 - precision: 0.8654 - recall: 0.8227 - val_auc: 0.9238 - val_binary_accuracy: 0.8395 - val_loss: 0.4054 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 152/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9367 - binary_accuracy: 0.8695 - loss: 0.3702 - precision: 0.8654 - recall: 0.8227 - val_auc: 0.9239 - val_binary_accuracy: 0.8395 - val_loss: 0.4052 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 153/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9363 - binary_accuracy: 0.8703 - loss: 0.3712 - precision: 0.8659 - recall: 0.8248 - val_auc: 0.9240 - val_binary_accuracy: 0.8395 - val_loss: 0.4051 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 154/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8695 - loss: 0.3716 - precision: 0.8640 - recall: 0.8245 - val_auc: 0.9242 - val_binary_accuracy: 0.8395 - val_loss: 0.4049 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 155/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9365 - binary_accuracy: 0.8703 - loss: 0.3707 - precision: 0.8642 - recall: 0.8263 - val_auc: 0.9243 - val_binary_accuracy: 0.8395 - val_loss: 0.4047 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 156/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8703 - loss: 0.3708 - precision: 0.8659 - recall: 0.8248 - val_auc: 0.9243 - val_binary_accuracy: 0.8372 - val_loss: 0.4046 - val_precision: 0.8304 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 157/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8711 - loss: 0.3696 - precision: 0.8662 - recall: 0.8266 - val_auc: 0.9243 - val_binary_accuracy: 0.8372 - val_loss: 0.4044 - val_precision: 0.8304 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 158/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9360 - binary_accuracy: 0.8695 - loss: 0.3714 - precision: 0.8640 - recall: 0.8245 - val_auc: 0.9245 - val_binary_accuracy: 0.8372 - val_loss: 0.4043 - val_precision: 0.8304 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 159/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8719 - loss: 0.3668 - precision: 0.8659 - recall: 0.8278 - val_auc: 0.9245 - val_binary_accuracy: 0.8349 - val_loss: 0.4041 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 160/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9369 - binary_accuracy: 0.8711 - loss: 0.3693 - precision: 0.8642 - recall: 0.8278 - val_auc: 0.9248 - val_binary_accuracy: 0.8349 - val_loss: 0.4039 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 161/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9368 - binary_accuracy: 0.8711 - loss: 0.3696 - precision: 0.8656 - recall: 0.8260 - val_auc: 0.9249 - val_binary_accuracy: 0.8349 - val_loss: 0.4038 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 162/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9376 - binary_accuracy: 0.8719 - loss: 0.3676 - precision: 0.8673 - recall: 0.8260 - val_auc: 0.9248 - val_binary_accuracy: 0.8349 - val_loss: 0.4037 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 163/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8719 - loss: 0.3675 - precision: 0.8648 - recall: 0.8300 - val_auc: 0.9249 - val_binary_accuracy: 0.8349 - val_loss: 0.4035 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 164/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9369 - binary_accuracy: 0.8703 - loss: 0.3693 - precision: 0.8637 - recall: 0.8257 - val_auc: 0.9250 - val_binary_accuracy: 0.8349 - val_loss: 0.4034 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 165/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9369 - binary_accuracy: 0.8703 - loss: 0.3693 - precision: 0.8648 - recall: 0.8270 - val_auc: 0.9249 - val_binary_accuracy: 0.8349 - val_loss: 0.4032 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 166/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9368 - binary_accuracy: 0.8711 - loss: 0.3698 - precision: 0.8648 - recall: 0.8285 - val_auc: 0.9252 - val_binary_accuracy: 0.8349 - val_loss: 0.4031 - val_precision: 0.8256 - val_recall: 0.7760 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 167/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8711 - loss: 0.3695 - precision: 0.8648 - recall: 0.8285 - val_auc: 0.9252 - val_binary_accuracy: 0.8372 - val_loss: 0.4029 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 168/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9377 - binary_accuracy: 0.8727 - loss: 0.3677 - precision: 0.8662 - recall: 0.8297 - val_auc: 0.9253 - val_binary_accuracy: 0.8372 - val_loss: 0.4028 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 169/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9373 - binary_accuracy: 0.8711 - loss: 0.3687 - precision: 0.8645 - recall: 0.8282 - val_auc: 0.9254 - val_binary_accuracy: 0.8372 - val_loss: 0.4027 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 170/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9386 - binary_accuracy: 0.8719 - loss: 0.3655 - precision: 0.8648 - recall: 0.8300 - val_auc: 0.9254 - val_binary_accuracy: 0.8372 - val_loss: 0.4025 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 171/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8719 - loss: 0.3667 - precision: 0.8642 - recall: 0.8294 - val_auc: 0.9254 - val_binary_accuracy: 0.8372 - val_loss: 0.4024 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 172/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9380 - binary_accuracy: 0.8719 - loss: 0.3668 - precision: 0.8662 - recall: 0.8282 - val_auc: 0.9255 - val_binary_accuracy: 0.8372 - val_loss: 0.4023 - val_precision: 0.8266 - val_recall: 0.7814 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 173/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9381 - binary_accuracy: 0.8703 - loss: 0.3663 - precision: 0.8640 - recall: 0.8260 - val_auc: 0.9255 - val_binary_accuracy: 0.8395 - val_loss: 0.4021 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 174/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9381 - binary_accuracy: 0.8711 - loss: 0.3662 - precision: 0.8623 - recall: 0.8290 - val_auc: 0.9256 - val_binary_accuracy: 0.8395 - val_loss: 0.4020 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 175/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9383 - binary_accuracy: 0.8703 - loss: 0.3659 - precision: 0.8621 - recall: 0.8272 - val_auc: 0.9257 - val_binary_accuracy: 0.8395 - val_loss: 0.4019 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 176/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9377 - binary_accuracy: 0.8687 - loss: 0.3672 - precision: 0.8618 - recall: 0.8239 - val_auc: 0.9257 - val_binary_accuracy: 0.8395 - val_loss: 0.4017 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 177/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9382 - binary_accuracy: 0.8695 - loss: 0.3660 - precision: 0.8621 - recall: 0.8257 - val_auc: 0.9256 - val_binary_accuracy: 0.8395 - val_loss: 0.4016 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 178/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9378 - binary_accuracy: 0.8687 - loss: 0.3671 - precision: 0.8621 - recall: 0.8242 - val_auc: 0.9256 - val_binary_accuracy: 0.8395 - val_loss: 0.4015 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 179/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9381 - binary_accuracy: 0.8687 - loss: 0.3661 - precision: 0.8621 - recall: 0.8242 - val_auc: 0.9257 - val_binary_accuracy: 0.8395 - val_loss: 0.4014 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 180/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8719 - loss: 0.3628 - precision: 0.8629 - recall: 0.8312 - val_auc: 0.9257 - val_binary_accuracy: 0.8395 - val_loss: 0.4013 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 181/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9394 - binary_accuracy: 0.8703 - loss: 0.3631 - precision: 0.8623 - recall: 0.8275 - val_auc: 0.9257 - val_binary_accuracy: 0.8395 - val_loss: 0.4012 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 182/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9382 - binary_accuracy: 0.8687 - loss: 0.3658 - precision: 0.8621 - recall: 0.8242 - val_auc: 0.9258 - val_binary_accuracy: 0.8395 - val_loss: 0.4011 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 183/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8695 - loss: 0.3664 - precision: 0.8640 - recall: 0.8245 - val_auc: 0.9259 - val_binary_accuracy: 0.8395 - val_loss: 0.4010 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 184/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9380 - binary_accuracy: 0.8687 - loss: 0.3659 - precision: 0.8621 - recall: 0.8242 - val_auc: 0.9260 - val_binary_accuracy: 0.8395 - val_loss: 0.4008 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 185/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9383 - binary_accuracy: 0.8703 - loss: 0.3651 - precision: 0.8637 - recall: 0.8257 - val_auc: 0.9259 - val_binary_accuracy: 0.8395 - val_loss: 0.4007 - val_precision: 0.8276 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 186/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9386 - binary_accuracy: 0.8703 - loss: 0.3645 - precision: 0.8651 - recall: 0.8239 - val_auc: 0.9261 - val_binary_accuracy: 0.8395 - val_loss: 0.4006 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 187/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9382 - binary_accuracy: 0.8695 - loss: 0.3654 - precision: 0.8637 - recall: 0.8242 - val_auc: 0.9260 - val_binary_accuracy: 0.8395 - val_loss: 0.4005 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 188/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9383 - binary_accuracy: 0.8695 - loss: 0.3654 - precision: 0.8640 - recall: 0.8245 - val_auc: 0.9259 - val_binary_accuracy: 0.8395 - val_loss: 0.4004 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 189/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8711 - loss: 0.3639 - precision: 0.8651 - recall: 0.8254 - val_auc: 0.9262 - val_binary_accuracy: 0.8395 - val_loss: 0.4004 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 190/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9388 - binary_accuracy: 0.8703 - loss: 0.3639 - precision: 0.8654 - recall: 0.8242 - val_auc: 0.9261 - val_binary_accuracy: 0.8395 - val_loss: 0.4002 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 191/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9391 - binary_accuracy: 0.8695 - loss: 0.3634 - precision: 0.8645 - recall: 0.8251 - val_auc: 0.9261 - val_binary_accuracy: 0.8395 - val_loss: 0.4001 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 192/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9385 - binary_accuracy: 0.8687 - loss: 0.3645 - precision: 0.8610 - recall: 0.8263 - val_auc: 0.9262 - val_binary_accuracy: 0.8395 - val_loss: 0.4000 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 193/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9390 - binary_accuracy: 0.8695 - loss: 0.3634 - precision: 0.8626 - recall: 0.8263 - val_auc: 0.9263 - val_binary_accuracy: 0.8395 - val_loss: 0.4000 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 194/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9390 - binary_accuracy: 0.8703 - loss: 0.3636 - precision: 0.8645 - recall: 0.8266 - val_auc: 0.9263 - val_binary_accuracy: 0.8395 - val_loss: 0.3999 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 195/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9399 - binary_accuracy: 0.8711 - loss: 0.3615 - precision: 0.8664 - recall: 0.8270 - val_auc: 0.9263 - val_binary_accuracy: 0.8395 - val_loss: 0.3998 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 196/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9393 - binary_accuracy: 0.8711 - loss: 0.3630 - precision: 0.8662 - recall: 0.8266 - val_auc: 0.9265 - val_binary_accuracy: 0.8395 - val_loss: 0.3997 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 197/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9404 - binary_accuracy: 0.8711 - loss: 0.3602 - precision: 0.8645 - recall: 0.8282 - val_auc: 0.9264 - val_binary_accuracy: 0.8395 - val_loss: 0.3996 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 198/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9401 - binary_accuracy: 0.8727 - loss: 0.3607 - precision: 0.8662 - recall: 0.8297 - val_auc: 0.9266 - val_binary_accuracy: 0.8395 - val_loss: 0.3995 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 199/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8719 - loss: 0.3616 - precision: 0.8645 - recall: 0.8297 - val_auc: 0.9265 - val_binary_accuracy: 0.8395 - val_loss: 0.3994 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 200/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9390 - binary_accuracy: 0.8703 - loss: 0.3633 - precision: 0.8642 - recall: 0.8263 - val_auc: 0.9266 - val_binary_accuracy: 0.8395 - val_loss: 0.3993 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 201/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9392 - binary_accuracy: 0.8703 - loss: 0.3625 - precision: 0.8637 - recall: 0.8257 - val_auc: 0.9266 - val_binary_accuracy: 0.8395 - val_loss: 0.3992 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 202/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9392 - binary_accuracy: 0.8703 - loss: 0.3628 - precision: 0.8642 - recall: 0.8263 - val_auc: 0.9265 - val_binary_accuracy: 0.8395 - val_loss: 0.3991 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 203/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9393 - binary_accuracy: 0.8711 - loss: 0.3624 - precision: 0.8642 - recall: 0.8278 - val_auc: 0.9266 - val_binary_accuracy: 0.8395 - val_loss: 0.3991 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 204/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9401 - binary_accuracy: 0.8727 - loss: 0.3605 - precision: 0.8659 - recall: 0.8294 - val_auc: 0.9265 - val_binary_accuracy: 0.8395 - val_loss: 0.3989 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 205/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9397 - binary_accuracy: 0.8719 - loss: 0.3614 - precision: 0.8656 - recall: 0.8275 - val_auc: 0.9266 - val_binary_accuracy: 0.8395 - val_loss: 0.3988 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 206/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9396 - binary_accuracy: 0.8703 - loss: 0.3615 - precision: 0.8637 - recall: 0.8257 - val_auc: 0.9267 - val_binary_accuracy: 0.8372 - val_loss: 0.3988 - val_precision: 0.8229 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 207/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9403 - binary_accuracy: 0.8703 - loss: 0.3602 - precision: 0.8637 - recall: 0.8257 - val_auc: 0.9267 - val_binary_accuracy: 0.8372 - val_loss: 0.3987 - val_precision: 0.8229 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 208/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9398 - binary_accuracy: 0.8703 - loss: 0.3612 - precision: 0.8654 - recall: 0.8242 - val_auc: 0.9268 - val_binary_accuracy: 0.8372 - val_loss: 0.3986 - val_precision: 0.8229 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 209/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9394 - binary_accuracy: 0.8695 - loss: 0.3624 - precision: 0.8642 - recall: 0.8248 - val_auc: 0.9268 - val_binary_accuracy: 0.8372 - val_loss: 0.3985 - val_precision: 0.8229 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 210/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9398 - binary_accuracy: 0.8703 - loss: 0.3611 - precision: 0.8645 - recall: 0.8266 - val_auc: 0.9269 - val_binary_accuracy: 0.8372 - val_loss: 0.3984 - val_precision: 0.8229 - val_recall: 0.7869 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 211/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9394 - binary_accuracy: 0.8695 - loss: 0.3617 - precision: 0.8635 - recall: 0.8239 - val_auc: 0.9269 - val_binary_accuracy: 0.8395 - val_loss: 0.3983 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 212/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9394 - binary_accuracy: 0.8695 - loss: 0.3617 - precision: 0.8640 - recall: 0.8245 - val_auc: 0.9269 - val_binary_accuracy: 0.8395 - val_loss: 0.3982 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 213/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9401 - binary_accuracy: 0.8703 - loss: 0.3603 - precision: 0.8642 - recall: 0.8263 - val_auc: 0.9269 - val_binary_accuracy: 0.8395 - val_loss: 0.3981 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 214/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9397 - binary_accuracy: 0.8703 - loss: 0.3612 - precision: 0.8659 - recall: 0.8248 - val_auc: 0.9269 - val_binary_accuracy: 0.8395 - val_loss: 0.3980 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 215/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9400 - binary_accuracy: 0.8703 - loss: 0.3603 - precision: 0.8654 - recall: 0.8242 - val_auc: 0.9270 - val_binary_accuracy: 0.8395 - val_loss: 0.3979 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 216/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9404 - binary_accuracy: 0.8703 - loss: 0.3591 - precision: 0.8656 - recall: 0.8245 - val_auc: 0.9269 - val_binary_accuracy: 0.8395 - val_loss: 0.3978 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 217/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9404 - binary_accuracy: 0.8711 - loss: 0.3591 - precision: 0.8640 - recall: 0.8275 - val_auc: 0.9270 - val_binary_accuracy: 0.8395 - val_loss: 0.3977 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 218/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9397 - binary_accuracy: 0.8695 - loss: 0.3613 - precision: 0.8645 - recall: 0.8251 - val_auc: 0.9269 - val_binary_accuracy: 0.8395 - val_loss: 0.3976 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 219/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9406 - binary_accuracy: 0.8703 - loss: 0.3586 - precision: 0.8656 - recall: 0.8245 - val_auc: 0.9268 - val_binary_accuracy: 0.8395 - val_loss: 0.3976 - val_precision: 0.8239 - val_recall: 0.7923 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 220/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9398 - binary_accuracy: 0.8695 - loss: 0.3607 - precision: 0.8637 - recall: 0.8242 - val_auc: 0.9268 - val_binary_accuracy: 0.8419 - val_loss: 0.3974 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 221/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9401 - binary_accuracy: 0.8703 - loss: 0.3598 - precision: 0.8637 - recall: 0.8257 - val_auc: 0.9269 - val_binary_accuracy: 0.8419 - val_loss: 0.3973 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 222/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9404 - binary_accuracy: 0.8695 - loss: 0.3593 - precision: 0.8642 - recall: 0.8248 - val_auc: 0.9270 - val_binary_accuracy: 0.8419 - val_loss: 0.3972 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 223/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9405 - binary_accuracy: 0.8703 - loss: 0.3590 - precision: 0.8637 - recall: 0.8257 - val_auc: 0.9270 - val_binary_accuracy: 0.8419 - val_loss: 0.3972 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 224/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9400 - binary_accuracy: 0.8703 - loss: 0.3598 - precision: 0.8649 - recall: 0.8235 - val_auc: 0.9271 - val_binary_accuracy: 0.8419 - val_loss: 0.3971 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 225/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9403 - binary_accuracy: 0.8703 - loss: 0.3597 - precision: 0.8659 - recall: 0.8248 - val_auc: 0.9272 - val_binary_accuracy: 0.8419 - val_loss: 0.3970 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 226/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9405 - binary_accuracy: 0.8711 - loss: 0.3588 - precision: 0.8645 - recall: 0.8282 - val_auc: 0.9272 - val_binary_accuracy: 0.8419 - val_loss: 0.3969 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 227/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9411 - binary_accuracy: 0.8719 - loss: 0.3579 - precision: 0.8667 - recall: 0.8288 - val_auc: 0.9272 - val_binary_accuracy: 0.8419 - val_loss: 0.3968 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 228/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9405 - binary_accuracy: 0.8711 - loss: 0.3590 - precision: 0.8645 - recall: 0.8282 - val_auc: 0.9273 - val_binary_accuracy: 0.8419 - val_loss: 0.3967 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 229/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9409 - binary_accuracy: 0.8711 - loss: 0.3578 - precision: 0.8648 - recall: 0.8285 - val_auc: 0.9274 - val_binary_accuracy: 0.8419 - val_loss: 0.3967 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 230/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9409 - binary_accuracy: 0.8711 - loss: 0.3578 - precision: 0.8662 - recall: 0.8266 - val_auc: 0.9274 - val_binary_accuracy: 0.8419 - val_loss: 0.3966 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 231/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9403 - binary_accuracy: 0.8703 - loss: 0.3593 - precision: 0.8640 - recall: 0.8260 - val_auc: 0.9274 - val_binary_accuracy: 0.8419 - val_loss: 0.3965 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 232/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9408 - binary_accuracy: 0.8719 - loss: 0.3580 - precision: 0.8676 - recall: 0.8263 - val_auc: 0.9275 - val_binary_accuracy: 0.8419 - val_loss: 0.3964 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 233/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8703 - loss: 0.3554 - precision: 0.8642 - recall: 0.8263 - val_auc: 0.9274 - val_binary_accuracy: 0.8419 - val_loss: 0.3963 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 234/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9406 - binary_accuracy: 0.8695 - loss: 0.3585 - precision: 0.8626 - recall: 0.8263 - val_auc: 0.9275 - val_binary_accuracy: 0.8419 - val_loss: 0.3962 - val_precision: 0.8249 - val_recall: 0.7978 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 235/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9403 - binary_accuracy: 0.8695 - loss: 0.3591 - precision: 0.8618 - recall: 0.8254 - val_auc: 0.9275 - val_binary_accuracy: 0.8442 - val_loss: 0.3962 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 236/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8711 - loss: 0.3564 - precision: 0.8631 - recall: 0.8300 - val_auc: 0.9275 - val_binary_accuracy: 0.8442 - val_loss: 0.3961 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 237/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9406 - binary_accuracy: 0.8703 - loss: 0.3583 - precision: 0.8626 - recall: 0.8278 - val_auc: 0.9275 - val_binary_accuracy: 0.8442 - val_loss: 0.3960 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 238/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8734 - loss: 0.3561 - precision: 0.8669 - recall: 0.8321 - val_auc: 0.9276 - val_binary_accuracy: 0.8442 - val_loss: 0.3959 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 239/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9409 - binary_accuracy: 0.8719 - loss: 0.3575 - precision: 0.8634 - recall: 0.8318 - val_auc: 0.9277 - val_binary_accuracy: 0.8442 - val_loss: 0.3958 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 240/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8719 - loss: 0.3578 - precision: 0.8639 - recall: 0.8324 - val_auc: 0.9277 - val_binary_accuracy: 0.8442 - val_loss: 0.3957 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 241/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9407 - binary_accuracy: 0.8727 - loss: 0.3575 - precision: 0.8626 - recall: 0.8324 - val_auc: 0.9277 - val_binary_accuracy: 0.8442 - val_loss: 0.3956 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 242/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8719 - loss: 0.3570 - precision: 0.8631 - recall: 0.8315 - val_auc: 0.9278 - val_binary_accuracy: 0.8442 - val_loss: 0.3955 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 243/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8727 - loss: 0.3551 - precision: 0.8653 - recall: 0.8321 - val_auc: 0.9278 - val_binary_accuracy: 0.8442 - val_loss: 0.3955 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 244/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8727 - loss: 0.3566 - precision: 0.8655 - recall: 0.8324 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3954 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 245/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8727 - loss: 0.3569 - precision: 0.8636 - recall: 0.8336 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3953 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 246/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8727 - loss: 0.3576 - precision: 0.8634 - recall: 0.8333 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3952 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 247/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8734 - loss: 0.3560 - precision: 0.8658 - recall: 0.8342 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3951 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 248/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8750 - loss: 0.3544 - precision: 0.8655 - recall: 0.8370 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3950 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 249/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9426 - binary_accuracy: 0.8742 - loss: 0.3532 - precision: 0.8642 - recall: 0.8373 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3950 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 250/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9409 - binary_accuracy: 0.8727 - loss: 0.3575 - precision: 0.8639 - recall: 0.8339 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3949 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 251/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8734 - loss: 0.3556 - precision: 0.8634 - recall: 0.8349 - val_auc: 0.9279 - val_binary_accuracy: 0.8442 - val_loss: 0.3948 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 252/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8734 - loss: 0.3568 - precision: 0.8639 - recall: 0.8355 - val_auc: 0.9280 - val_binary_accuracy: 0.8442 - val_loss: 0.3947 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 253/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8742 - loss: 0.3541 - precision: 0.8674 - recall: 0.8342 - val_auc: 0.9280 - val_binary_accuracy: 0.8442 - val_loss: 0.3947 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 254/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8734 - loss: 0.3555 - precision: 0.8644 - recall: 0.8361 - val_auc: 0.9281 - val_binary_accuracy: 0.8442 - val_loss: 0.3946 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 255/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8734 - loss: 0.3558 - precision: 0.8650 - recall: 0.8333 - val_auc: 0.9281 - val_binary_accuracy: 0.8442 - val_loss: 0.3945 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 256/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8742 - loss: 0.3553 - precision: 0.8658 - recall: 0.8358 - val_auc: 0.9282 - val_binary_accuracy: 0.8442 - val_loss: 0.3944 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 257/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8734 - loss: 0.3538 - precision: 0.8653 - recall: 0.8336 - val_auc: 0.9281 - val_binary_accuracy: 0.8465 - val_loss: 0.3943 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 258/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8742 - loss: 0.3538 - precision: 0.8653 - recall: 0.8352 - val_auc: 0.9282 - val_binary_accuracy: 0.8465 - val_loss: 0.3943 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 259/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8734 - loss: 0.3549 - precision: 0.8644 - recall: 0.8361 - val_auc: 0.9282 - val_binary_accuracy: 0.8465 - val_loss: 0.3942 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 260/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8734 - loss: 0.3550 - precision: 0.8636 - recall: 0.8352 - val_auc: 0.9282 - val_binary_accuracy: 0.8465 - val_loss: 0.3941 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 261/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8727 - loss: 0.3560 - precision: 0.8631 - recall: 0.8330 - val_auc: 0.9282 - val_binary_accuracy: 0.8465 - val_loss: 0.3940 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 262/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8734 - loss: 0.3557 - precision: 0.8639 - recall: 0.8355 - val_auc: 0.9283 - val_binary_accuracy: 0.8442 - val_loss: 0.3939 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 263/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8750 - loss: 0.3508 - precision: 0.8639 - recall: 0.8385 - val_auc: 0.9284 - val_binary_accuracy: 0.8465 - val_loss: 0.3939 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 264/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8727 - loss: 0.3555 - precision: 0.8631 - recall: 0.8330 - val_auc: 0.9284 - val_binary_accuracy: 0.8465 - val_loss: 0.3938 - val_precision: 0.8305 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 265/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8734 - loss: 0.3547 - precision: 0.8636 - recall: 0.8352 - val_auc: 0.9284 - val_binary_accuracy: 0.8442 - val_loss: 0.3937 - val_precision: 0.8258 - val_recall: 0.8033 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 266/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8727 - loss: 0.3556 - precision: 0.8639 - recall: 0.8339 - val_auc: 0.9284 - val_binary_accuracy: 0.8465 - val_loss: 0.3936 - val_precision: 0.8268 - val_recall: 0.8087 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 267/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8734 - loss: 0.3544 - precision: 0.8653 - recall: 0.8336 - val_auc: 0.9284 - val_binary_accuracy: 0.8465 - val_loss: 0.3936 - val_precision: 0.8268 - val_recall: 0.8087 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 268/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8727 - loss: 0.3552 - precision: 0.8636 - recall: 0.8336 - val_auc: 0.9284 - val_binary_accuracy: 0.8465 - val_loss: 0.3935 - val_precision: 0.8268 - val_recall: 0.8087 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 269/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8727 - loss: 0.3550 - precision: 0.8631 - recall: 0.8330 - val_auc: 0.9285 - val_binary_accuracy: 0.8465 - val_loss: 0.3934 - val_precision: 0.8268 - val_recall: 0.8087 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 270/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8742 - loss: 0.3541 - precision: 0.8653 - recall: 0.8352 - val_auc: 0.9285 - val_binary_accuracy: 0.8465 - val_loss: 0.3933 - val_precision: 0.8268 - val_recall: 0.8087 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 271/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8734 - loss: 0.3533 - precision: 0.8639 - recall: 0.8355 - val_auc: 0.9285 - val_binary_accuracy: 0.8488 - val_loss: 0.3933 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 272/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8734 - loss: 0.3528 - precision: 0.8653 - recall: 0.8336 - val_auc: 0.9284 - val_binary_accuracy: 0.8488 - val_loss: 0.3932 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 273/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8734 - loss: 0.3528 - precision: 0.8636 - recall: 0.8352 - val_auc: 0.9285 - val_binary_accuracy: 0.8488 - val_loss: 0.3931 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 274/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8734 - loss: 0.3539 - precision: 0.8634 - recall: 0.8349 - val_auc: 0.9284 - val_binary_accuracy: 0.8488 - val_loss: 0.3930 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 275/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8734 - loss: 0.3527 - precision: 0.8639 - recall: 0.8355 - val_auc: 0.9285 - val_binary_accuracy: 0.8488 - val_loss: 0.3929 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 276/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8734 - loss: 0.3534 - precision: 0.8636 - recall: 0.8352 - val_auc: 0.9284 - val_binary_accuracy: 0.8488 - val_loss: 0.3929 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 277/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8734 - loss: 0.3530 - precision: 0.8636 - recall: 0.8352 - val_auc: 0.9285 - val_binary_accuracy: 0.8488 - val_loss: 0.3928 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 278/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8719 - loss: 0.3541 - precision: 0.8617 - recall: 0.8333 - val_auc: 0.9286 - val_binary_accuracy: 0.8488 - val_loss: 0.3927 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 279/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8758 - loss: 0.3529 - precision: 0.8658 - recall: 0.8388 - val_auc: 0.9288 - val_binary_accuracy: 0.8488 - val_loss: 0.3926 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 280/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8734 - loss: 0.3528 - precision: 0.8636 - recall: 0.8352 - val_auc: 0.9287 - val_binary_accuracy: 0.8488 - val_loss: 0.3926 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 281/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8727 - loss: 0.3525 - precision: 0.8636 - recall: 0.8336 - val_auc: 0.9288 - val_binary_accuracy: 0.8488 - val_loss: 0.3925 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 282/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8727 - loss: 0.3539 - precision: 0.8636 - recall: 0.8336 - val_auc: 0.9288 - val_binary_accuracy: 0.8488 - val_loss: 0.3924 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 283/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8719 - loss: 0.3531 - precision: 0.8617 - recall: 0.8333 - val_auc: 0.9289 - val_binary_accuracy: 0.8488 - val_loss: 0.3923 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 284/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8750 - loss: 0.3488 - precision: 0.8620 - recall: 0.8398 - val_auc: 0.9288 - val_binary_accuracy: 0.8488 - val_loss: 0.3923 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 285/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9429 - binary_accuracy: 0.8750 - loss: 0.3513 - precision: 0.8677 - recall: 0.8361 - val_auc: 0.9289 - val_binary_accuracy: 0.8488 - val_loss: 0.3922 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 286/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8719 - loss: 0.3538 - precision: 0.8612 - recall: 0.8361 - val_auc: 0.9289 - val_binary_accuracy: 0.8488 - val_loss: 0.3921 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 287/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8719 - loss: 0.3521 - precision: 0.8606 - recall: 0.8355 - val_auc: 0.9289 - val_binary_accuracy: 0.8488 - val_loss: 0.3921 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 288/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9433 - binary_accuracy: 0.8719 - loss: 0.3503 - precision: 0.8606 - recall: 0.8355 - val_auc: 0.9289 - val_binary_accuracy: 0.8465 - val_loss: 0.3920 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 289/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8719 - loss: 0.3524 - precision: 0.8620 - recall: 0.8336 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3919 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 290/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9430 - binary_accuracy: 0.8727 - loss: 0.3509 - precision: 0.8625 - recall: 0.8358 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3918 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 291/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9433 - binary_accuracy: 0.8742 - loss: 0.3501 - precision: 0.8644 - recall: 0.8376 - val_auc: 0.9289 - val_binary_accuracy: 0.8465 - val_loss: 0.3917 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 292/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8719 - loss: 0.3526 - precision: 0.8606 - recall: 0.8355 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3917 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 293/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8727 - loss: 0.3532 - precision: 0.8628 - recall: 0.8361 - val_auc: 0.9289 - val_binary_accuracy: 0.8465 - val_loss: 0.3915 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 294/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8727 - loss: 0.3511 - precision: 0.8623 - recall: 0.8355 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3915 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 295/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8727 - loss: 0.3518 - precision: 0.8604 - recall: 0.8367 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3914 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 296/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9430 - binary_accuracy: 0.8734 - loss: 0.3502 - precision: 0.8601 - recall: 0.8379 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3913 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 297/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9425 - binary_accuracy: 0.8727 - loss: 0.3515 - precision: 0.8606 - recall: 0.8370 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3912 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 298/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9424 - binary_accuracy: 0.8711 - loss: 0.3523 - precision: 0.8609 - recall: 0.8342 - val_auc: 0.9290 - val_binary_accuracy: 0.8465 - val_loss: 0.3912 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 299/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9425 - binary_accuracy: 0.8719 - loss: 0.3517 - precision: 0.8604 - recall: 0.8352 - val_auc: 0.9291 - val_binary_accuracy: 0.8488 - val_loss: 0.3911 - val_precision: 0.8278 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "Epoch 300/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9430 - binary_accuracy: 0.8719 - loss: 0.3501 - precision: 0.8620 - recall: 0.8336 - val_auc: 0.9291 - val_binary_accuracy: 0.8465 - val_loss: 0.3910 - val_precision: 0.8232 - val_recall: 0.8142 - learning_rate: 3.0333e-05\n",
      "\n",
      "./plots/useful-worm-481/learning_rate_vs_epoch.png                                \n",
      "./plots/useful-worm-481/auc_vs_epoch.png                                          \n",
      "./plots/useful-worm-481/loss_vs_epoch.png                                         \n",
      "./plots/useful-worm-481/binary_accuracy_vs_epoch.png                              \n",
      "./plots/useful-worm-481/recall_vs_epoch.png                                       \n",
      "./plots/useful-worm-481/precision_vs_epoch.png                                    \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 594ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step         \n",
      "\n",
      " 90%|█████████ | 18/20 [07:49<03:56, 118.50s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step         \n",
      "\n",
      " 90%|█████████ | 18/20 [07:49<03:56, 118.50s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd3097a9c144dfe985b83300408e256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 24/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 49/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 76/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 46/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 71/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m194/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 47/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 72/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m100/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 49/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 73/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m225/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m225/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 40/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m259/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 94/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m116/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m283/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step                \n",
      "\u001b[1m 14/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step                 \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 30ms/step                \n",
      "\u001b[1m 14/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step                 \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 71/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m221/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m203/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m205/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 22/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 49/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m292/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 79/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m303/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 23/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 48/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m181/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m220/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m114/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m288/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m192/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m145/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m285/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 88/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m176/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m298/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m178/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m235/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m195/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m225/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m256/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run useful-worm-481 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/47aedd7b095047758c2fc59af6d30c89\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "preprocessing - initialising normalisers                                          \n",
      " 95%|█████████▌| 19/20 [08:39<02:08, 128.59s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:44:40.735679: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:40.784325: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:40.834846: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:40.885679: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:40.944493: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.001734: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.054576: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.464149: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.531853: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.591791: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.655525: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.736088: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.798962: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.867147: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:41.936488: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-08 22:44:42.010844: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300                                                                       \n",
      "\n",
      "80/80 - 5s - 57ms/step - auc: 0.2231 - binary_accuracy: 0.2625 - loss: 0.7987 - precision: 0.1809 - recall: 0.2040 - val_auc: 0.2872 - val_binary_accuracy: 0.3000 - val_loss: 0.7737 - val_precision: 0.2294 - val_recall: 0.2732 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 2/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.2701 - binary_accuracy: 0.3187 - loss: 0.7670 - precision: 0.2295 - recall: 0.2495 - val_auc: 0.3369 - val_binary_accuracy: 0.3605 - val_loss: 0.7460 - val_precision: 0.2767 - val_recall: 0.3115 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 3/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.3300 - binary_accuracy: 0.3695 - loss: 0.7412 - precision: 0.2689 - recall: 0.2812 - val_auc: 0.4064 - val_binary_accuracy: 0.4279 - val_loss: 0.7221 - val_precision: 0.3385 - val_recall: 0.3607 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 4/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.4169 - binary_accuracy: 0.4648 - loss: 0.7167 - precision: 0.3661 - recall: 0.3480 - val_auc: 0.4893 - val_binary_accuracy: 0.5140 - val_loss: 0.6992 - val_precision: 0.4198 - val_recall: 0.3716 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 5/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.5147 - binary_accuracy: 0.5789 - loss: 0.6951 - precision: 0.5071 - recall: 0.3908 - val_auc: 0.5834 - val_binary_accuracy: 0.5977 - val_loss: 0.6774 - val_precision: 0.5352 - val_recall: 0.4153 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 6/300                                                                       \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.6153 - binary_accuracy: 0.6508 - loss: 0.6724 - precision: 0.6253 - recall: 0.4599 - val_auc: 0.6771 - val_binary_accuracy: 0.6605 - val_loss: 0.6554 - val_precision: 0.6331 - val_recall: 0.4809 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 7/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.6938 - binary_accuracy: 0.6945 - loss: 0.6509 - precision: 0.6997 - recall: 0.5018 - val_auc: 0.7470 - val_binary_accuracy: 0.7140 - val_loss: 0.6343 - val_precision: 0.7273 - val_recall: 0.5246 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 8/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7551 - binary_accuracy: 0.7242 - loss: 0.6286 - precision: 0.7443 - recall: 0.5385 - val_auc: 0.7914 - val_binary_accuracy: 0.7512 - val_loss: 0.6133 - val_precision: 0.7754 - val_recall: 0.5847 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 9/300                                                                       \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.7958 - binary_accuracy: 0.7492 - loss: 0.6074 - precision: 0.7705 - recall: 0.5853 - val_auc: 0.8238 - val_binary_accuracy: 0.7651 - val_loss: 0.5929 - val_precision: 0.7887 - val_recall: 0.6120 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 10/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8297 - binary_accuracy: 0.7711 - loss: 0.5845 - precision: 0.7908 - recall: 0.6300 - val_auc: 0.8486 - val_binary_accuracy: 0.7860 - val_loss: 0.5717 - val_precision: 0.8054 - val_recall: 0.6557 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 11/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.8535 - binary_accuracy: 0.7898 - loss: 0.5630 - precision: 0.8035 - recall: 0.6728 - val_auc: 0.8682 - val_binary_accuracy: 0.8093 - val_loss: 0.5502 - val_precision: 0.8258 - val_recall: 0.6995 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 12/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8720 - binary_accuracy: 0.8016 - loss: 0.5415 - precision: 0.8124 - recall: 0.6965 - val_auc: 0.8825 - val_binary_accuracy: 0.8186 - val_loss: 0.5298 - val_precision: 0.8344 - val_recall: 0.7158 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 13/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8871 - binary_accuracy: 0.8117 - loss: 0.5192 - precision: 0.8161 - recall: 0.7221 - val_auc: 0.8920 - val_binary_accuracy: 0.8233 - val_loss: 0.5103 - val_precision: 0.8323 - val_recall: 0.7322 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 14/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.8964 - binary_accuracy: 0.8266 - loss: 0.4997 - precision: 0.8340 - recall: 0.7427 - val_auc: 0.8987 - val_binary_accuracy: 0.8233 - val_loss: 0.4928 - val_precision: 0.8282 - val_recall: 0.7377 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 15/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9048 - binary_accuracy: 0.8336 - loss: 0.4808 - precision: 0.8367 - recall: 0.7587 - val_auc: 0.9044 - val_binary_accuracy: 0.8209 - val_loss: 0.4765 - val_precision: 0.8232 - val_recall: 0.7377 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 16/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9109 - binary_accuracy: 0.8344 - loss: 0.4641 - precision: 0.8323 - recall: 0.7687 - val_auc: 0.9091 - val_binary_accuracy: 0.8233 - val_loss: 0.4621 - val_precision: 0.8242 - val_recall: 0.7432 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 17/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9151 - binary_accuracy: 0.8383 - loss: 0.4489 - precision: 0.8346 - recall: 0.7751 - val_auc: 0.9121 - val_binary_accuracy: 0.8256 - val_loss: 0.4491 - val_precision: 0.8253 - val_recall: 0.7486 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 18/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9180 - binary_accuracy: 0.8406 - loss: 0.4360 - precision: 0.8359 - recall: 0.7810 - val_auc: 0.9143 - val_binary_accuracy: 0.8256 - val_loss: 0.4375 - val_precision: 0.8214 - val_recall: 0.7541 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 19/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9208 - binary_accuracy: 0.8438 - loss: 0.4236 - precision: 0.8372 - recall: 0.7883 - val_auc: 0.9161 - val_binary_accuracy: 0.8256 - val_loss: 0.4272 - val_precision: 0.8253 - val_recall: 0.7486 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 20/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9244 - binary_accuracy: 0.8484 - loss: 0.4103 - precision: 0.8417 - recall: 0.7956 - val_auc: 0.9177 - val_binary_accuracy: 0.8302 - val_loss: 0.4178 - val_precision: 0.8313 - val_recall: 0.7541 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 21/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9254 - binary_accuracy: 0.8516 - loss: 0.4010 - precision: 0.8416 - recall: 0.8047 - val_auc: 0.9193 - val_binary_accuracy: 0.8326 - val_loss: 0.4092 - val_precision: 0.8364 - val_recall: 0.7541 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 22/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9268 - binary_accuracy: 0.8570 - loss: 0.3927 - precision: 0.8437 - recall: 0.8175 - val_auc: 0.9208 - val_binary_accuracy: 0.8326 - val_loss: 0.4018 - val_precision: 0.8364 - val_recall: 0.7541 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 23/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9287 - binary_accuracy: 0.8594 - loss: 0.3836 - precision: 0.8488 - recall: 0.8179 - val_auc: 0.9217 - val_binary_accuracy: 0.8326 - val_loss: 0.3951 - val_precision: 0.8323 - val_recall: 0.7596 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 24/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9285 - binary_accuracy: 0.8617 - loss: 0.3779 - precision: 0.8477 - recall: 0.8245 - val_auc: 0.9228 - val_binary_accuracy: 0.8349 - val_loss: 0.3893 - val_precision: 0.8333 - val_recall: 0.7650 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 25/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9302 - binary_accuracy: 0.8617 - loss: 0.3710 - precision: 0.8451 - recall: 0.8282 - val_auc: 0.9235 - val_binary_accuracy: 0.8302 - val_loss: 0.3841 - val_precision: 0.8235 - val_recall: 0.7650 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 26/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9306 - binary_accuracy: 0.8656 - loss: 0.3651 - precision: 0.8505 - recall: 0.8318 - val_auc: 0.9241 - val_binary_accuracy: 0.8372 - val_loss: 0.3794 - val_precision: 0.8304 - val_recall: 0.7760 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 27/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9310 - binary_accuracy: 0.8633 - loss: 0.3608 - precision: 0.8489 - recall: 0.8288 - val_auc: 0.9247 - val_binary_accuracy: 0.8395 - val_loss: 0.3754 - val_precision: 0.8353 - val_recall: 0.7760 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 28/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9314 - binary_accuracy: 0.8641 - loss: 0.3563 - precision: 0.8476 - recall: 0.8321 - val_auc: 0.9251 - val_binary_accuracy: 0.8395 - val_loss: 0.3714 - val_precision: 0.8353 - val_recall: 0.7760 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 29/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9322 - binary_accuracy: 0.8641 - loss: 0.3524 - precision: 0.8470 - recall: 0.8315 - val_auc: 0.9253 - val_binary_accuracy: 0.8442 - val_loss: 0.3683 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 30/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9326 - binary_accuracy: 0.8633 - loss: 0.3486 - precision: 0.8467 - recall: 0.8297 - val_auc: 0.9257 - val_binary_accuracy: 0.8442 - val_loss: 0.3652 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 31/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9327 - binary_accuracy: 0.8633 - loss: 0.3463 - precision: 0.8454 - recall: 0.8315 - val_auc: 0.9261 - val_binary_accuracy: 0.8442 - val_loss: 0.3626 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 32/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9339 - binary_accuracy: 0.8625 - loss: 0.3424 - precision: 0.8432 - recall: 0.8339 - val_auc: 0.9264 - val_binary_accuracy: 0.8442 - val_loss: 0.3601 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 33/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9335 - binary_accuracy: 0.8625 - loss: 0.3405 - precision: 0.8442 - recall: 0.8318 - val_auc: 0.9266 - val_binary_accuracy: 0.8419 - val_loss: 0.3578 - val_precision: 0.8363 - val_recall: 0.7814 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 34/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9344 - binary_accuracy: 0.8617 - loss: 0.3370 - precision: 0.8439 - recall: 0.8300 - val_auc: 0.9269 - val_binary_accuracy: 0.8419 - val_loss: 0.3559 - val_precision: 0.8363 - val_recall: 0.7814 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 35/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9349 - binary_accuracy: 0.8625 - loss: 0.3342 - precision: 0.8420 - recall: 0.8327 - val_auc: 0.9272 - val_binary_accuracy: 0.8419 - val_loss: 0.3541 - val_precision: 0.8363 - val_recall: 0.7814 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 36/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8641 - loss: 0.3291 - precision: 0.8457 - recall: 0.8333 - val_auc: 0.9276 - val_binary_accuracy: 0.8419 - val_loss: 0.3526 - val_precision: 0.8363 - val_recall: 0.7814 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 37/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9346 - binary_accuracy: 0.8602 - loss: 0.3325 - precision: 0.8417 - recall: 0.8278 - val_auc: 0.9275 - val_binary_accuracy: 0.8395 - val_loss: 0.3513 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 38/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9349 - binary_accuracy: 0.8625 - loss: 0.3310 - precision: 0.8442 - recall: 0.8318 - val_auc: 0.9277 - val_binary_accuracy: 0.8395 - val_loss: 0.3501 - val_precision: 0.8314 - val_recall: 0.7814 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 39/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9353 - binary_accuracy: 0.8641 - loss: 0.3290 - precision: 0.8444 - recall: 0.8352 - val_auc: 0.9278 - val_binary_accuracy: 0.8419 - val_loss: 0.3490 - val_precision: 0.8324 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 40/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9360 - binary_accuracy: 0.8641 - loss: 0.3266 - precision: 0.8454 - recall: 0.8330 - val_auc: 0.9280 - val_binary_accuracy: 0.8442 - val_loss: 0.3481 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 41/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9371 - binary_accuracy: 0.8664 - loss: 0.3237 - precision: 0.8476 - recall: 0.8367 - val_auc: 0.9281 - val_binary_accuracy: 0.8442 - val_loss: 0.3473 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 42/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9362 - binary_accuracy: 0.8648 - loss: 0.3251 - precision: 0.8457 - recall: 0.8349 - val_auc: 0.9281 - val_binary_accuracy: 0.8442 - val_loss: 0.3465 - val_precision: 0.8372 - val_recall: 0.7869 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 43/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9361 - binary_accuracy: 0.8648 - loss: 0.3245 - precision: 0.8463 - recall: 0.8355 - val_auc: 0.9285 - val_binary_accuracy: 0.8465 - val_loss: 0.3458 - val_precision: 0.8382 - val_recall: 0.7923 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 44/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8664 - loss: 0.3221 - precision: 0.8497 - recall: 0.8358 - val_auc: 0.9284 - val_binary_accuracy: 0.8465 - val_loss: 0.3453 - val_precision: 0.8382 - val_recall: 0.7923 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 45/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9364 - binary_accuracy: 0.8656 - loss: 0.3230 - precision: 0.8484 - recall: 0.8361 - val_auc: 0.9286 - val_binary_accuracy: 0.8465 - val_loss: 0.3446 - val_precision: 0.8382 - val_recall: 0.7923 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 46/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9378 - binary_accuracy: 0.8664 - loss: 0.3190 - precision: 0.8494 - recall: 0.8355 - val_auc: 0.9286 - val_binary_accuracy: 0.8465 - val_loss: 0.3441 - val_precision: 0.8382 - val_recall: 0.7923 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 47/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9380 - binary_accuracy: 0.8672 - loss: 0.3185 - precision: 0.8497 - recall: 0.8373 - val_auc: 0.9291 - val_binary_accuracy: 0.8465 - val_loss: 0.3436 - val_precision: 0.8382 - val_recall: 0.7923 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 48/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9370 - binary_accuracy: 0.8672 - loss: 0.3205 - precision: 0.8494 - recall: 0.8370 - val_auc: 0.9288 - val_binary_accuracy: 0.8465 - val_loss: 0.3432 - val_precision: 0.8382 - val_recall: 0.7923 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 49/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9376 - binary_accuracy: 0.8672 - loss: 0.3189 - precision: 0.8492 - recall: 0.8367 - val_auc: 0.9292 - val_binary_accuracy: 0.8488 - val_loss: 0.3428 - val_precision: 0.8391 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 50/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9373 - binary_accuracy: 0.8680 - loss: 0.3191 - precision: 0.8529 - recall: 0.8358 - val_auc: 0.9292 - val_binary_accuracy: 0.8465 - val_loss: 0.3424 - val_precision: 0.8343 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 51/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9376 - binary_accuracy: 0.8664 - loss: 0.3185 - precision: 0.8497 - recall: 0.8358 - val_auc: 0.9295 - val_binary_accuracy: 0.8465 - val_loss: 0.3421 - val_precision: 0.8343 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 52/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9379 - binary_accuracy: 0.8672 - loss: 0.3175 - precision: 0.8510 - recall: 0.8355 - val_auc: 0.9299 - val_binary_accuracy: 0.8465 - val_loss: 0.3417 - val_precision: 0.8343 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 53/300                                                                      \n",
      "\n",
      "80/80 - 1s - 7ms/step - auc: 0.9379 - binary_accuracy: 0.8672 - loss: 0.3174 - precision: 0.8510 - recall: 0.8355 - val_auc: 0.9297 - val_binary_accuracy: 0.8465 - val_loss: 0.3415 - val_precision: 0.8343 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 54/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9376 - binary_accuracy: 0.8656 - loss: 0.3178 - precision: 0.8492 - recall: 0.8336 - val_auc: 0.9301 - val_binary_accuracy: 0.8465 - val_loss: 0.3412 - val_precision: 0.8343 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 55/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9379 - binary_accuracy: 0.8672 - loss: 0.3172 - precision: 0.8526 - recall: 0.8339 - val_auc: 0.9303 - val_binary_accuracy: 0.8465 - val_loss: 0.3409 - val_precision: 0.8343 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 56/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9386 - binary_accuracy: 0.8672 - loss: 0.3155 - precision: 0.8542 - recall: 0.8324 - val_auc: 0.9303 - val_binary_accuracy: 0.8465 - val_loss: 0.3407 - val_precision: 0.8343 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 57/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9396 - binary_accuracy: 0.8664 - loss: 0.3129 - precision: 0.8492 - recall: 0.8352 - val_auc: 0.9304 - val_binary_accuracy: 0.8442 - val_loss: 0.3404 - val_precision: 0.8295 - val_recall: 0.7978 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 58/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9387 - binary_accuracy: 0.8672 - loss: 0.3154 - precision: 0.8526 - recall: 0.8339 - val_auc: 0.9307 - val_binary_accuracy: 0.8488 - val_loss: 0.3402 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 59/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9384 - binary_accuracy: 0.8672 - loss: 0.3159 - precision: 0.8507 - recall: 0.8352 - val_auc: 0.9309 - val_binary_accuracy: 0.8488 - val_loss: 0.3400 - val_precision: 0.8315 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 60/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9405 - binary_accuracy: 0.8703 - loss: 0.3106 - precision: 0.8563 - recall: 0.8376 - val_auc: 0.9308 - val_binary_accuracy: 0.8512 - val_loss: 0.3398 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 61/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9393 - binary_accuracy: 0.8703 - loss: 0.3141 - precision: 0.8563 - recall: 0.8376 - val_auc: 0.9310 - val_binary_accuracy: 0.8512 - val_loss: 0.3396 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 62/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9391 - binary_accuracy: 0.8695 - loss: 0.3142 - precision: 0.8529 - recall: 0.8388 - val_auc: 0.9311 - val_binary_accuracy: 0.8512 - val_loss: 0.3394 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 63/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9393 - binary_accuracy: 0.8703 - loss: 0.3140 - precision: 0.8553 - recall: 0.8397 - val_auc: 0.9311 - val_binary_accuracy: 0.8512 - val_loss: 0.3392 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 64/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8711 - loss: 0.3104 - precision: 0.8532 - recall: 0.8422 - val_auc: 0.9313 - val_binary_accuracy: 0.8512 - val_loss: 0.3390 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 65/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9412 - binary_accuracy: 0.8727 - loss: 0.3090 - precision: 0.8547 - recall: 0.8438 - val_auc: 0.9314 - val_binary_accuracy: 0.8512 - val_loss: 0.3389 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 66/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9402 - binary_accuracy: 0.8695 - loss: 0.3116 - precision: 0.8526 - recall: 0.8385 - val_auc: 0.9316 - val_binary_accuracy: 0.8512 - val_loss: 0.3388 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 67/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9391 - binary_accuracy: 0.8695 - loss: 0.3136 - precision: 0.8529 - recall: 0.8388 - val_auc: 0.9314 - val_binary_accuracy: 0.8512 - val_loss: 0.3386 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 68/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9394 - binary_accuracy: 0.8687 - loss: 0.3133 - precision: 0.8532 - recall: 0.8376 - val_auc: 0.9315 - val_binary_accuracy: 0.8535 - val_loss: 0.3385 - val_precision: 0.8409 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 69/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9397 - binary_accuracy: 0.8695 - loss: 0.3125 - precision: 0.8532 - recall: 0.8391 - val_auc: 0.9315 - val_binary_accuracy: 0.8535 - val_loss: 0.3384 - val_precision: 0.8409 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 70/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9401 - binary_accuracy: 0.8703 - loss: 0.3113 - precision: 0.8534 - recall: 0.8410 - val_auc: 0.9315 - val_binary_accuracy: 0.8512 - val_loss: 0.3382 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 71/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9396 - binary_accuracy: 0.8687 - loss: 0.3128 - precision: 0.8526 - recall: 0.8370 - val_auc: 0.9317 - val_binary_accuracy: 0.8512 - val_loss: 0.3381 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 72/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9397 - binary_accuracy: 0.8687 - loss: 0.3120 - precision: 0.8526 - recall: 0.8370 - val_auc: 0.9319 - val_binary_accuracy: 0.8512 - val_loss: 0.3379 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 73/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9398 - binary_accuracy: 0.8695 - loss: 0.3116 - precision: 0.8523 - recall: 0.8382 - val_auc: 0.9317 - val_binary_accuracy: 0.8512 - val_loss: 0.3379 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 74/300                                                                      \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9399 - binary_accuracy: 0.8703 - loss: 0.3120 - precision: 0.8561 - recall: 0.8373 - val_auc: 0.9318 - val_binary_accuracy: 0.8512 - val_loss: 0.3377 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 75/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9397 - binary_accuracy: 0.8695 - loss: 0.3121 - precision: 0.8545 - recall: 0.8373 - val_auc: 0.9320 - val_binary_accuracy: 0.8512 - val_loss: 0.3375 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 76/300                                                                      \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9399 - binary_accuracy: 0.8687 - loss: 0.3116 - precision: 0.8529 - recall: 0.8373 - val_auc: 0.9321 - val_binary_accuracy: 0.8512 - val_loss: 0.3374 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 77/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9408 - binary_accuracy: 0.8703 - loss: 0.3093 - precision: 0.8547 - recall: 0.8391 - val_auc: 0.9321 - val_binary_accuracy: 0.8512 - val_loss: 0.3373 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 78/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9404 - binary_accuracy: 0.8695 - loss: 0.3099 - precision: 0.8545 - recall: 0.8373 - val_auc: 0.9321 - val_binary_accuracy: 0.8512 - val_loss: 0.3372 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 79/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9399 - binary_accuracy: 0.8695 - loss: 0.3112 - precision: 0.8529 - recall: 0.8388 - val_auc: 0.9322 - val_binary_accuracy: 0.8512 - val_loss: 0.3371 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 80/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9404 - binary_accuracy: 0.8687 - loss: 0.3105 - precision: 0.8532 - recall: 0.8376 - val_auc: 0.9325 - val_binary_accuracy: 0.8512 - val_loss: 0.3369 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 81/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8711 - loss: 0.3083 - precision: 0.8556 - recall: 0.8415 - val_auc: 0.9325 - val_binary_accuracy: 0.8512 - val_loss: 0.3368 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 82/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9409 - binary_accuracy: 0.8703 - loss: 0.3092 - precision: 0.8534 - recall: 0.8410 - val_auc: 0.9325 - val_binary_accuracy: 0.8512 - val_loss: 0.3366 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 83/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9403 - binary_accuracy: 0.8703 - loss: 0.3107 - precision: 0.8547 - recall: 0.8391 - val_auc: 0.9325 - val_binary_accuracy: 0.8512 - val_loss: 0.3365 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 84/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8711 - loss: 0.3088 - precision: 0.8563 - recall: 0.8391 - val_auc: 0.9326 - val_binary_accuracy: 0.8512 - val_loss: 0.3364 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 85/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8711 - loss: 0.3051 - precision: 0.8563 - recall: 0.8391 - val_auc: 0.9326 - val_binary_accuracy: 0.8535 - val_loss: 0.3364 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 86/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9415 - binary_accuracy: 0.8727 - loss: 0.3077 - precision: 0.8556 - recall: 0.8446 - val_auc: 0.9325 - val_binary_accuracy: 0.8512 - val_loss: 0.3362 - val_precision: 0.8362 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 87/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8711 - loss: 0.3082 - precision: 0.8537 - recall: 0.8428 - val_auc: 0.9326 - val_binary_accuracy: 0.8535 - val_loss: 0.3361 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 88/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9406 - binary_accuracy: 0.8687 - loss: 0.3096 - precision: 0.8506 - recall: 0.8412 - val_auc: 0.9324 - val_binary_accuracy: 0.8535 - val_loss: 0.3360 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 89/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8719 - loss: 0.3079 - precision: 0.8566 - recall: 0.8410 - val_auc: 0.9327 - val_binary_accuracy: 0.8535 - val_loss: 0.3359 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 90/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8695 - loss: 0.3081 - precision: 0.8519 - recall: 0.8410 - val_auc: 0.9326 - val_binary_accuracy: 0.8535 - val_loss: 0.3357 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 91/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8711 - loss: 0.3079 - precision: 0.8547 - recall: 0.8407 - val_auc: 0.9326 - val_binary_accuracy: 0.8535 - val_loss: 0.3357 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 92/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9414 - binary_accuracy: 0.8711 - loss: 0.3075 - precision: 0.8545 - recall: 0.8404 - val_auc: 0.9328 - val_binary_accuracy: 0.8535 - val_loss: 0.3356 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 93/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8687 - loss: 0.3083 - precision: 0.8513 - recall: 0.8388 - val_auc: 0.9327 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 94/300                                                                      \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9413 - binary_accuracy: 0.8695 - loss: 0.3078 - precision: 0.8513 - recall: 0.8404 - val_auc: 0.9327 - val_binary_accuracy: 0.8535 - val_loss: 0.3355 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 95/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9412 - binary_accuracy: 0.8711 - loss: 0.3081 - precision: 0.8545 - recall: 0.8404 - val_auc: 0.9327 - val_binary_accuracy: 0.8535 - val_loss: 0.3354 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 96/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8703 - loss: 0.3067 - precision: 0.8521 - recall: 0.8428 - val_auc: 0.9329 - val_binary_accuracy: 0.8512 - val_loss: 0.3353 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 97/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9410 - binary_accuracy: 0.8695 - loss: 0.3087 - precision: 0.8516 - recall: 0.8407 - val_auc: 0.9327 - val_binary_accuracy: 0.8512 - val_loss: 0.3352 - val_precision: 0.8324 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 98/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9411 - binary_accuracy: 0.8695 - loss: 0.3085 - precision: 0.8516 - recall: 0.8407 - val_auc: 0.9327 - val_binary_accuracy: 0.8535 - val_loss: 0.3351 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 99/300                                                                      \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8703 - loss: 0.3080 - precision: 0.8532 - recall: 0.8407 - val_auc: 0.9328 - val_binary_accuracy: 0.8535 - val_loss: 0.3350 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 100/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8719 - loss: 0.3059 - precision: 0.8553 - recall: 0.8428 - val_auc: 0.9327 - val_binary_accuracy: 0.8535 - val_loss: 0.3348 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 101/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8727 - loss: 0.3056 - precision: 0.8569 - recall: 0.8428 - val_auc: 0.9326 - val_binary_accuracy: 0.8535 - val_loss: 0.3348 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 102/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9412 - binary_accuracy: 0.8719 - loss: 0.3082 - precision: 0.8553 - recall: 0.8428 - val_auc: 0.9328 - val_binary_accuracy: 0.8535 - val_loss: 0.3347 - val_precision: 0.8371 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 103/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9413 - binary_accuracy: 0.8719 - loss: 0.3081 - precision: 0.8553 - recall: 0.8428 - val_auc: 0.9326 - val_binary_accuracy: 0.8558 - val_loss: 0.3346 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 104/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9413 - binary_accuracy: 0.8719 - loss: 0.3077 - precision: 0.8553 - recall: 0.8428 - val_auc: 0.9326 - val_binary_accuracy: 0.8558 - val_loss: 0.3345 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 105/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9424 - binary_accuracy: 0.8750 - loss: 0.3051 - precision: 0.8571 - recall: 0.8477 - val_auc: 0.9326 - val_binary_accuracy: 0.8558 - val_loss: 0.3345 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 106/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9416 - binary_accuracy: 0.8727 - loss: 0.3069 - precision: 0.8550 - recall: 0.8440 - val_auc: 0.9326 - val_binary_accuracy: 0.8558 - val_loss: 0.3346 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 107/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9414 - binary_accuracy: 0.8727 - loss: 0.3072 - precision: 0.8545 - recall: 0.8435 - val_auc: 0.9326 - val_binary_accuracy: 0.8558 - val_loss: 0.3344 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 108/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9418 - binary_accuracy: 0.8742 - loss: 0.3067 - precision: 0.8577 - recall: 0.8467 - val_auc: 0.9329 - val_binary_accuracy: 0.8558 - val_loss: 0.3343 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 109/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9420 - binary_accuracy: 0.8734 - loss: 0.3059 - precision: 0.8553 - recall: 0.8459 - val_auc: 0.9328 - val_binary_accuracy: 0.8558 - val_loss: 0.3342 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 110/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9423 - binary_accuracy: 0.8750 - loss: 0.3056 - precision: 0.8577 - recall: 0.8483 - val_auc: 0.9329 - val_binary_accuracy: 0.8558 - val_loss: 0.3341 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 111/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9417 - binary_accuracy: 0.8734 - loss: 0.3065 - precision: 0.8553 - recall: 0.8459 - val_auc: 0.9329 - val_binary_accuracy: 0.8558 - val_loss: 0.3340 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 112/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8719 - loss: 0.3062 - precision: 0.8553 - recall: 0.8428 - val_auc: 0.9331 - val_binary_accuracy: 0.8581 - val_loss: 0.3339 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 113/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9418 - binary_accuracy: 0.8719 - loss: 0.3065 - precision: 0.8553 - recall: 0.8428 - val_auc: 0.9330 - val_binary_accuracy: 0.8581 - val_loss: 0.3339 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 114/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8734 - loss: 0.3058 - precision: 0.8574 - recall: 0.8449 - val_auc: 0.9330 - val_binary_accuracy: 0.8558 - val_loss: 0.3338 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 115/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8727 - loss: 0.3058 - precision: 0.8558 - recall: 0.8449 - val_auc: 0.9332 - val_binary_accuracy: 0.8558 - val_loss: 0.3336 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 116/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8742 - loss: 0.3024 - precision: 0.8558 - recall: 0.8480 - val_auc: 0.9333 - val_binary_accuracy: 0.8558 - val_loss: 0.3336 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 117/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8734 - loss: 0.3052 - precision: 0.8558 - recall: 0.8464 - val_auc: 0.9333 - val_binary_accuracy: 0.8558 - val_loss: 0.3335 - val_precision: 0.8418 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 118/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9419 - binary_accuracy: 0.8727 - loss: 0.3062 - precision: 0.8553 - recall: 0.8443 - val_auc: 0.9334 - val_binary_accuracy: 0.8581 - val_loss: 0.3335 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 119/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8734 - loss: 0.3037 - precision: 0.8569 - recall: 0.8443 - val_auc: 0.9334 - val_binary_accuracy: 0.8581 - val_loss: 0.3334 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 120/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9420 - binary_accuracy: 0.8727 - loss: 0.3061 - precision: 0.8556 - recall: 0.8446 - val_auc: 0.9335 - val_binary_accuracy: 0.8581 - val_loss: 0.3334 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 121/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8734 - loss: 0.3054 - precision: 0.8561 - recall: 0.8467 - val_auc: 0.9335 - val_binary_accuracy: 0.8581 - val_loss: 0.3333 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 122/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9431 - binary_accuracy: 0.8734 - loss: 0.3036 - precision: 0.8558 - recall: 0.8464 - val_auc: 0.9337 - val_binary_accuracy: 0.8581 - val_loss: 0.3333 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 123/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8734 - loss: 0.3051 - precision: 0.8571 - recall: 0.8446 - val_auc: 0.9335 - val_binary_accuracy: 0.8581 - val_loss: 0.3331 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 124/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8734 - loss: 0.3057 - precision: 0.8569 - recall: 0.8443 - val_auc: 0.9338 - val_binary_accuracy: 0.8581 - val_loss: 0.3331 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 125/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9421 - binary_accuracy: 0.8734 - loss: 0.3055 - precision: 0.8569 - recall: 0.8443 - val_auc: 0.9338 - val_binary_accuracy: 0.8581 - val_loss: 0.3330 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 126/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8734 - loss: 0.3047 - precision: 0.8553 - recall: 0.8459 - val_auc: 0.9338 - val_binary_accuracy: 0.8581 - val_loss: 0.3329 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 127/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9428 - binary_accuracy: 0.8742 - loss: 0.3039 - precision: 0.8585 - recall: 0.8443 - val_auc: 0.9338 - val_binary_accuracy: 0.8581 - val_loss: 0.3328 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 128/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9422 - binary_accuracy: 0.8742 - loss: 0.3050 - precision: 0.8582 - recall: 0.8440 - val_auc: 0.9339 - val_binary_accuracy: 0.8581 - val_loss: 0.3328 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 129/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9429 - binary_accuracy: 0.8758 - loss: 0.3032 - precision: 0.8603 - recall: 0.8462 - val_auc: 0.9339 - val_binary_accuracy: 0.8581 - val_loss: 0.3328 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 130/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8750 - loss: 0.3048 - precision: 0.8587 - recall: 0.8462 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3327 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 131/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9424 - binary_accuracy: 0.8742 - loss: 0.3047 - precision: 0.8571 - recall: 0.8462 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3327 - val_precision: 0.8466 - val_recall: 0.8142 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 132/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9425 - binary_accuracy: 0.8750 - loss: 0.3042 - precision: 0.8574 - recall: 0.8480 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3326 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 133/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9435 - binary_accuracy: 0.8758 - loss: 0.3018 - precision: 0.8587 - recall: 0.8477 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3325 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 134/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9429 - binary_accuracy: 0.8750 - loss: 0.3034 - precision: 0.8603 - recall: 0.8446 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3324 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 135/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9428 - binary_accuracy: 0.8758 - loss: 0.3035 - precision: 0.8593 - recall: 0.8483 - val_auc: 0.9342 - val_binary_accuracy: 0.8558 - val_loss: 0.3324 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 136/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8781 - loss: 0.2974 - precision: 0.8627 - recall: 0.8501 - val_auc: 0.9342 - val_binary_accuracy: 0.8558 - val_loss: 0.3323 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 137/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8766 - loss: 0.3027 - precision: 0.8595 - recall: 0.8501 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3323 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 138/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9435 - binary_accuracy: 0.8781 - loss: 0.3016 - precision: 0.8632 - recall: 0.8506 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3323 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 139/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8750 - loss: 0.3024 - precision: 0.8609 - recall: 0.8452 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3322 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 140/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9433 - binary_accuracy: 0.8766 - loss: 0.3017 - precision: 0.8606 - recall: 0.8480 - val_auc: 0.9339 - val_binary_accuracy: 0.8558 - val_loss: 0.3321 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 141/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9439 - binary_accuracy: 0.8750 - loss: 0.3003 - precision: 0.8603 - recall: 0.8446 - val_auc: 0.9339 - val_binary_accuracy: 0.8558 - val_loss: 0.3321 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 142/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9427 - binary_accuracy: 0.8742 - loss: 0.3036 - precision: 0.8587 - recall: 0.8446 - val_auc: 0.9340 - val_binary_accuracy: 0.8558 - val_loss: 0.3320 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 143/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9429 - binary_accuracy: 0.8742 - loss: 0.3031 - precision: 0.8590 - recall: 0.8449 - val_auc: 0.9339 - val_binary_accuracy: 0.8558 - val_loss: 0.3321 - val_precision: 0.8457 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 144/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9437 - binary_accuracy: 0.8766 - loss: 0.3011 - precision: 0.8625 - recall: 0.8467 - val_auc: 0.9338 - val_binary_accuracy: 0.8535 - val_loss: 0.3320 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 145/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9432 - binary_accuracy: 0.8750 - loss: 0.3026 - precision: 0.8609 - recall: 0.8452 - val_auc: 0.9340 - val_binary_accuracy: 0.8535 - val_loss: 0.3320 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 146/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9431 - binary_accuracy: 0.8758 - loss: 0.3029 - precision: 0.8593 - recall: 0.8483 - val_auc: 0.9338 - val_binary_accuracy: 0.8535 - val_loss: 0.3320 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 147/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9430 - binary_accuracy: 0.8758 - loss: 0.3027 - precision: 0.8593 - recall: 0.8483 - val_auc: 0.9339 - val_binary_accuracy: 0.8535 - val_loss: 0.3320 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 148/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9433 - binary_accuracy: 0.8758 - loss: 0.3024 - precision: 0.8595 - recall: 0.8485 - val_auc: 0.9339 - val_binary_accuracy: 0.8535 - val_loss: 0.3319 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 149/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9435 - binary_accuracy: 0.8766 - loss: 0.3020 - precision: 0.8590 - recall: 0.8495 - val_auc: 0.9340 - val_binary_accuracy: 0.8512 - val_loss: 0.3319 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 150/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9444 - binary_accuracy: 0.8766 - loss: 0.2997 - precision: 0.8587 - recall: 0.8493 - val_auc: 0.9338 - val_binary_accuracy: 0.8512 - val_loss: 0.3318 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 151/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8773 - loss: 0.2965 - precision: 0.8622 - recall: 0.8480 - val_auc: 0.9339 - val_binary_accuracy: 0.8512 - val_loss: 0.3319 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 152/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9440 - binary_accuracy: 0.8750 - loss: 0.3005 - precision: 0.8590 - recall: 0.8464 - val_auc: 0.9339 - val_binary_accuracy: 0.8512 - val_loss: 0.3318 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 153/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8734 - loss: 0.3018 - precision: 0.8579 - recall: 0.8422 - val_auc: 0.9340 - val_binary_accuracy: 0.8535 - val_loss: 0.3318 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 154/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9434 - binary_accuracy: 0.8742 - loss: 0.3017 - precision: 0.8582 - recall: 0.8440 - val_auc: 0.9341 - val_binary_accuracy: 0.8535 - val_loss: 0.3317 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 155/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8750 - loss: 0.3013 - precision: 0.8593 - recall: 0.8467 - val_auc: 0.9338 - val_binary_accuracy: 0.8535 - val_loss: 0.3317 - val_precision: 0.8409 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 156/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8742 - loss: 0.3015 - precision: 0.8585 - recall: 0.8443 - val_auc: 0.9339 - val_binary_accuracy: 0.8535 - val_loss: 0.3317 - val_precision: 0.8409 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 157/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8758 - loss: 0.2997 - precision: 0.8590 - recall: 0.8480 - val_auc: 0.9339 - val_binary_accuracy: 0.8535 - val_loss: 0.3316 - val_precision: 0.8409 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 158/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9436 - binary_accuracy: 0.8750 - loss: 0.3015 - precision: 0.8587 - recall: 0.8462 - val_auc: 0.9340 - val_binary_accuracy: 0.8535 - val_loss: 0.3316 - val_precision: 0.8409 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 159/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9441 - binary_accuracy: 0.8750 - loss: 0.3003 - precision: 0.8606 - recall: 0.8449 - val_auc: 0.9341 - val_binary_accuracy: 0.8512 - val_loss: 0.3316 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 160/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9439 - binary_accuracy: 0.8750 - loss: 0.3008 - precision: 0.8603 - recall: 0.8446 - val_auc: 0.9341 - val_binary_accuracy: 0.8512 - val_loss: 0.3316 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 161/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9440 - binary_accuracy: 0.8758 - loss: 0.3005 - precision: 0.8619 - recall: 0.8446 - val_auc: 0.9341 - val_binary_accuracy: 0.8535 - val_loss: 0.3317 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 162/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9443 - binary_accuracy: 0.8758 - loss: 0.2997 - precision: 0.8603 - recall: 0.8462 - val_auc: 0.9341 - val_binary_accuracy: 0.8512 - val_loss: 0.3315 - val_precision: 0.8400 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 163/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9441 - binary_accuracy: 0.8766 - loss: 0.3000 - precision: 0.8619 - recall: 0.8462 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3315 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 164/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9447 - binary_accuracy: 0.8781 - loss: 0.2985 - precision: 0.8627 - recall: 0.8501 - val_auc: 0.9342 - val_binary_accuracy: 0.8535 - val_loss: 0.3314 - val_precision: 0.8448 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 165/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9449 - binary_accuracy: 0.8781 - loss: 0.2981 - precision: 0.8662 - recall: 0.8473 - val_auc: 0.9341 - val_binary_accuracy: 0.8558 - val_loss: 0.3314 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 166/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9441 - binary_accuracy: 0.8766 - loss: 0.3000 - precision: 0.8606 - recall: 0.8480 - val_auc: 0.9340 - val_binary_accuracy: 0.8558 - val_loss: 0.3314 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 167/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9448 - binary_accuracy: 0.8781 - loss: 0.2980 - precision: 0.8598 - recall: 0.8535 - val_auc: 0.9340 - val_binary_accuracy: 0.8558 - val_loss: 0.3313 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 168/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9441 - binary_accuracy: 0.8758 - loss: 0.3000 - precision: 0.8609 - recall: 0.8467 - val_auc: 0.9340 - val_binary_accuracy: 0.8558 - val_loss: 0.3314 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 169/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9452 - binary_accuracy: 0.8773 - loss: 0.2972 - precision: 0.8625 - recall: 0.8483 - val_auc: 0.9340 - val_binary_accuracy: 0.8558 - val_loss: 0.3313 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 170/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9446 - binary_accuracy: 0.8766 - loss: 0.2988 - precision: 0.8625 - recall: 0.8467 - val_auc: 0.9339 - val_binary_accuracy: 0.8558 - val_loss: 0.3312 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 171/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9450 - binary_accuracy: 0.8781 - loss: 0.2977 - precision: 0.8638 - recall: 0.8480 - val_auc: 0.9339 - val_binary_accuracy: 0.8558 - val_loss: 0.3312 - val_precision: 0.8497 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 172/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9454 - binary_accuracy: 0.8773 - loss: 0.2966 - precision: 0.8617 - recall: 0.8474 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3312 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 173/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9442 - binary_accuracy: 0.8766 - loss: 0.2999 - precision: 0.8625 - recall: 0.8467 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3312 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 174/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9455 - binary_accuracy: 0.8773 - loss: 0.2960 - precision: 0.8625 - recall: 0.8483 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3310 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 175/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9452 - binary_accuracy: 0.8797 - loss: 0.2967 - precision: 0.8643 - recall: 0.8516 - val_auc: 0.9339 - val_binary_accuracy: 0.8581 - val_loss: 0.3311 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 176/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9447 - binary_accuracy: 0.8781 - loss: 0.2985 - precision: 0.8627 - recall: 0.8501 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3310 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 177/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8781 - loss: 0.2988 - precision: 0.8625 - recall: 0.8498 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3309 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 178/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9449 - binary_accuracy: 0.8789 - loss: 0.2981 - precision: 0.8659 - recall: 0.8485 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3309 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 179/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8789 - loss: 0.2964 - precision: 0.8641 - recall: 0.8498 - val_auc: 0.9339 - val_binary_accuracy: 0.8581 - val_loss: 0.3308 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 180/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9448 - binary_accuracy: 0.8781 - loss: 0.2981 - precision: 0.8625 - recall: 0.8498 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3308 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 181/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8773 - loss: 0.2984 - precision: 0.8625 - recall: 0.8483 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3308 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 182/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8781 - loss: 0.2975 - precision: 0.8646 - recall: 0.8488 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3308 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 183/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9444 - binary_accuracy: 0.8773 - loss: 0.2988 - precision: 0.8619 - recall: 0.8477 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3307 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 184/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8773 - loss: 0.2985 - precision: 0.8617 - recall: 0.8474 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3306 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 185/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9455 - binary_accuracy: 0.8781 - loss: 0.2958 - precision: 0.8636 - recall: 0.8477 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3306 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 186/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9446 - binary_accuracy: 0.8781 - loss: 0.2987 - precision: 0.8625 - recall: 0.8498 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3306 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 187/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9453 - binary_accuracy: 0.8805 - loss: 0.2967 - precision: 0.8632 - recall: 0.8553 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3305 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 188/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8789 - loss: 0.2973 - precision: 0.8643 - recall: 0.8501 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3305 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 189/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9453 - binary_accuracy: 0.8797 - loss: 0.2967 - precision: 0.8630 - recall: 0.8535 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3304 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 190/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9447 - binary_accuracy: 0.8773 - loss: 0.2984 - precision: 0.8622 - recall: 0.8480 - val_auc: 0.9339 - val_binary_accuracy: 0.8581 - val_loss: 0.3304 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 191/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9453 - binary_accuracy: 0.8789 - loss: 0.2966 - precision: 0.8630 - recall: 0.8519 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3303 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 192/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8805 - loss: 0.2961 - precision: 0.8648 - recall: 0.8537 - val_auc: 0.9339 - val_binary_accuracy: 0.8581 - val_loss: 0.3303 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 193/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9448 - binary_accuracy: 0.8789 - loss: 0.2979 - precision: 0.8625 - recall: 0.8514 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3301 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 194/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9456 - binary_accuracy: 0.8789 - loss: 0.2958 - precision: 0.8625 - recall: 0.8514 - val_auc: 0.9340 - val_binary_accuracy: 0.8581 - val_loss: 0.3301 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 195/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9451 - binary_accuracy: 0.8789 - loss: 0.2970 - precision: 0.8625 - recall: 0.8514 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3301 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 196/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9450 - binary_accuracy: 0.8789 - loss: 0.2974 - precision: 0.8627 - recall: 0.8516 - val_auc: 0.9341 - val_binary_accuracy: 0.8581 - val_loss: 0.3301 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 197/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9452 - binary_accuracy: 0.8789 - loss: 0.2970 - precision: 0.8627 - recall: 0.8516 - val_auc: 0.9342 - val_binary_accuracy: 0.8605 - val_loss: 0.3299 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 198/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9459 - binary_accuracy: 0.8805 - loss: 0.2955 - precision: 0.8667 - recall: 0.8525 - val_auc: 0.9342 - val_binary_accuracy: 0.8581 - val_loss: 0.3298 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 199/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9453 - binary_accuracy: 0.8797 - loss: 0.2973 - precision: 0.8637 - recall: 0.8543 - val_auc: 0.9344 - val_binary_accuracy: 0.8605 - val_loss: 0.3298 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 200/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8797 - loss: 0.2952 - precision: 0.8632 - recall: 0.8537 - val_auc: 0.9344 - val_binary_accuracy: 0.8581 - val_loss: 0.3297 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 201/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9463 - binary_accuracy: 0.8813 - loss: 0.2942 - precision: 0.8648 - recall: 0.8553 - val_auc: 0.9343 - val_binary_accuracy: 0.8581 - val_loss: 0.3297 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 202/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9452 - binary_accuracy: 0.8805 - loss: 0.2969 - precision: 0.8637 - recall: 0.8558 - val_auc: 0.9345 - val_binary_accuracy: 0.8581 - val_loss: 0.3297 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 203/300                                                                     \n",
      "\n",
      "80/80 - 0s - 5ms/step - auc: 0.9463 - binary_accuracy: 0.8813 - loss: 0.2940 - precision: 0.8635 - recall: 0.8571 - val_auc: 0.9346 - val_binary_accuracy: 0.8581 - val_loss: 0.3297 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 204/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9451 - binary_accuracy: 0.8813 - loss: 0.2971 - precision: 0.8662 - recall: 0.8535 - val_auc: 0.9347 - val_binary_accuracy: 0.8581 - val_loss: 0.3295 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 205/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8820 - loss: 0.2965 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9347 - val_binary_accuracy: 0.8581 - val_loss: 0.3294 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 206/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8820 - loss: 0.2958 - precision: 0.8678 - recall: 0.8535 - val_auc: 0.9346 - val_binary_accuracy: 0.8581 - val_loss: 0.3294 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 207/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9458 - binary_accuracy: 0.8813 - loss: 0.2957 - precision: 0.8651 - recall: 0.8556 - val_auc: 0.9347 - val_binary_accuracy: 0.8581 - val_loss: 0.3294 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 208/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9459 - binary_accuracy: 0.8820 - loss: 0.2953 - precision: 0.8667 - recall: 0.8556 - val_auc: 0.9346 - val_binary_accuracy: 0.8605 - val_loss: 0.3295 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 209/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9456 - binary_accuracy: 0.8805 - loss: 0.2960 - precision: 0.8648 - recall: 0.8537 - val_auc: 0.9347 - val_binary_accuracy: 0.8581 - val_loss: 0.3294 - val_precision: 0.8547 - val_recall: 0.8033 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 210/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9454 - binary_accuracy: 0.8805 - loss: 0.2964 - precision: 0.8632 - recall: 0.8553 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3294 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 211/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8805 - loss: 0.2958 - precision: 0.8635 - recall: 0.8556 - val_auc: 0.9348 - val_binary_accuracy: 0.8605 - val_loss: 0.3293 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 212/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9462 - binary_accuracy: 0.8828 - loss: 0.2944 - precision: 0.8664 - recall: 0.8569 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3293 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 213/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8813 - loss: 0.2957 - precision: 0.8664 - recall: 0.8537 - val_auc: 0.9348 - val_binary_accuracy: 0.8605 - val_loss: 0.3292 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 214/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9456 - binary_accuracy: 0.8813 - loss: 0.2963 - precision: 0.8672 - recall: 0.8545 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3293 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 215/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9463 - binary_accuracy: 0.8820 - loss: 0.2945 - precision: 0.8637 - recall: 0.8590 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3292 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 216/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9463 - binary_accuracy: 0.8820 - loss: 0.2943 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9348 - val_binary_accuracy: 0.8605 - val_loss: 0.3292 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 217/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9458 - binary_accuracy: 0.8828 - loss: 0.2954 - precision: 0.8669 - recall: 0.8574 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3293 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 218/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9459 - binary_accuracy: 0.8828 - loss: 0.2951 - precision: 0.8667 - recall: 0.8571 - val_auc: 0.9348 - val_binary_accuracy: 0.8605 - val_loss: 0.3292 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 219/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8820 - loss: 0.2948 - precision: 0.8664 - recall: 0.8553 - val_auc: 0.9349 - val_binary_accuracy: 0.8605 - val_loss: 0.3291 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 220/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9460 - binary_accuracy: 0.8828 - loss: 0.2951 - precision: 0.8683 - recall: 0.8556 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3292 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 221/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8844 - loss: 0.2940 - precision: 0.8701 - recall: 0.8574 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3291 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 222/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9457 - binary_accuracy: 0.8820 - loss: 0.2959 - precision: 0.8678 - recall: 0.8535 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3290 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 223/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9459 - binary_accuracy: 0.8820 - loss: 0.2953 - precision: 0.8662 - recall: 0.8550 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3290 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 224/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8813 - loss: 0.2953 - precision: 0.8662 - recall: 0.8535 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3290 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 225/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9468 - binary_accuracy: 0.8844 - loss: 0.2932 - precision: 0.8720 - recall: 0.8561 - val_auc: 0.9346 - val_binary_accuracy: 0.8605 - val_loss: 0.3289 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 226/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9460 - binary_accuracy: 0.8820 - loss: 0.2950 - precision: 0.8646 - recall: 0.8566 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3289 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 227/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8828 - loss: 0.2950 - precision: 0.8675 - recall: 0.8548 - val_auc: 0.9346 - val_binary_accuracy: 0.8605 - val_loss: 0.3289 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 228/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9464 - binary_accuracy: 0.8828 - loss: 0.2940 - precision: 0.8680 - recall: 0.8553 - val_auc: 0.9347 - val_binary_accuracy: 0.8605 - val_loss: 0.3288 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 229/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8828 - loss: 0.2947 - precision: 0.8683 - recall: 0.8556 - val_auc: 0.9348 - val_binary_accuracy: 0.8628 - val_loss: 0.3287 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 230/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9460 - binary_accuracy: 0.8828 - loss: 0.2951 - precision: 0.8678 - recall: 0.8550 - val_auc: 0.9348 - val_binary_accuracy: 0.8628 - val_loss: 0.3287 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 231/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9476 - binary_accuracy: 0.8844 - loss: 0.2909 - precision: 0.8683 - recall: 0.8587 - val_auc: 0.9348 - val_binary_accuracy: 0.8628 - val_loss: 0.3287 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 232/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9465 - binary_accuracy: 0.8844 - loss: 0.2936 - precision: 0.8685 - recall: 0.8590 - val_auc: 0.9347 - val_binary_accuracy: 0.8628 - val_loss: 0.3287 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 233/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9468 - binary_accuracy: 0.8844 - loss: 0.2930 - precision: 0.8688 - recall: 0.8592 - val_auc: 0.9348 - val_binary_accuracy: 0.8628 - val_loss: 0.3287 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 234/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9461 - binary_accuracy: 0.8820 - loss: 0.2946 - precision: 0.8678 - recall: 0.8535 - val_auc: 0.9347 - val_binary_accuracy: 0.8628 - val_loss: 0.3287 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 235/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9462 - binary_accuracy: 0.8828 - loss: 0.2948 - precision: 0.8683 - recall: 0.8556 - val_auc: 0.9348 - val_binary_accuracy: 0.8628 - val_loss: 0.3286 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 236/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9461 - binary_accuracy: 0.8813 - loss: 0.2946 - precision: 0.8678 - recall: 0.8519 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3285 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 237/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9466 - binary_accuracy: 0.8828 - loss: 0.2935 - precision: 0.8678 - recall: 0.8550 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3284 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 238/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9474 - binary_accuracy: 0.8844 - loss: 0.2913 - precision: 0.8699 - recall: 0.8571 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3284 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 239/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9462 - binary_accuracy: 0.8828 - loss: 0.2946 - precision: 0.8685 - recall: 0.8558 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3284 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 240/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9463 - binary_accuracy: 0.8820 - loss: 0.2940 - precision: 0.8673 - recall: 0.8529 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3283 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 241/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9463 - binary_accuracy: 0.8805 - loss: 0.2942 - precision: 0.8673 - recall: 0.8498 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3284 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 242/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8836 - loss: 0.2923 - precision: 0.8683 - recall: 0.8571 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 243/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9472 - binary_accuracy: 0.8836 - loss: 0.2914 - precision: 0.8694 - recall: 0.8550 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3283 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 244/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8836 - loss: 0.2925 - precision: 0.8699 - recall: 0.8556 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 245/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8844 - loss: 0.2924 - precision: 0.8699 - recall: 0.8571 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 246/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9467 - binary_accuracy: 0.8828 - loss: 0.2932 - precision: 0.8696 - recall: 0.8537 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3283 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 247/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9480 - binary_accuracy: 0.8844 - loss: 0.2895 - precision: 0.8699 - recall: 0.8571 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 248/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8828 - loss: 0.2923 - precision: 0.8678 - recall: 0.8550 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 249/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9479 - binary_accuracy: 0.8836 - loss: 0.2901 - precision: 0.8694 - recall: 0.8550 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 250/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8813 - loss: 0.2922 - precision: 0.8667 - recall: 0.8540 - val_auc: 0.9349 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 251/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9476 - binary_accuracy: 0.8828 - loss: 0.2908 - precision: 0.8692 - recall: 0.8532 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3281 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 252/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8828 - loss: 0.2921 - precision: 0.8710 - recall: 0.8519 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3282 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 253/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8828 - loss: 0.2922 - precision: 0.8680 - recall: 0.8553 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3280 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 254/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8820 - loss: 0.2922 - precision: 0.8678 - recall: 0.8535 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3280 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 255/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9472 - binary_accuracy: 0.8836 - loss: 0.2917 - precision: 0.8680 - recall: 0.8569 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3281 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 256/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9469 - binary_accuracy: 0.8813 - loss: 0.2930 - precision: 0.8683 - recall: 0.8525 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3281 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 257/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9467 - binary_accuracy: 0.8820 - loss: 0.2933 - precision: 0.8694 - recall: 0.8519 - val_auc: 0.9352 - val_binary_accuracy: 0.8628 - val_loss: 0.3280 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 258/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9473 - binary_accuracy: 0.8820 - loss: 0.2919 - precision: 0.8678 - recall: 0.8535 - val_auc: 0.9350 - val_binary_accuracy: 0.8628 - val_loss: 0.3280 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 259/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9475 - binary_accuracy: 0.8836 - loss: 0.2911 - precision: 0.8715 - recall: 0.8540 - val_auc: 0.9353 - val_binary_accuracy: 0.8628 - val_loss: 0.3280 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 260/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9476 - binary_accuracy: 0.8836 - loss: 0.2905 - precision: 0.8696 - recall: 0.8553 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3279 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 261/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9467 - binary_accuracy: 0.8813 - loss: 0.2933 - precision: 0.8680 - recall: 0.8522 - val_auc: 0.9353 - val_binary_accuracy: 0.8628 - val_loss: 0.3278 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 262/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9469 - binary_accuracy: 0.8805 - loss: 0.2926 - precision: 0.8654 - recall: 0.8511 - val_auc: 0.9351 - val_binary_accuracy: 0.8628 - val_loss: 0.3279 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 263/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9469 - binary_accuracy: 0.8828 - loss: 0.2925 - precision: 0.8696 - recall: 0.8537 - val_auc: 0.9352 - val_binary_accuracy: 0.8628 - val_loss: 0.3278 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 264/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9469 - binary_accuracy: 0.8813 - loss: 0.2926 - precision: 0.8654 - recall: 0.8527 - val_auc: 0.9353 - val_binary_accuracy: 0.8628 - val_loss: 0.3278 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 265/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9471 - binary_accuracy: 0.8813 - loss: 0.2923 - precision: 0.8680 - recall: 0.8522 - val_auc: 0.9353 - val_binary_accuracy: 0.8628 - val_loss: 0.3277 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 266/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9479 - binary_accuracy: 0.8836 - loss: 0.2902 - precision: 0.8696 - recall: 0.8553 - val_auc: 0.9352 - val_binary_accuracy: 0.8628 - val_loss: 0.3277 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 267/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9478 - binary_accuracy: 0.8820 - loss: 0.2904 - precision: 0.8662 - recall: 0.8550 - val_auc: 0.9353 - val_binary_accuracy: 0.8628 - val_loss: 0.3278 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 268/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9472 - binary_accuracy: 0.8805 - loss: 0.2917 - precision: 0.8654 - recall: 0.8511 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3277 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 269/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9473 - binary_accuracy: 0.8813 - loss: 0.2914 - precision: 0.8662 - recall: 0.8535 - val_auc: 0.9353 - val_binary_accuracy: 0.8628 - val_loss: 0.3277 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 270/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9476 - binary_accuracy: 0.8828 - loss: 0.2905 - precision: 0.8692 - recall: 0.8532 - val_auc: 0.9354 - val_binary_accuracy: 0.8628 - val_loss: 0.3277 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 271/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9468 - binary_accuracy: 0.8813 - loss: 0.2929 - precision: 0.8680 - recall: 0.8522 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3276 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 272/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9469 - binary_accuracy: 0.8820 - loss: 0.2924 - precision: 0.8689 - recall: 0.8514 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3275 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 273/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9477 - binary_accuracy: 0.8828 - loss: 0.2906 - precision: 0.8713 - recall: 0.8522 - val_auc: 0.9354 - val_binary_accuracy: 0.8628 - val_loss: 0.3275 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 274/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9482 - binary_accuracy: 0.8836 - loss: 0.2892 - precision: 0.8710 - recall: 0.8535 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3274 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 275/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9471 - binary_accuracy: 0.8813 - loss: 0.2921 - precision: 0.8675 - recall: 0.8516 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3275 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 276/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9483 - binary_accuracy: 0.8820 - loss: 0.2888 - precision: 0.8692 - recall: 0.8516 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3275 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 277/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9475 - binary_accuracy: 0.8828 - loss: 0.2912 - precision: 0.8678 - recall: 0.8550 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3276 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 278/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9471 - binary_accuracy: 0.8813 - loss: 0.2920 - precision: 0.8675 - recall: 0.8516 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3274 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 279/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9486 - binary_accuracy: 0.8828 - loss: 0.2883 - precision: 0.8699 - recall: 0.8540 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3274 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 280/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9470 - binary_accuracy: 0.8805 - loss: 0.2919 - precision: 0.8657 - recall: 0.8514 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3273 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 281/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9482 - binary_accuracy: 0.8844 - loss: 0.2893 - precision: 0.8731 - recall: 0.8540 - val_auc: 0.9354 - val_binary_accuracy: 0.8628 - val_loss: 0.3275 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 282/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9477 - binary_accuracy: 0.8836 - loss: 0.2901 - precision: 0.8696 - recall: 0.8553 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3275 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 283/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9474 - binary_accuracy: 0.8813 - loss: 0.2913 - precision: 0.8678 - recall: 0.8519 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3274 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 284/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9473 - binary_accuracy: 0.8813 - loss: 0.2917 - precision: 0.8678 - recall: 0.8519 - val_auc: 0.9353 - val_binary_accuracy: 0.8628 - val_loss: 0.3274 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 285/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9472 - binary_accuracy: 0.8813 - loss: 0.2919 - precision: 0.8680 - recall: 0.8522 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3274 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 286/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9475 - binary_accuracy: 0.8805 - loss: 0.2910 - precision: 0.8646 - recall: 0.8535 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3273 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 287/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9473 - binary_accuracy: 0.8820 - loss: 0.2914 - precision: 0.8694 - recall: 0.8519 - val_auc: 0.9354 - val_binary_accuracy: 0.8628 - val_loss: 0.3274 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 288/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9473 - binary_accuracy: 0.8828 - loss: 0.2913 - precision: 0.8710 - recall: 0.8519 - val_auc: 0.9354 - val_binary_accuracy: 0.8628 - val_loss: 0.3273 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 289/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9478 - binary_accuracy: 0.8836 - loss: 0.2904 - precision: 0.8715 - recall: 0.8540 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3273 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 290/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9473 - binary_accuracy: 0.8820 - loss: 0.2916 - precision: 0.8694 - recall: 0.8519 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3273 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 291/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9484 - binary_accuracy: 0.8820 - loss: 0.2884 - precision: 0.8692 - recall: 0.8516 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3273 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 292/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9479 - binary_accuracy: 0.8844 - loss: 0.2899 - precision: 0.8748 - recall: 0.8525 - val_auc: 0.9356 - val_binary_accuracy: 0.8628 - val_loss: 0.3272 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 293/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9474 - binary_accuracy: 0.8820 - loss: 0.2909 - precision: 0.8689 - recall: 0.8514 - val_auc: 0.9357 - val_binary_accuracy: 0.8628 - val_loss: 0.3271 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 294/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9475 - binary_accuracy: 0.8813 - loss: 0.2911 - precision: 0.8678 - recall: 0.8519 - val_auc: 0.9358 - val_binary_accuracy: 0.8605 - val_loss: 0.3270 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 295/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9478 - binary_accuracy: 0.8820 - loss: 0.2899 - precision: 0.8694 - recall: 0.8519 - val_auc: 0.9357 - val_binary_accuracy: 0.8628 - val_loss: 0.3271 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 296/300                                                                     \n",
      "\n",
      "80/80 - 0s - 2ms/step - auc: 0.9478 - binary_accuracy: 0.8836 - loss: 0.2899 - precision: 0.8719 - recall: 0.8511 - val_auc: 0.9355 - val_binary_accuracy: 0.8628 - val_loss: 0.3271 - val_precision: 0.8605 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 297/300                                                                     \n",
      "\n",
      "80/80 - 0s - 4ms/step - auc: 0.9477 - binary_accuracy: 0.8836 - loss: 0.2904 - precision: 0.8717 - recall: 0.8543 - val_auc: 0.9359 - val_binary_accuracy: 0.8605 - val_loss: 0.3270 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 298/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9475 - binary_accuracy: 0.8813 - loss: 0.2909 - precision: 0.8667 - recall: 0.8540 - val_auc: 0.9356 - val_binary_accuracy: 0.8605 - val_loss: 0.3270 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 299/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9477 - binary_accuracy: 0.8820 - loss: 0.2904 - precision: 0.8694 - recall: 0.8519 - val_auc: 0.9355 - val_binary_accuracy: 0.8605 - val_loss: 0.3271 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "Epoch 300/300                                                                     \n",
      "\n",
      "80/80 - 0s - 3ms/step - auc: 0.9482 - binary_accuracy: 0.8836 - loss: 0.2890 - precision: 0.8727 - recall: 0.8519 - val_auc: 0.9355 - val_binary_accuracy: 0.8605 - val_loss: 0.3270 - val_precision: 0.8555 - val_recall: 0.8087 - learning_rate: 9.6512e-05\n",
      "\n",
      "./plots/smiling-pig-909/learning_rate_vs_epoch.png                                \n",
      "./plots/smiling-pig-909/auc_vs_epoch.png                                          \n",
      "./plots/smiling-pig-909/loss_vs_epoch.png                                         \n",
      "./plots/smiling-pig-909/binary_accuracy_vs_epoch.png                              \n",
      "./plots/smiling-pig-909/recall_vs_epoch.png                                       \n",
      "./plots/smiling-pig-909/precision_vs_epoch.png                                    \n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 521ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step        \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step         \n",
      "\n",
      " 95%|█████████▌| 19/20 [10:09<02:08, 128.59s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/pistachio/evaluation.py:49: RuntimeWarning: overflow encountered in cast\n",
      "  thresholds[0] = sys.float_info.max\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step          \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step         \n",
      "\n",
      " 95%|█████████▌| 19/20 [10:10<02:08, 128.59s/trial, best loss: 0.2997603714466095]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6347aacf60bb4d82ac8f7b2eadde4cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step          \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step         \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 95/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m127/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 83/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m216/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m169/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m252/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m280/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m146/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m149/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m208/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m291/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m156/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m269/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m120/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m210/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m184/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 58/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 89/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m121/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m209/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m232/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m254/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step                \n",
      "\u001b[1m 19/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 38/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 99/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m136/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 16/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step        \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 47/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 67/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 86/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m175/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m263/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 29ms/step                \n",
      "\u001b[1m 20/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 43/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 66/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m139/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m215/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m191/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m112/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m194/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m249/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m162/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m286/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m258/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 20/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 39/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 60/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m224/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m253/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m282/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 82/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m140/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m172/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m260/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m288/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m129/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m155/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m107/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m214/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m240/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m268/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 52/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m202/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m289/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m123/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m152/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m211/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m242/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m272/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 53/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m160/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m219/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m248/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m277/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 22ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 63/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m122/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m153/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m306/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 28/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 51/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m110/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m165/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m193/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m222/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m250/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m278/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step                \n",
      "\u001b[1m 30/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m105/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m188/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m159/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m190/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m247/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m274/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 59/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m118/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m147/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m170/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m194/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m241/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 77/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m104/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m183/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m290/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 24ms/step                \n",
      "\u001b[1m 25/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 50/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 72/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 99/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m126/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m154/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m207/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m237/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 62/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 93/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m124/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m151/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m174/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m198/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m223/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m251/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m304/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 85/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m115/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m144/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m173/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m228/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m255/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m281/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m308/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 31/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 91/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m119/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m150/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m182/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m276/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m307/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 56/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 84/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m113/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m161/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m189/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m217/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m243/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 55/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m108/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m134/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m158/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m185/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m213/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m245/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m273/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 29/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 57/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 78/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 96/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m194/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m218/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m270/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m295/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step                \n",
      "\u001b[1m 26/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 47/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 68/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m117/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m157/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m177/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m262/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m279/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m297/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 27ms/step                \n",
      "\u001b[1m 18/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step        \n",
      "\u001b[1m 35/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 54/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 72/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 90/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m109/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m128/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m148/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m167/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m187/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m212/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m239/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m302/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 32/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m163/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m196/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m227/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m261/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m293/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 35/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 69/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step       \n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step       \n",
      "\u001b[1m204/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m238/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m271/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m305/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 65/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m 98/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m164/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m197/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m230/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m264/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 23ms/step                \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 67/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m100/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m133/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m166/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m199/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m231/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m299/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step                \n",
      "\u001b[1m 34/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step        \n",
      "\u001b[1m 67/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m101/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m135/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m168/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m201/313\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m234/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m267/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m300/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step       \n",
      "\n",
      "🏃 View run smiling-pig-909 at: http://pistachio_mlflow:5000/#/experiments/969440810327601672/runs/76c65f79b249439c8bad95179279ddfc\n",
      "\n",
      "🧪 View experiment at: http://pistachio_mlflow:5000/#/experiments/969440810327601672\n",
      "\n",
      "100%|██████████| 20/20 [10:59<00:00, 131.84s/trial, best loss: 0.2997603714466095]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from hyperopt import Trials, fmin, tpe\n",
    "if os.path.exists(TRIALS_FILE_LOCATION):\n",
    "    trials = pickle.load(open(TRIALS_FILE_LOCATION,'rb'))\n",
    "else:\n",
    "    trials = Trials()\n",
    "\n",
    "\n",
    "evals_done = len(trials.trials)\n",
    "max_evals = evals_done + TRIALS_PER_RUN\n",
    "best = fmin(pistachio_objective,\n",
    "    space=hp_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials)\n",
    "\n",
    "with open(TRIALS_FILE_LOCATION,'wb') as outfile:\n",
    "    pickle.dump(trials,outfile)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6381b4eb-f602-4192-95b0-70e34140def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "trials = pickle.load(open(TRIALS_FILE_LOCATION,'rb'))\n",
    "print(len(trials.trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca134d-81a2-4925-a913-1e58b51ec189",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57cbcf8d-65a8-4865-9e1e-a06a7f773e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "def shap_wrapper(X):\n",
    "    feature_dict = {k:X[:,i] for i,k in enumerate(feature_columns)}\n",
    "    return model.predict(feature_dict).flatten()\n",
    "\n",
    "# shap_n_samples = 50\n",
    "# shap_explainer_samples = 50\n",
    "\n",
    "# data_shap = train_df.loc[:,feature_columns]\n",
    "# explainer = shap.KernelExplainer(shap_wrapper, data_shap.iloc[:shap_explainer_samples,:])\n",
    "# shap_values = explainer.shap_values(data_shap.iloc[shap_explainer_samples:shap_explainer_samples+shap_n_samples, :], nsamples=200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "162d3525-16e1-4b47-b261-1f78ed9f2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81858e7-edfd-4c76-a001-0fac60046b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.scatter(explainer)\n",
    "# shap.plots.bar(shap_values[0])\n",
    "# shap_violin_path = os.path.join(plot_dir,'shap_violin.png')\n",
    "# shap_bar_path = os.path.join(plot_dir,'shap_bar.png')\n",
    "\n",
    "# shap.summary_plot(\n",
    "#     shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"violin\", max_display=30, show=False)\n",
    "# plt.savefig(shap_violin_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8022bc9-7de6-427a-ae34-f1277c45d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(\n",
    "#     shap_values, features=data_shap.iloc[50:100, :], feature_names=feature_columns, plot_type=\"bar\", max_display=30, show=False)\n",
    "# plt.savefig(shap_bar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "527e5c7e-ad4c-44dc-9f74-e27635afcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run(run_id=run_id) as mlflow_run:\n",
    "# #     for mm in metrics_to_plot:\n",
    "# #         # fig_path = os.path.join(plot_dir, f'{mm}_vs_epoch.png');\n",
    "    \n",
    "\n",
    "#     mlflow.log_artifact(validation_metrics_path)\n",
    "#     mlflow.log_artifact(shap_bar_path, artifact_path='evaluation_plots')\n",
    "#     mlflow.log_artifact(shap_violin_path, artifact_path='evaluation_plots')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # mlflow.log_metrics(best_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad6598-ee20-4e4a-bd25-78936e8d5d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
