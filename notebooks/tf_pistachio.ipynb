{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67e146c-7741-4e5d-b3e5-152d1fcce01c",
   "metadata": {},
   "source": [
    "# tensorflow pistachio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9645c12f-836e-43ef-a516-dd6134687a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 19:58:49.091691: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c077c-56e8-4081-b5dc-34945bd1fa61",
   "metadata": {},
   "source": [
    "## arff to csv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19e49d4-8185-4a92-b60f-7e94609fccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/pistachio_16.csv exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from scipy.io import arff\n",
    "import os \n",
    "label_mapping = {'Kirmizi_Pistachio': 0, 'Siit_Pistachio': 1}\n",
    "\n",
    "def load_arff_file(input_arff: str) -> pd.DataFrame:\n",
    "    \"\"\"convert arff file to parquet\"\"\"\n",
    "    if not os.path.exists(input_arff):\n",
    "        raise ValueError(f\"input file '{input_arff}' does not exist\")\n",
    "    print(f'loading arff file {input_arff}')\n",
    "    data, meta = arff.loadarff(input_arff)\n",
    "    print(f\"arff metadata: {meta}\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df['Class'] = df['Class'].astype(str).map(label_mapping)\n",
    "    \n",
    "    return df\n",
    "##################\n",
    "\n",
    "arff_filename = './data/Pistachio_16_Features_Dataset.arff'\n",
    "csv_filename = './data/pistachio_16.csv'\n",
    "if not os.path.exists(csv_filename):\n",
    "    df = load_arff_file(arff_filename)\n",
    "    df.head()\n",
    "    df.to_csv(csv_filename, index=False, header=True)\n",
    "    print(f'wrote file to {csv_filename}')\n",
    "else:\n",
    "    print(f'{csv_filename} exists')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e66103-32dc-4820-8089-71b0f3b4b789",
   "metadata": {},
   "source": [
    "## dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7845cd-40fe-4406-9874-ca68bc501561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/pistachio_train.csv', './data/pistachio_valid.csv', './data/pistachio_test.csv'] exist\n",
      "file: ./data/pistachio_train.csv, records 1589\n",
      "file: ./data/pistachio_valid.csv, records 221\n",
      "file: ./data/pistachio_test.csv, records 338\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "# want a stratified split here\n",
    "def split_csv_data(infilename: str, filenames: List[str], fractions: List[float]):\n",
    "    df = pd.read_csv(infilename, header=0)\n",
    "    df = df.sample(frac=1.0, random_state=34)\n",
    "    columns = df.columns\n",
    "    print(f'total_records = {len(df)}')\n",
    "    if len(filenames) != len(fractions):\n",
    "        raise ValueError('list of filenames must be of same length as split fractions')\n",
    "    renorm = sum(fractions)\n",
    "    lower_bound = 0\n",
    "    df['split_var'] = np.random.uniform(size=len(df))\n",
    "\n",
    "    for filename, frac in zip(filenames, fractions):\n",
    "        upper_bound = lower_bound + frac/renorm\n",
    "        this_data = df.loc[(df.split_var >= lower_bound) & (df.split_var < upper_bound) ][columns]\n",
    "        this_data.to_csv(filename, index=False, header=True)\n",
    "        print(f'wrote {len(this_data)} records to {filename}')\n",
    "        lower_bound = upper_bound\n",
    "#################################\n",
    "    \n",
    "train_filename = './data/pistachio_train.csv'\n",
    "valid_filename = './data/pistachio_valid.csv'\n",
    "test_filename = './data/pistachio_test.csv'\n",
    "filenames = [train_filename, valid_filename, test_filename]\n",
    "fractions = [0.75, 0.10, 0.15]\n",
    "\n",
    "if not (os.path.exists(train_filename) and os.path.exists(test_filename) and os.path.exists(valid_filename)):\n",
    "    split_csv_data(csv_filename, filenames, fractions )\n",
    "else:\n",
    "    print(f'{filenames} exist')\n",
    "\n",
    "\n",
    "for i in filenames:\n",
    "    df = pd.read_csv(i, header=0)\n",
    "    print(f'file: {i}, records {len(df)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1902bad6-0b5a-4cbf-8163-159c21a7b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(features, labels):\n",
    "    return tf.transpose(tf.stack([features[k] for k in features])), tf.reshape(labels,[-1,1])\n",
    "\n",
    "batch_size = 10\n",
    "# use dataset.map to concatenate feature dictionary into tensor\n",
    "pistachio_train_batches = tf.data.experimental.make_csv_dataset(\n",
    "    train_filename, batch_size=batch_size,\n",
    "    num_epochs=1,\n",
    "    label_name=\"Class\").map(map_func)\n",
    "pistachio_test_data = tf.data.experimental.make_csv_dataset(\n",
    "    test_filename,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=1,\n",
    "    label_name=\"Class\").map(map_func)\n",
    "validation_data = tf.data.experimental.make_csv_dataset(\n",
    "    valid_filename, batch_size=batch_size,\n",
    "    num_epochs=1,\n",
    "    label_name=\"Class\").map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a8ac90-eceb-44cb-a73f-8d55a76c66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'label': [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "features batch shape: (4, 16)\n",
      "'label': [[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "features batch shape: (4, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:35:45.953447: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "batch = 0\n",
    "for feature_batch, label_batch in pistachio_train_batches.take(2):\n",
    "    # print(f'{batch}, {label_batch.shape}')\n",
    "    # cat_batch = tf.stack([feature_batch['AREA'],feature_batch['PERIMETER']],axis=1)\n",
    "    # cat_batch = tf.stack([feature_batch[k] for k in feature_batch],axis=1)\n",
    "\n",
    "    # batch += 1\n",
    "    \n",
    "    print(\"'label': {}\".format(label_batch))\n",
    "    # print(cat_batch)\n",
    "    print(f\"features batch shape: {feature_batch.shape}\")\n",
    "    # print(feature_batch.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48becd0f-e403-4e38-8de1-0cf00d1dea89",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd86bdb2-b2a3-47ae-b4af-24a4ce24404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization\n",
    "# from tensorflow.keras import Model\n",
    "\n",
    "# class PistachioModel(Model):\n",
    "#     def __init__(self, units: int=10):\n",
    "#         super().__init__()\n",
    "#         self._units = units\n",
    "    \n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.bn = BatchNormalization(axis=0, input_shape=input_shape)\n",
    "#         self.d1 = Dense(self._units, activation='relu', input_shape=input_shape)\n",
    "#         self.d2 = Dense(self._units)\n",
    "#         self.lout = Dense(1, activation='sigmoid')\n",
    "        \n",
    "\n",
    "\n",
    "#     def call(self, x):\n",
    "#         x = self.bn(x)\n",
    "#         x = self.d1(x)\n",
    "#         x = self.d2(x)\n",
    "#         return self.lout(x)\n",
    "\n",
    "# # Create an instance of the model\n",
    "# model = PistachioModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea6012-3ffa-4ca8-b617-9d0999e588a4",
   "metadata": {},
   "source": [
    "## Keras model.fit api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afb24047-86ea-4f70-939c-769ca8089d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "#               metrics=['accuracy', 'auc'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e71dc3-4e8f-4895-946b-04af6afcea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(pistachio_train_batches, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196f01d-4e1d-4014-9041-a8228d2117e3",
   "metadata": {},
   "source": [
    "## sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffdfcd8e-0ee0-4882-a93c-3cef10012d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.BatchNormalization(), \n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(16),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', 'auc', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a9cc68-ae2c-4564-af0a-16be2692cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.fit(pistachio_train_batches, epochs=20, validation_data=validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd47e368-7596-4cbd-a224-9aeb9879c0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 0s - 2ms/step - accuracy: 0.8698 - auc: 0.9361 - loss: 0.3439 - precision: 0.8252 - recall: 0.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:37:06.076313: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.343885213136673,\n",
       " 0.8698225021362305,\n",
       " 0.9361041188240051,\n",
       " 0.8251748085021973,\n",
       " 0.8613138794898987]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model2.evaluate(pistachio_test_data,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84046f88-2c10-4a9d-ad6a-da772e906c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted prob: [0.6096879], label: [1]\n",
      "predicted prob: [0.13835986], label: [0]\n",
      "predicted prob: [0.06268708], label: [0]\n",
      "predicted prob: [0.10202026], label: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:37:17.202003: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# for features, labels in pistachio_test_data.take(1):\n",
    "#     predictions = model2(features)\n",
    "#     for p,l in zip(predictions, labels):\n",
    "#         print(f'predicted prob: {p}, label: {l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630f2c6-e791-422d-bc5f-b6eb964590c7",
   "metadata": {},
   "source": [
    "## custom training loop stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c11d10d9-f58b-4b21-b654-8a12e8be037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.BatchNormalization(), \n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(16),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c40b55d5-f055-4458-9db4-a99297a5b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0, training loss 1852.3375244140625\n",
      "epoch 0, batch 10, training loss 1219.437744140625\n",
      "epoch 0, batch 20, training loss 353.310546875\n",
      "epoch 0, batch 30, training loss 346.21746826171875\n",
      "epoch 0, batch 40, training loss 441.00518798828125\n",
      "epoch 0, batch 50, training loss 293.82550048828125\n",
      "epoch 0, batch 60, training loss 348.50836181640625\n",
      "epoch 0, batch 70, training loss 188.50709533691406\n",
      "epoch 0, batch 80, training loss 527.7088623046875\n",
      "epoch 0, batch 90, training loss 316.4344177246094\n",
      "epoch 0, batch 100, training loss 247.21017456054688\n",
      "epoch 0, batch 110, training loss 145.61026000976562\n",
      "epoch 0, batch 120, training loss 275.33489990234375\n",
      "epoch 0, batch 130, training loss 127.54837799072266\n",
      "epoch 0, batch 140, training loss 295.907958984375\n",
      "epoch 0, batch 150, training loss 260.89910888671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 20:07:19.146993: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, time 10.288832426071167\n",
      "epoch 1, batch 0, training loss 285.18707275390625\n",
      "epoch 1, batch 10, training loss 223.09078979492188\n",
      "epoch 1, batch 20, training loss 499.3887634277344\n",
      "epoch 1, batch 30, training loss 140.48171997070312\n",
      "epoch 1, batch 40, training loss 521.537109375\n",
      "epoch 1, batch 50, training loss 165.34548950195312\n",
      "epoch 1, batch 60, training loss 130.39639282226562\n",
      "epoch 1, batch 70, training loss 357.6820983886719\n",
      "epoch 1, batch 80, training loss 242.6947784423828\n",
      "epoch 1, batch 90, training loss 190.4488067626953\n",
      "epoch 1, batch 100, training loss 223.4416046142578\n",
      "epoch 1, batch 110, training loss 227.3134765625\n",
      "epoch 1, batch 120, training loss 416.3309020996094\n",
      "epoch 1, batch 130, training loss 165.32669067382812\n",
      "epoch 1, batch 140, training loss 313.72735595703125\n",
      "epoch 1, batch 150, training loss 353.150390625\n",
      "epoch 1, time 11.163836240768433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 20:07:31.708628: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "epoch_times = []\n",
    "from time import time\n",
    "\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "start_time = time()\n",
    "epochs = 2\n",
    "steps_per_output=10\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time()\n",
    "\n",
    "    for batch_no, (train_x, train_y) in enumerate(pistachio_train_batches):\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model3(train_x)\n",
    "            the_loss = loss(train_y, output)\n",
    "        train_loss.append(the_loss)\n",
    "            \n",
    "\n",
    "        grads = tape.gradient(the_loss, model3.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model3.trainable_weights))\n",
    "\n",
    "        if batch_no % steps_per_output == 0:\n",
    "            print(f'epoch {epoch}, batch {batch_no}, training loss {the_loss}')\n",
    "    this_epoch_time = time() - epoch_start_time\n",
    "    print(f'epoch {epoch}, time {this_epoch_time}')\n",
    "    epoch_times.append(this_epoch_time)\n",
    "    \n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521f321b-3f87-4bc3-b81f-afdaa3f22fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.288832426071167, 11.163836240768433]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf0981-5859-433a-a837-169a41ddbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8325fcf-5fbb-4560-9750-abae042443e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_records = []\n",
    "valid_loss_records = []\n",
    "epoch_times = []\n",
    "from time import time\n",
    "\n",
    "# loss function\n",
    "train_loss_ob = tf.keras.losses.BinaryCrossentropy(from_logits=False, name='training_loss')\n",
    "# training metrics\n",
    "train_metrics = {\n",
    "    \"train_roc\": tf.keras.metrics.AUC(name=\"training_ROC_AUC\"),\n",
    "    \"train_acc\": tf.keras.metrics.BinaryAccuracy(name=\"train_accuracy\"),\n",
    "    \"train_recall\": tf.keras.metrics.Recall(name=\"train_recall\"),\n",
    "    \"train_precision\":  tf.keras.metrics.Precision(name=\"train_precision\")\n",
    "}\n",
    "\n",
    "# validation\n",
    "# loss function\n",
    "valid_loss_ob = tf.keras.losses.BinaryCrossentropy(from_logits=False, name='valid')\n",
    "# validing metrics\n",
    "valid_metrics = {\n",
    "    \"valid_roc_auc\": tf.keras.metrics.AUC(name=\"valid_ROC_AUC\"),\n",
    "    \"valid_acc\": tf.keras.metrics.BinaryAccuracy(name=\"valid_accuracy\"),\n",
    "    \"valid_recall\": tf.keras.metrics.Recall(name=\"valid_recall\"),\n",
    "    \"valid_precision\": tf.keras.metrics.Precision(name=\"valid_precision\")\n",
    "}\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "837ece09-1097-4802-a799-ac58f4b42f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(train_x, train_y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(train_x, training=True)\n",
    "        loss = train_loss_ob(train_y, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    for metric in train_metrics.values():\n",
    "        metric.update_state(train_y, predictions)\n",
    "    return loss\n",
    " \n",
    "  # train_loss(loss)\n",
    "  # train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a43b7-7b52-4502-b0e9-5e6415cb1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def test_step(images, labels):\n",
    "    pass\n",
    "    # # training=False is only needed if there are layers with different\n",
    "    # # behavior during training versus inference (e.g. Dropout).\n",
    "    # predictions = model(images, training=False)\n",
    "    # t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    # test_loss(t_loss)\n",
    "    # test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "768d9dad-1cf3-4b91-becf-0370b03417d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0, training loss 0.7548421025276184\n",
      "epoch 0, batch 10, training loss 0.7286007404327393\n",
      "epoch 0, batch 20, training loss 0.7910215854644775\n",
      "epoch 0, batch 30, training loss 0.7089307904243469\n",
      "epoch 0, batch 40, training loss 0.7511945366859436\n",
      "epoch 0, batch 50, training loss 0.6782774329185486\n",
      "epoch 0, batch 60, training loss 0.6774525046348572\n",
      "epoch 0, batch 70, training loss 0.5865039229393005\n",
      "epoch 0, batch 80, training loss 0.7561821341514587\n",
      "epoch 0, batch 90, training loss 0.6875983476638794\n",
      "epoch 0, batch 100, training loss 0.7411220073699951\n",
      "epoch 0, batch 110, training loss 0.6971716284751892\n",
      "epoch 0, batch 120, training loss 0.653087317943573\n",
      "epoch 0, batch 130, training loss 0.6775817275047302\n",
      "epoch 0, batch 140, training loss 0.6160794496536255\n",
      "epoch 0, batch 150, training loss 0.5910268425941467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 21:03:20.624650: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, time 5.132985591888428\n",
      "train_roc: 0.4983018934726715\n",
      "train_acc: 0.5078665614128113\n",
      "train_recall: 0.4281567633152008\n",
      "train_precision: 0.4319179952144623\n",
      "epoch 1, batch 0, training loss 0.7238677144050598\n",
      "epoch 1, batch 10, training loss 0.6127718091011047\n",
      "epoch 1, batch 20, training loss 0.6200535893440247\n",
      "epoch 1, batch 30, training loss 0.6818579435348511\n",
      "epoch 1, batch 40, training loss 0.6232209205627441\n",
      "epoch 1, batch 50, training loss 0.6710546612739563\n",
      "epoch 1, batch 60, training loss 0.6384653449058533\n",
      "epoch 1, batch 70, training loss 0.5474119782447815\n",
      "epoch 1, batch 80, training loss 0.6812781691551208\n",
      "epoch 1, batch 90, training loss 0.5983659625053406\n",
      "epoch 1, batch 100, training loss 0.5465803742408752\n",
      "epoch 1, batch 110, training loss 0.6512739658355713\n",
      "epoch 1, batch 120, training loss 0.5343424677848816\n",
      "epoch 1, batch 130, training loss 0.5651676058769226\n",
      "epoch 1, batch 140, training loss 0.5229609608650208\n",
      "epoch 1, batch 150, training loss 0.6935484409332275\n",
      "epoch 1, time 0.32559967041015625\n",
      "train_roc: 0.7813119292259216\n",
      "train_acc: 0.7186909914016724\n",
      "train_recall: 0.5805515050888062\n",
      "train_precision: 0.7168458700180054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 21:03:23.275484: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_loss_records = []\n",
    "valid_loss_records = []\n",
    "train_metric_records = []\n",
    "epoch_times = []\n",
    "\n",
    "start_time = time()\n",
    "epochs = 2\n",
    "steps_per_output=50\n",
    "total_batches = 0\n",
    "for epoch in range(epochs):\n",
    "    # clear the metric states - these metrics are computed over all batches in the epoch\n",
    "    for metric in train_metrics.values():\n",
    "        metric.reset_state()\n",
    "    # start the clock for this epoch\n",
    "    epoch_start_time = time()\n",
    "    \n",
    "    # run through batches\n",
    "    for batch_no, (train_x, train_y) in enumerate(pistachio_train_batches):\n",
    "        # take a training step\n",
    "        the_loss = train_step(train_x, train_y)\n",
    "        # this is the individual loss for a training batch\n",
    "        train_loss.append(the_loss)\n",
    "        \n",
    "        if batch_no % steps_per_output == 0:\n",
    "            print(f'epoch {epoch}, batch {batch_no}, training loss {the_loss}')\n",
    "        \n",
    "    # time for this epoch    \n",
    "    this_epoch_time = time() - epoch_start_time\n",
    "    print(f'epoch {epoch}, time {this_epoch_time}')\n",
    "    # evaluate metrics over the epoch\n",
    "    epoch_metrics = {k: v.result() for k,v in train_metrics.items()}\n",
    "    for k,v in epoch_metrics.items():\n",
    "        print(f'{k}: {v}')\n",
    "        \n",
    "    train_metric_records.append(epoch_metrics)\n",
    "    epoch_times.append(this_epoch_time)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d180f3c-c79e-4d93-bb72-81f4870f6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.tensorflow.org/guide/migrate/early_stopping\n",
    "This accumulates training and validation losses as averages over an epoch of training/the valudation set. \n",
    "Can do training loss per batch, or training + validation per epoch\n",
    "remember to set training = true/false in metric evaluation/updating\n",
    "moose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b049d-3213-460c-ac02-d02a01454360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_state()\n",
    "  train_accuracy.reset_state()\n",
    "  test_loss.reset_state()\n",
    "  test_accuracy.reset_state()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result():0.2f}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100:0.2f}, '\n",
    "    f'Test Loss: {test_loss.result():0.2f}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100:0.2f}'\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
